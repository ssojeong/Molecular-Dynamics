device singleton constructed for  cpu
pid :  98950
uname :  posix.uname_result(sysname='Darwin', nodename='hks-MacBook-Pro.local', release='20.6.0', version='Darwin Kernel Version 20.6.0: Mon Aug 30 06:12:21 PDT 2021; root:xnu-7195.141.6~3/RELEASE_X86_64', machine='x86_64')
code run start time  20220420, 10:06:43
device singleton constructed for  cpu
trainer dict ============== 
loadfile : None
nn_mode : ff
pwnet_nnodes : 256
mbnet_nnodes : 256
pw4mb_nnodes : 256
grad_clip : 1
n_chain : 1
ngrids : 6
b : 0.2
lr : 0.001
tau_lr : 0.01
sch_step : 10
sch_decay : 0.99
reset_lr : False
loss dict ============== 
eweight : 0.0
polynomial_degree : 1
data dict ============== 
train_file : ../data_sets/n16anyrholt10everystps_afew_nsamples30000train.pt
valid_file : ../data_sets/n16anyrholt10everystps_afew_nsamples24000valid.pt
test_file : ../data_sets/n16anyrholt10everystps_afew_nsamples24000valid.pt
train_pts : 400
vald_pts : 20
test_pts : 10
batch_size : 200
n_chain : 1
main dict ============== 
start_epoch : 0
end_epoch : 100000
save_dir : test_dir
ckpt_interval : 1000
val_interval : 10000
verb : 10
my_data initialized : train_filename  ../data_sets/n16anyrholt10everystps_afew_nsamples30000train.pt  val_filename  ../data_sets/n16anyrholt10everystps_afew_nsamples24000valid.pt  test_filename  ../data_sets/n16anyrholt10everystps_afew_nsamples24000valid.pt  train_pts  400  val_pts  20  test_pts  10
kwargs  {} batch_size  200
pw fnn
--- initialize pw_ff ---
mb fnn
--- initialize mb ff ---
pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
)
pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=3, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
)
pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
)
pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
)
pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=6, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
)
pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=7, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
)
mb_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=24, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
mb_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=36, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
mb_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=48, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
mb_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=60, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
mb_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=72, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
mb_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=84, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
)
pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
)
pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
)
state dict  {'cos_dict': {'T_0': 10, 'T_i': 10, 'T_mult': 1, 'eta_min': 0, 'base_lrs': [0.001], 'last_epoch': 0, '_step_count': 0, 'verbose': False, 'T_cur': 0, '_get_lr_called_within_step': False, '_last_lr': [0.001]}, 'thrsh': 0.001, 'cntr': 0}
checkpoint initialized : net list  [pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
), pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=3, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
), pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
), pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
), pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=6, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
), pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=7, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
), mb_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=24, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
), mb_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=36, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
), mb_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=48, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
), mb_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=60, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
), mb_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=72, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
), mb_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=84, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=256, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
), pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
), pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
), pw_neural_net(
  (layers): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
)  opt2  SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <optimizers.DecayCosineAnnealingWarmRestarts.DecayCosineAnnealingWarmRestarts object at 0x7ff38f232fd0>
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.7913e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.7913e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.7850e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.7850e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.7439e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.7439e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.0310e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.0310e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.7461e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.7461e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.9271e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.9271e-28, grad_fn=<SumBackward0>)
2 batches 


 train 1 lr 1.00e-03 total 2.979816e+01 (8.8568e+00) 
 train 1 lr 1.00e-03 *qrmse 3.522986e+00 (1.7827e-02)  -qmse 1.486925e+01 (9.9078e-02)  -qmae 4.603913e+00 (2.7202e-02) 
 train 1 lr 1.00e-03 *prmse 1.273294e+01 (3.7460e+00)  -pmse 2.350745e+02 (1.1854e+02)  -pmae 1.602829e+01 (4.1640e+00) 
 train 1 lr 1.00e-03 *emae 3.053640e+08 (5.5064e+07)  -emse 1.170479e+19 (2.5952e+18)  *mmae 1.354224e+01 (5.0929e+00) 
 train 1 lr 1.00e-03 qshape 3.522986e+00 (1.7827e-02)  pshape 1.273294e+01 (3.7460e+00)  eshape 3.053640e+08 (5.5064e+07)  mshape 1.354224e+01 (5.0929e+00) 

1 train mb tau 0:9.98e-01 1:1.19e+00 2:8.72e-01 3:1.02e+00 4:8.07e-01 5:1.00e+00
1 train pw tau 0:9.73e-01 1:1.00e+00 2:9.96e-01 3:1.01e+00 4:1.00e+00 5:1.00e+00
weight/bias range [ -0.5387078153927546 0.5154435222218813 ]
weight/bias range [ -0.5694003836520345 0.5748634079552373 ]
weight/bias range [ -0.5549766345017708 0.505472808103924 ]
weight/bias range [ -0.47881374575156294 0.5202671330866664 ]
weight/bias range [ -0.5950611040671826 0.4895786411850264 ]
weight/bias range [ -0.5082576637976957 0.5012306751815406 ]
weight/bias range [ -0.5807865476780332 0.5770306383790913 ]
weight/bias range [ -0.5564699110752894 0.5077967453790156 ]
weight/bias range [ -0.5089035020687969 0.49517255777080665 ]
weight/bias range [ -0.4953682058171323 0.652421506040768 ]
weight/bias range [ -0.508149131165424 0.567831961408222 ]
weight/bias range [ -0.5712563888061858 0.5593899257399848 ]
weight/bias range [ -0.4821103639568539 0.46738490631560276 ]
weight/bias range [ -0.5058689693379836 0.5294368332702448 ]
weight/bias range [ -0.49334355081822956 0.5169085331375506 ]
memory usage : 35.9  at t= 1
time usage : 0:00:54.941228 ( 0:00:54.941228 ) at t= 1
y shape  torch.Size([20, 16, 2])
q input mean shape  torch.Size([320, 12])
diff sq in mb_base.py  tensor(8.0068e-29, grad_fn=<SumBackward0>)
y shape  torch.Size([20, 16, 2])
q input mean shape  torch.Size([320, 12])
diff sq in mb_base.py  tensor(8.0068e-29, grad_fn=<SumBackward0>)
y shape  torch.Size([20, 16, 2])
q input mean shape  torch.Size([320, 12])
diff sq in mb_base.py  tensor(1.5391e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([20, 16, 2])
q input mean shape  torch.Size([320, 12])
diff sq in mb_base.py  tensor(1.5391e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([20, 16, 2])
q input mean shape  torch.Size([320, 12])
diff sq in mb_base.py  tensor(4.8162e-29, grad_fn=<SumBackward0>)
y shape  torch.Size([20, 16, 2])
q input mean shape  torch.Size([320, 12])
diff sq in mb_base.py  tensor(4.8162e-29, grad_fn=<SumBackward0>)

 eval 1 lr 1.00e-03 total 2.333924e+01 (0.0000e+00) 
 eval 1 lr 1.00e-03 *qrmse 3.463778e+00 (0.0000e+00)  -qmse 1.373175e+01 (0.0000e+00)  -qmae 4.546867e+00 (0.0000e+00) 
 eval 1 lr 1.00e-03 *prmse 9.204650e+00 (0.0000e+00)  -pmse 1.226687e+02 (0.0000e+00)  -pmae 1.239872e+01 (0.0000e+00) 
 eval 1 lr 1.00e-03 *emae 7.930709e+08 (0.0000e+00)  -emse 4.298242e+19 (0.0000e+00)  *mmae 1.067081e+01 (0.0000e+00) 
 eval 1 lr 1.00e-03 qshape 3.463778e+00 (0.0000e+00)  pshape 9.204650e+00 (0.0000e+00)  eshape 7.930709e+08 (0.0000e+00)  mshape 1.067081e+01 (0.0000e+00) 

1 eval mb tau 0:9.98e-01 1:1.19e+00 2:8.72e-01 3:1.02e+00 4:8.07e-01 5:1.00e+00
1 eval pw tau 0:9.73e-01 1:1.00e+00 2:9.96e-01 3:1.01e+00 4:1.00e+00 5:1.00e+00
weight/bias range [ -0.5387078153927546 0.5154435222218813 ]
weight/bias range [ -0.5694003836520345 0.5748634079552373 ]
weight/bias range [ -0.5549766345017708 0.505472808103924 ]
weight/bias range [ -0.47881374575156294 0.5202671330866664 ]
weight/bias range [ -0.5950611040671826 0.4895786411850264 ]
weight/bias range [ -0.5082576637976957 0.5012306751815406 ]
weight/bias range [ -0.5807865476780332 0.5770306383790913 ]
weight/bias range [ -0.5564699110752894 0.5077967453790156 ]
weight/bias range [ -0.5089035020687969 0.49517255777080665 ]
weight/bias range [ -0.4953682058171323 0.652421506040768 ]
weight/bias range [ -0.508149131165424 0.567831961408222 ]
weight/bias range [ -0.5712563888061858 0.5593899257399848 ]
weight/bias range [ -0.4821103639568539 0.46738490631560276 ]
weight/bias range [ -0.5058689693379836 0.5294368332702448 ]
weight/bias range [ -0.49334355081822956 0.5169085331375506 ]
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.0599e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.0599e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(2.7551e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(2.7551e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.7640e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.7640e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3664e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3664e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(2.7067e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(2.7067e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(2.1101e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(2.1101e-27, grad_fn=<SumBackward0>)
2 batches 

y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.0752e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.0752e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.2129e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.2129e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.2130e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.2130e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.0969e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.0969e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.5705e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.5705e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.1522e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.1522e-28, grad_fn=<SumBackward0>)
2 batches 

y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.6117e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.6117e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.4632e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.4632e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.1024e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.1024e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.1417e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.1417e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.7163e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.7163e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(6.4484e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(6.4484e-28, grad_fn=<SumBackward0>)
2 batches 

y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.1287e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.1287e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(2.3162e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(2.3162e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.1724e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.1724e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.8683e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.8683e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.4730e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.4730e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(6.0744e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(6.0744e-28, grad_fn=<SumBackward0>)
2 batches 

y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.1261e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.1261e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.6435e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.6435e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.3020e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.3020e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.3856e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.3856e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.5739e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.5739e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.6177e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.6177e-28, grad_fn=<SumBackward0>)
2 batches 

y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.2204e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.2204e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.2109e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.2109e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.4277e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.4277e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(9.0125e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(9.0125e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.4863e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.4863e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.3676e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.3676e-28, grad_fn=<SumBackward0>)
2 batches 

y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.6186e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.6186e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.4761e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.4761e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.9142e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.9142e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.6206e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.6206e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.2416e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.2416e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.1510e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.1510e-28, grad_fn=<SumBackward0>)
2 batches 

y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.6302e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.6302e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.2610e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.2610e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.0780e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.0780e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(9.4896e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(9.4896e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3906e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3906e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.3578e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.3578e-28, grad_fn=<SumBackward0>)
2 batches 

y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.8907e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.8907e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3653e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3653e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(4.9387e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(4.9387e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.1613e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.1613e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3975e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3975e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.2068e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.2068e-28, grad_fn=<SumBackward0>)
2 batches 

y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.3129e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(8.3129e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.4838e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.4838e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.1753e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.1753e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.5676e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.5676e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3991e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3991e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.5983e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.5983e-28, grad_fn=<SumBackward0>)
2 batches 


 train 11 lr 9.90e-04 total 1.040777e+01 (7.5809e+00) 
 train 11 lr 9.90e-04 *qrmse 3.500748e+00 (5.9793e-02)  -qmse 1.470914e+01 (5.0709e-01)  -qmae 4.574941e+00 (7.8569e-02) 
 train 11 lr 9.90e-04 *prmse 3.728048e+00 (3.4319e+00)  -pmse 3.574854e+01 (6.5097e+01)  -pmae 4.798824e+00 (4.4255e+00) 
 train 11 lr 9.90e-04 *emae 2.977855e+08 (6.0174e+07)  -emse 1.160124e+19 (3.3193e+18)  *mmae 3.178975e+00 (4.1474e+00) 
 train 11 lr 9.90e-04 qshape 3.500748e+00 (5.9793e-02)  pshape 3.728048e+00 (3.4319e+00)  eshape 2.977855e+08 (6.0174e+07)  mshape 3.178975e+00 (4.1474e+00) 

11 train mb tau 0:2.17e-01 1:8.85e-01 2:-2.13e-02 3:1.06e+00 4:-1.33e-02 5:1.00e+00
11 train pw tau 0:9.40e-01 1:8.51e-01 2:9.82e-01 3:1.02e+00 4:9.97e-01 5:1.00e+00
weight/bias range [ -0.5387297316428329 0.5153335816865663 ]
weight/bias range [ -0.5694374585563539 0.5748621173603846 ]
weight/bias range [ -0.5548823277482753 0.5053832332096482 ]
weight/bias range [ -0.47881556954554405 0.5202773697239271 ]
weight/bias range [ -0.5950590901976144 0.48958142164808005 ]
weight/bias range [ -0.5082575076684168 0.5012304005951063 ]
weight/bias range [ -0.5808718034879303 0.5769010070097836 ]
weight/bias range [ -0.5565763943112784 0.5075148845137664 ]
weight/bias range [ -0.5088674436899362 0.49516086309418933 ]
weight/bias range [ -0.49537408808805944 0.6524092490593142 ]
weight/bias range [ -0.5079649785908773 0.5678465520086766 ]
weight/bias range [ -0.5712557615033105 0.5593900284277441 ]
weight/bias range [ -0.4812659874042845 0.4682948616980931 ]
weight/bias range [ -0.505842991045868 0.5294354454767238 ]
weight/bias range [ -0.49334355081822956 0.5169085331375506 ]
memory usage : 37.8  at t= 11
time usage : 0:09:59.307932 ( 0:09:04.366704 ) at t= 11
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(6.7916e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(6.7916e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.4983e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.4983e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(6.1089e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(6.1089e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.1444e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.1444e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.9685e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.9685e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.8584e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.8584e-28, grad_fn=<SumBackward0>)
2 batches 

y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.6393e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.6393e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3789e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3789e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.0788e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.0788e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.0136e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.0136e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.1956e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.1956e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.0939e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.0939e-28, grad_fn=<SumBackward0>)
2 batches 

y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(9.8325e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(9.8325e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.5519e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.5519e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.4808e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(5.4808e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3320e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3320e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.7872e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.7872e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.2237e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.2237e-28, grad_fn=<SumBackward0>)
2 batches 

y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3683e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.3683e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.7260e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(1.7260e-27, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.5260e-28, grad_fn=<SumBackward0>)
y shape  torch.Size([200, 16, 2])
q input mean shape  torch.Size([3200, 12])
diff sq in mb_base.py  tensor(7.5260e-28, grad_fn=<SumBackward0>)
Traceback (most recent call last):
  File "main08.py", line 129, in <module>
    train.one_step(q_init,p_init,q_label,p_label,l_init)
  File "/Users/hk/research/projects/statphys_ML/20210325_HNN/20220305/hfnn20220415/ML/trainer/trainer.py", line 71, in one_step
    loss_val.backward()
  File "/Users/hk/anaconda3/lib/python3.8/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/Users/hk/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt

python main08.py  1054.42s user 318.50s system 134% cpu 16:59.92 total
