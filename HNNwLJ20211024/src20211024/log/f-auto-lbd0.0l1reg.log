forward 1rho0.10, first run no save model .....
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522355
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:52:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f65efd4f610>
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.399070 valid_loss:0.404618 each epoch time:19.79492
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001601  valid_dq/boxsize 0.001626  train_dp 0.378820  valid_dp 0.384046 reg_loss 34.999216
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:53:47
run time  0:01:41.268405
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/rho0/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/forward_1/forward_1_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522371
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:53:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f44b2061fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 5, '_step_count': 6, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.457826 valid_loss:0.451506 each epoch time:20.00142
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.002187  valid_dq/boxsize 0.002159  train_dp 0.434443  valid_dp 0.428423 reg_loss 36.837355
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:55:29
run time  0:01:41.718538
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_1/forward_1_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522395
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:55:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4677496490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 10, '_step_count': 11, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.363426 valid_loss:0.369693 each epoch time:20.65836
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001488  valid_dq/boxsize 0.001517  train_dp 0.344605  valid_dp 0.350507 reg_loss 29.649816
memory usage : 3.5  at e= 5
end date/time : 20211025, 14:57:17
run time  0:01:43.301586
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_1/forward_1_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522411
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:57:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fee02978390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 15, '_step_count': 16, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.503351 valid_loss:0.501003 each epoch time:19.73018
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002917  valid_dq/boxsize 0.002910  train_dp 0.477263  valid_dp 0.474972 reg_loss 58.141755
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:58:58
run time  0:01:40.187671
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_1/forward_1_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522428
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:58:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb70fced0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 20, '_step_count': 21, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.346870 valid_loss:0.353480 each epoch time:20.13565
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001439  valid_dq/boxsize 0.001469  train_dp 0.328667  valid_dp 0.334901 reg_loss 27.341362
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:00:41
run time  0:01:41.795658
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_1/forward_1_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522444
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:00:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff63c7b2090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 25, '_step_count': 26, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.417627 valid_loss:0.412618 each epoch time:20.19451
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.002049  valid_dq/boxsize 0.002026  train_dp 0.395726  valid_dp 0.390962 reg_loss 30.382097
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:02:23
run time  0:01:40.254456
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_1/forward_1_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522461
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:02:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe1637b3050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 30, '_step_count': 31, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.546987 valid_loss:0.543132 each epoch time:20.16324
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003729  valid_dq/boxsize 0.003711  train_dp 0.518283  valid_dp 0.514565 reg_loss 65.155193
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:04:06
run time  0:01:41.476879
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_1/forward_1_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522479
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:04:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f560d21d910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 35, '_step_count': 36, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.619403 valid_loss:0.617593 each epoch time:21.07192
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.005033  valid_dq/boxsize 0.005030  train_dp 0.586743  valid_dp 0.584957 reg_loss 69.206019
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:05:53
run time  0:01:45.161654
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_1/forward_1_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522495
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:05:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f54818eab50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 40, '_step_count': 41, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.532632 valid_loss:0.529105 each epoch time:20.10063
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003666  valid_dq/boxsize 0.003651  train_dp 0.504408  valid_dp 0.501002 reg_loss 60.775379
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:07:35
run time  0:01:40.994144
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_1/backward_1_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522512
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:07:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0a985e2f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 45, '_step_count': 46, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.400125 valid_loss:0.395308 each epoch time:19.76081
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001987  valid_dq/boxsize 0.001964  train_dp 0.378884  valid_dp 0.374308 reg_loss 26.878881
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:09:17
run time  0:01:40.263573
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_1/backward_1_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522529
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:09:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8eb6200810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 50, '_step_count': 51, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.325130 valid_loss:0.331167 each epoch time:19.93991
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001369  valid_dq/boxsize 0.001398  train_dp 0.307809  valid_dp 0.313477 reg_loss 24.734364
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:10:58
run time  0:01:40.072325
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_1/backward_1_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522546
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:10:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4ab283d250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 55, '_step_count': 56, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.460088 valid_loss:0.458191 each epoch time:20.23350
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002761  valid_dq/boxsize 0.002758  train_dp 0.435392  valid_dp 0.433525 reg_loss 51.344363
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:12:40
run time  0:01:40.699489
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_1/backward_1_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522563
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:12:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7191594350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 60, '_step_count': 61, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.318555 valid_loss:0.324675 each epoch time:20.16836
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001354  valid_dq/boxsize 0.001384  train_dp 0.301423  valid_dp 0.307166 reg_loss 25.132550
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:14:22
run time  0:01:40.935895
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_1/backward_1_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522579
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:14:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f35e2630310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 65, '_step_count': 66, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.386307 valid_loss:0.381725 each epoch time:20.07900
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001957  valid_dq/boxsize 0.001936  train_dp 0.365389  valid_dp 0.361032 reg_loss 28.233022
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:16:05
run time  0:01:40.563869
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_1/backward_1_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522596
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:16:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc601255490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 70, '_step_count': 71, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.312604 valid_loss:0.318842 each epoch time:20.12072
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001345  valid_dq/boxsize 0.001376  train_dp 0.295586  valid_dp 0.301437 reg_loss 25.636879
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:17:45
run time  0:01:38.502038
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_1/backward_1_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522618
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:17:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcbb09abf10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 75, '_step_count': 76, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.380691 valid_loss:0.376212 each epoch time:20.20793
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001949  valid_dq/boxsize 0.001928  train_dp 0.359856  valid_dp 0.355599 reg_loss 28.576264
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:19:29
run time  0:01:41.651636
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_2/forward_2_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522634
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:19:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f94bf58af90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 80, '_step_count': 81, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.307548 valid_loss:0.313831 each epoch time:20.29013
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001339  valid_dq/boxsize 0.001370  train_dp 0.290616  valid_dp 0.296506 reg_loss 25.832245
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:21:13
run time  0:01:40.781322
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_2/forward_2_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522651
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:21:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f388d131b50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 85, '_step_count': 86, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.442585 valid_loss:0.440627 each epoch time:20.69993
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002730  valid_dq/boxsize 0.002726  train_dp 0.418169  valid_dp 0.416247 reg_loss 51.994926
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:22:56
run time  0:01:42.211680
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_2/forward_2_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522669
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:22:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feb941dc110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 90, '_step_count': 91, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.303181 valid_loss:0.309380 each epoch time:19.98712
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001329  valid_dq/boxsize 0.001360  train_dp 0.286371  valid_dp 0.292175 reg_loss 25.515190
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:24:37
run time  0:01:39.358225
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_2/forward_2_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522686
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:24:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7facecd4f6d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 95, '_step_count': 96, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.370685 valid_loss:0.366349 each epoch time:20.38895
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001930  valid_dq/boxsize 0.001910  train_dp 0.350049  valid_dp 0.345929 reg_loss 28.170723
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:26:19
run time  0:01:40.526132
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_2/forward_2_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522702
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:26:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff9bff38050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 100, '_step_count': 101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.494704 valid_loss:0.491127 each epoch time:19.97124
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003576  valid_dq/boxsize 0.003559  train_dp 0.467173  valid_dp 0.463726 reg_loss 61.729279
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:28:01
run time  0:01:40.945481
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_2/forward_2_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522718
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:28:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5aabaa0290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 105, '_step_count': 106, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.566852 valid_loss:0.564843 each epoch time:20.76333
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.004870  valid_dq/boxsize 0.004864  train_dp 0.535254  valid_dp 0.533282 reg_loss 65.411455
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:29:45
run time  0:01:43.208347
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_2/forward_2_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522736
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:29:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1fc4370d90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 110, '_step_count': 111, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.485029 valid_loss:0.481668 each epoch time:19.97161
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003516  valid_dq/boxsize 0.003501  train_dp 0.457966  valid_dp 0.454718 reg_loss 57.629240
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:31:30
run time  0:01:40.922513
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_2/backward_2_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522756
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:31:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7face5cb3b50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 115, '_step_count': 116, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.361871 valid_loss:0.357578 each epoch time:19.92226
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001881  valid_dq/boxsize 0.001861  train_dp 0.341767  valid_dp 0.337682 reg_loss 25.053592
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:33:11
run time  0:01:40.004021
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_2/backward_2_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522775
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:33:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f29671b25d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 120, '_step_count': 121, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.293015 valid_loss:0.298569 each epoch time:20.25940
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001293  valid_dq/boxsize 0.001324  train_dp 0.276660  valid_dp 0.281822 reg_loss 23.367379
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:34:53
run time  0:01:41.253599
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_2/backward_2_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522791
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:34:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd1ae345710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 125, '_step_count': 126, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.420625 valid_loss:0.418762 each epoch time:19.94785
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002656  valid_dq/boxsize 0.002653  train_dp 0.396869  valid_dp 0.395038 reg_loss 47.454375
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:36:34
run time  0:01:39.644658
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_2/backward_2_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522808
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:36:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8aa3f88410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 130, '_step_count': 131, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.288695 valid_loss:0.294349 each epoch time:19.79747
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001293  valid_dq/boxsize 0.001324  train_dp 0.272340  valid_dp 0.277599 reg_loss 23.487582
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:38:16
run time  0:01:40.967042
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_2/backward_2_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522825
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:38:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2bda3422d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 135, '_step_count': 136, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.352988 valid_loss:0.348902 each epoch time:20.43248
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001886  valid_dq/boxsize 0.001867  train_dp 0.332831  valid_dp 0.328948 reg_loss 25.757850
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:39:58
run time  0:01:40.364988
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_2/backward_2_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522841
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:40:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f878df26210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 140, '_step_count': 141, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.284652 valid_loss:0.290447 each epoch time:19.98579
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001297  valid_dq/boxsize 0.001328  train_dp 0.268248  valid_dp 0.273647 reg_loss 23.666909
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:41:42
run time  0:01:40.515843
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_2/backward_2_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522859
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:41:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f80e2138d90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 145, '_step_count': 146, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.349383 valid_loss:0.345355 each epoch time:20.07468
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001888  valid_dq/boxsize 0.001869  train_dp 0.329200  valid_dp 0.325374 reg_loss 25.762680
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:43:24
run time  0:01:40.119478
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_3/forward_3_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522877
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:43:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdab61ee090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 150, '_step_count': 151, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.281198 valid_loss:0.287058 each epoch time:19.77617
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001298  valid_dq/boxsize 0.001329  train_dp 0.264778  valid_dp 0.270244 reg_loss 23.577538
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:45:06
run time  0:01:40.764712
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_3/forward_3_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522905
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:45:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f63f5047890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 155, '_step_count': 156, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.409700 valid_loss:0.407835 each epoch time:19.86872
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002654  valid_dq/boxsize 0.002649  train_dp 0.385962  valid_dp 0.384143 reg_loss 46.998867
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:46:48
run time  0:01:41.159675
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_3/forward_3_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522921
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:46:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2a0a541310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 160, '_step_count': 161, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.278168 valid_loss:0.283950 each epoch time:19.81477
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001293  valid_dq/boxsize 0.001323  train_dp 0.261819  valid_dp 0.267209 reg_loss 23.087997
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:48:29
run time  0:01:40.188998
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_3/forward_3_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522938
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:48:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f82c988e310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 165, '_step_count': 166, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.342432 valid_loss:0.338474 each epoch time:19.76540
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001879  valid_dq/boxsize 0.001861  train_dp 0.322341  valid_dp 0.318582 reg_loss 25.001080
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:50:11
run time  0:01:40.725846
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_3/forward_3_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522955
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:50:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbc56e851d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 170, '_step_count': 171, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.461512 valid_loss:0.458163 each epoch time:20.15309
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003484  valid_dq/boxsize 0.003468  train_dp 0.434693  valid_dp 0.431463 reg_loss 56.463280
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:51:53
run time  0:01:40.434285
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_3/forward_3_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522971
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:51:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f95b8ea66d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 175, '_step_count': 176, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.531869 valid_loss:0.529770 each epoch time:20.28621
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.004748  valid_dq/boxsize 0.004738  train_dp 0.501062  valid_dp 0.499024 reg_loss 59.740392
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:53:37
run time  0:01:42.847176
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_3/forward_3_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  522988
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:53:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe0735ce1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 180, '_step_count': 181, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.453721 valid_loss:0.450601 each epoch time:20.15840
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003427  valid_dq/boxsize 0.003413  train_dp 0.427343  valid_dp 0.424329 reg_loss 52.801633
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:55:18
run time  0:01:40.283669
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_3/backward_3_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523004
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:55:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9529d36290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 185, '_step_count': 186, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.336057 valid_loss:0.332038 each epoch time:19.70199
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001832  valid_dq/boxsize 0.001814  train_dp 0.316476  valid_dp 0.312649 reg_loss 22.394833
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:57:00
run time  0:01:40.683274
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_3/backward_3_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523021
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:57:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f99c4e7e350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 190, '_step_count': 191, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.270563 valid_loss:0.275751 each epoch time:20.60301
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001264  valid_dq/boxsize 0.001295  train_dp 0.254575  valid_dp 0.259376 reg_loss 20.999938
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:58:43
run time  0:01:41.072694
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_3/backward_3_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523038
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:58:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe3149bfa50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 195, '_step_count': 196, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.392886 valid_loss:0.391089 each epoch time:19.91586
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002596  valid_dq/boxsize 0.002591  train_dp 0.369670  valid_dp 0.367914 reg_loss 42.991762
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:00:25
run time  0:01:41.086670
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_3/backward_3_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523054
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:00:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff4efccd5d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 200, '_step_count': 201, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.266818 valid_loss:0.272163 each epoch time:20.35713
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001268  valid_dq/boxsize 0.001299  train_dp 0.250775  valid_dp 0.255737 reg_loss 20.988072
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:02:08
run time  0:01:41.365172
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_3/backward_3_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523071
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:02:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdda4d19bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 205, '_step_count': 206, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.328451 valid_loss:0.324588 each epoch time:20.53606
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001847  valid_dq/boxsize 0.001829  train_dp 0.308708  valid_dp 0.305038 reg_loss 22.765839
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:03:52
run time  0:01:41.872146
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_3/backward_3_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523087
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:03:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f83fc07f4d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 210, '_step_count': 211, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.263445 valid_loss:0.268964 each epoch time:20.20126
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001274  valid_dq/boxsize 0.001304  train_dp 0.247333  valid_dp 0.252474 reg_loss 20.980676
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:05:34
run time  0:01:41.416827
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_3/backward_3_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523105
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:05:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f11b29a51d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 215, '_step_count': 216, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.325506 valid_loss:0.321661 each epoch time:19.83599
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001849  valid_dq/boxsize 0.001831  train_dp 0.305741  valid_dp 0.302091 reg_loss 22.610508
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:07:17
run time  0:01:39.915024
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_4/forward_4_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523121
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:07:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9943e551d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 220, '_step_count': 221, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.260692 valid_loss:0.266257 each epoch time:20.16612
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001274  valid_dq/boxsize 0.001304  train_dp 0.244574  valid_dp 0.249767 reg_loss 20.741539
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:09:00
run time  0:01:41.445946
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_4/forward_4_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523138
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:09:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9e03196e90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 225, '_step_count': 226, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.383776 valid_loss:0.381988 each epoch time:20.31876
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002594  valid_dq/boxsize 0.002589  train_dp 0.360574  valid_dp 0.358836 reg_loss 42.132822
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:10:43
run time  0:01:42.218589
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_4/forward_4_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523155
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:10:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f71a0cb5190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 230, '_step_count': 231, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.258218 valid_loss:0.263698 each epoch time:19.81643
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001269  valid_dq/boxsize 0.001298  train_dp 0.242170  valid_dp 0.247279 reg_loss 20.278191
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:12:24
run time  0:01:39.588433
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_4/forward_4_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523171
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:12:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc9395c1890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 235, '_step_count': 236, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.319756 valid_loss:0.315916 each epoch time:19.79131
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001839  valid_dq/boxsize 0.001821  train_dp 0.300093  valid_dp 0.296447 reg_loss 21.795190
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:14:05
run time  0:01:40.062501
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_4/forward_4_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523188
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:14:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feb4c889510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 240, '_step_count': 241, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.434360 valid_loss:0.431263 each epoch time:20.41413
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003402  valid_dq/boxsize 0.003388  train_dp 0.408168  valid_dp 0.405184 reg_loss 50.710035
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:15:48
run time  0:01:41.643463
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_4/forward_4_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523205
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:15:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa7fd2a5050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 245, '_step_count': 246, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.502858 valid_loss:0.500800 each epoch time:20.56694
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.004637  valid_dq/boxsize 0.004625  train_dp 0.472772  valid_dp 0.470789 reg_loss 53.549533
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:17:31
run time  0:01:42.342099
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_4/forward_4_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523227
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:17:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faa8b8f0f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 250, '_step_count': 251, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.427946 valid_loss:0.424991 each epoch time:20.52221
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003356  valid_dq/boxsize 0.003342  train_dp 0.402114  valid_dp 0.399264 reg_loss 47.786861
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:19:15
run time  0:01:42.088744
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_4/backward_4_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523244
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:19:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f19c9109cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 255, '_step_count': 256, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.314280 valid_loss:0.310298 each epoch time:19.59874
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001800  valid_dq/boxsize 0.001783  train_dp 0.295034  valid_dp 0.291235 reg_loss 19.832696
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:20:56
run time  0:01:40.123811
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_4/backward_4_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523260
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:20:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9122f53310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 260, '_step_count': 261, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.251395 valid_loss:0.256378 each epoch time:19.56872
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001247  valid_dq/boxsize 0.001276  train_dp 0.235619  valid_dp 0.240236 reg_loss 18.700779
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:22:36
run time  0:01:39.306602
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_4/backward_4_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523277
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:22:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f621afc0e10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 265, '_step_count': 266, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.369423 valid_loss:0.367681 each epoch time:20.12873
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002548  valid_dq/boxsize 0.002543  train_dp 0.346632  valid_dp 0.344936 reg_loss 39.000638
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:24:20
run time  0:01:40.336913
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_4/backward_4_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523294
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:24:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffa76ad2cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 270, '_step_count': 271, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.248410 valid_loss:0.253538 each epoch time:20.07588
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001250  valid_dq/boxsize 0.001279  train_dp 0.232592  valid_dp 0.237361 reg_loss 18.588016
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:26:02
run time  0:01:39.626107
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_4/backward_4_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523311
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:26:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1897a43290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 275, '_step_count': 276, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.307848 valid_loss:0.303996 each epoch time:20.02029
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001813  valid_dq/boxsize 0.001795  train_dp 0.288465  valid_dp 0.284804 reg_loss 19.910469
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:27:44
run time  0:01:39.609231
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_4/backward_4_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523328
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:27:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f88f2f124d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 280, '_step_count': 281, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.245955 valid_loss:0.251187 each epoch time:19.90867
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001252  valid_dq/boxsize 0.001279  train_dp 0.230123  valid_dp 0.235003 reg_loss 18.410446
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:29:27
run time  0:01:40.495405
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_4/backward_4_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523345
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:29:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa256ac4c10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 285, '_step_count': 286, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.305463 valid_loss:0.301607 each epoch time:19.68671
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001810  valid_dq/boxsize 0.001792  train_dp 0.286111  valid_dp 0.282449 reg_loss 19.602139
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:31:11
run time  0:01:39.712495
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_5/forward_5_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523364
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:31:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3ae54cd2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 290, '_step_count': 291, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.243867 valid_loss:0.249100 each epoch time:20.11052
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001248  valid_dq/boxsize 0.001276  train_dp 0.228076  valid_dp 0.232960 reg_loss 18.102828
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:32:53
run time  0:01:41.357182
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_5/forward_5_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523381
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:32:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f16af1ea250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 295, '_step_count': 296, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.361468 valid_loss:0.359765 each epoch time:19.59208
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002535  valid_dq/boxsize 0.002529  train_dp 0.338795  valid_dp 0.337142 reg_loss 37.720367
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:34:36
run time  0:01:39.396296
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_5/forward_5_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523398
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:34:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2e73c4a390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 300, '_step_count': 301, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.241843 valid_loss:0.246997 each epoch time:20.37666
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001243  valid_dq/boxsize 0.001270  train_dp 0.226122  valid_dp 0.230929 reg_loss 17.718580
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:36:19
run time  0:01:42.145728
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_5/forward_5_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523418
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:36:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc1f5d3f890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 305, '_step_count': 306, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.300731 valid_loss:0.296864 each epoch time:20.06892
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001798  valid_dq/boxsize 0.001780  train_dp 0.281511  valid_dp 0.277840 reg_loss 18.820180
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:38:03
run time  0:01:40.585494
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_5/forward_5_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523436
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:38:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6e8dc7d190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 310, '_step_count': 311, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.410766 valid_loss:0.407844 each epoch time:20.38146
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003324  valid_dq/boxsize 0.003310  train_dp 0.385174  valid_dp 0.382366 reg_loss 45.351500
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:39:48
run time  0:01:40.849841
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_5/forward_5_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523454
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:39:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f21f55f6050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 315, '_step_count': 316, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.477423 valid_loss:0.475387 each epoch time:20.16582
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.004534  valid_dq/boxsize 0.004521  train_dp 0.448005  valid_dp 0.446052 reg_loss 47.979021
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:41:31
run time  0:01:41.925594
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_5/forward_5_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523470
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:41:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc2245a3410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 320, '_step_count': 321, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.405722 valid_loss:0.402928 each epoch time:20.31925
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003290  valid_dq/boxsize 0.003276  train_dp 0.380399  valid_dp 0.377711 reg_loss 43.252517
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:43:13
run time  0:01:40.582984
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_5/backward_5_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523488
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:43:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4a7a586350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 325, '_step_count': 326, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.295829 valid_loss:0.291855 each epoch time:19.56874
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001770  valid_dq/boxsize 0.001753  train_dp 0.276904  valid_dp 0.273118 reg_loss 17.466437
memory usage : 3.6  at e= 5
end date/time : 20211025, 16:44:53
run time  0:01:38.288715
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_5/backward_5_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523506
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:44:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbd9f9a7190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 330, '_step_count': 331, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.235819 valid_loss:0.240662 each epoch time:19.89239
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001227  valid_dq/boxsize 0.001254  train_dp 0.220301  valid_dp 0.224803 reg_loss 16.616176
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:46:34
run time  0:01:40.085775
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_5/backward_5_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523524
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:46:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f264b42bfd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 335, '_step_count': 336, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.349486 valid_loss:0.347773 each epoch time:19.80993
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002497  valid_dq/boxsize 0.002491  train_dp 0.327155  valid_dp 0.325491 reg_loss 35.281779
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:48:16
run time  0:01:40.521781
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_5/backward_5_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523540
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:48:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fef3240a390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 340, '_step_count': 341, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.233740 valid_loss:0.238646 each epoch time:19.80960
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001226  valid_dq/boxsize 0.001252  train_dp 0.218234  valid_dp 0.222805 reg_loss 16.394780
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:49:56
run time  0:01:39.042359
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_5/backward_5_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523557
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:49:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc025217e10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 345, '_step_count': 346, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.290902 valid_loss:0.287033 each epoch time:20.43332
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001773  valid_dq/boxsize 0.001755  train_dp 0.271947  valid_dp 0.268276 reg_loss 17.228302
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:51:39
run time  0:01:41.196773
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_5/backward_5_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523574
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:51:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff487a06450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 350, '_step_count': 351, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.231960 valid_loss:0.236898 each epoch time:20.09015
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001223  valid_dq/boxsize 0.001249  train_dp 0.216490  valid_dp 0.221099 reg_loss 16.154909
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:53:19
run time  0:01:38.830016
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_5/backward_5_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523591
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:53:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb3ea2cef10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 355, '_step_count': 356, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.288989 valid_loss:0.285135 each epoch time:19.91043
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001767  valid_dq/boxsize 0.001749  train_dp 0.270094  valid_dp 0.266439 reg_loss 16.911718
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:54:59
run time  0:01:39.680451
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_6/forward_6_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523608
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:55:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fabaaf5d1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 360, '_step_count': 361, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.230318 valid_loss:0.235243 each epoch time:19.71897
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001218  valid_dq/boxsize 0.001244  train_dp 0.214909  valid_dp 0.219506 reg_loss 15.884613
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:56:43
run time  0:01:40.797558
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_6/forward_6_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523625
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:56:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9c4b06c150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 365, '_step_count': 366, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.342851 valid_loss:0.341148 each epoch time:20.22612
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002475  valid_dq/boxsize 0.002469  train_dp 0.320712  valid_dp 0.319060 reg_loss 33.973596
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:58:25
run time  0:01:41.269606
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_6/forward_6_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523642
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:58:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3523193bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 370, '_step_count': 371, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.228664 valid_loss:0.233533 each epoch time:19.02962
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001213  valid_dq/boxsize 0.001239  train_dp 0.213324  valid_dp 0.217866 reg_loss 15.596429
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:00:04
run time  0:01:38.020103
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_6/forward_6_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523659
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:00:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6485159b10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 375, '_step_count': 376, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.285145 valid_loss:0.281313 each epoch time:19.94158
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001754  valid_dq/boxsize 0.001735  train_dp 0.266392  valid_dp 0.262761 reg_loss 16.299008
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:01:44
run time  0:01:38.688418
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_6/forward_6_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523676
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:01:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f141e61e2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 380, '_step_count': 381, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.390883 valid_loss:0.388219 each epoch time:20.34939
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003249  valid_dq/boxsize 0.003234  train_dp 0.365874  valid_dp 0.363325 reg_loss 40.766950
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:03:28
run time  0:01:42.388093
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_6/forward_6_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523693
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:03:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6f8c381390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 385, '_step_count': 386, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.455712 valid_loss:0.453667 each epoch time:20.53366
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.004437  valid_dq/boxsize 0.004424  train_dp 0.426919  valid_dp 0.424959 reg_loss 43.378882
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:05:13
run time  0:01:43.461335
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_6/forward_6_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523709
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:05:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0f9954b150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 390, '_step_count': 391, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.386807 valid_loss:0.384276 each epoch time:20.66355
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003223  valid_dq/boxsize 0.003209  train_dp 0.362000  valid_dp 0.359576 reg_loss 39.314982
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:06:56
run time  0:01:41.369045
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_6/backward_6_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523726
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:06:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbaef756e90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 395, '_step_count': 396, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.280750 valid_loss:0.276889 each epoch time:20.23462
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001734  valid_dq/boxsize 0.001716  train_dp 0.262211  valid_dp 0.258544 reg_loss 15.450073
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:08:37
run time  0:01:40.651460
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_6/backward_6_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523743
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:08:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc4f087ec90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 400, '_step_count': 401, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.223592 valid_loss:0.228238 each epoch time:20.14540
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001199  valid_dq/boxsize 0.001224  train_dp 0.208431  valid_dp 0.212755 reg_loss 14.752926
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:10:19
run time  0:01:40.351193
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_6/backward_6_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523760
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:10:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1089e3d710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 405, '_step_count': 406, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.332834 valid_loss:0.331135 each epoch time:20.63190
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002440  valid_dq/boxsize 0.002434  train_dp 0.311009  valid_dp 0.309361 reg_loss 32.107020
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:12:06
run time  0:01:42.827534
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_6/backward_6_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523777
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:12:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f96940d7650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 410, '_step_count': 411, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.221982 valid_loss:0.226630 each epoch time:19.60759
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001195  valid_dq/boxsize 0.001221  train_dp 0.206861  valid_dp 0.211191 reg_loss 14.520135
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:13:47
run time  0:01:39.735316
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_6/backward_6_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523795
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:13:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdd4fb68e10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 415, '_step_count': 416, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.276929 valid_loss:0.273166 each epoch time:20.32253
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001730  valid_dq/boxsize 0.001711  train_dp 0.258436  valid_dp 0.254877 reg_loss 15.110860
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:15:31
run time  0:01:40.868119
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_6/backward_6_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523812
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:15:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3094e4f450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 420, '_step_count': 421, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.220521 valid_loss:0.225184 each epoch time:20.97199
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001191  valid_dq/boxsize 0.001216  train_dp 0.205455  valid_dp 0.209802 reg_loss 14.303763
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:17:15
run time  0:01:42.807199
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_6/backward_6_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523832
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:17:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f07fc25d410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 425, '_step_count': 426, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.275313 valid_loss:0.271576 each epoch time:20.18698
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001724  valid_dq/boxsize 0.001704  train_dp 0.256888  valid_dp 0.253354 reg_loss 14.873171
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:19:00
run time  0:01:41.270477
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_7/forward_7_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523849
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:19:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0cb22d9f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 430, '_step_count': 431, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.219132 valid_loss:0.223791 each epoch time:20.39198
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001186  valid_dq/boxsize 0.001211  train_dp 0.204131  valid_dp 0.208475 reg_loss 14.096497
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:20:44
run time  0:01:41.604748
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_7/forward_7_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523865
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:20:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f514d154310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 435, '_step_count': 436, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.327221 valid_loss:0.325544 each epoch time:20.18478
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002417  valid_dq/boxsize 0.002411  train_dp 0.305605  valid_dp 0.303981 reg_loss 31.058345
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:22:27
run time  0:01:41.964502
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_7/forward_7_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523881
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:22:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f925ba803d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 440, '_step_count': 441, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.217720 valid_loss:0.222344 each epoch time:20.12591
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001181  valid_dq/boxsize 0.001206  train_dp 0.202784  valid_dp 0.207093 reg_loss 13.894924
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:24:08
run time  0:01:40.170947
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_7/forward_7_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523898
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:24:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc8daef6690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 445, '_step_count': 446, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.272061 valid_loss:0.268337 each epoch time:20.03861
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001710  valid_dq/boxsize 0.001691  train_dp 0.253775  valid_dp 0.250256 reg_loss 14.439520
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:25:50
run time  0:01:40.269146
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_7/forward_7_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523915
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:25:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb298e099d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 450, '_step_count': 451, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.374012 valid_loss:0.371600 each epoch time:20.03719
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003177  valid_dq/boxsize 0.003162  train_dp 0.349556  valid_dp 0.347257 reg_loss 37.036352
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:27:33
run time  0:01:42.421299
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_7/forward_7_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523932
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:27:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa5574d00d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 455, '_step_count': 456, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.437104 valid_loss:0.435084 each epoch time:20.33931
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.004349  valid_dq/boxsize 0.004336  train_dp 0.408886  valid_dp 0.406950 reg_loss 39.700425
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:29:19
run time  0:01:43.359540
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_7/forward_7_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523948
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:29:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f748119f590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 460, '_step_count': 461, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.370577 valid_loss:0.368299 each epoch time:20.63449
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003156  valid_dq/boxsize 0.003142  train_dp 0.346280  valid_dp 0.344109 reg_loss 35.999492
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:31:03
run time  0:01:42.996568
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_7/backward_7_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523967
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:31:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f92192d6410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 465, '_step_count': 466, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.268188 valid_loss:0.264455 each epoch time:20.22974
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001695  valid_dq/boxsize 0.001676  train_dp 0.250072  valid_dp 0.246539 reg_loss 13.872294
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:32:46
run time  0:01:41.257397
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_7/backward_7_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  523984
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:32:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2924341410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 470, '_step_count': 471, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.213389 valid_loss:0.217850 each epoch time:19.97403
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001168  valid_dq/boxsize 0.001192  train_dp 0.198620  valid_dp 0.202769 reg_loss 13.271300
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:34:28
run time  0:01:40.959487
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_7/backward_7_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524002
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:34:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb09db5a350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 475, '_step_count': 476, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.318665 valid_loss:0.316999 each epoch time:20.46655
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002384  valid_dq/boxsize 0.002378  train_dp 0.297340  valid_dp 0.295730 reg_loss 29.583715
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:36:11
run time  0:01:41.957014
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_7/backward_7_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524022
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:36:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8799fa6a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 480, '_step_count': 481, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.212019 valid_loss:0.216489 each epoch time:19.84053
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001164  valid_dq/boxsize 0.001188  train_dp 0.197298  valid_dp 0.201458 reg_loss 13.083892
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:37:53
run time  0:01:40.590749
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_7/backward_7_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524040
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:37:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd7e266a450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 485, '_step_count': 486, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.265043 valid_loss:0.261370 each epoch time:20.63793
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001687  valid_dq/boxsize 0.001668  train_dp 0.247006  valid_dp 0.243539 reg_loss 13.523802
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:39:36
run time  0:01:41.306989
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_7/backward_7_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524057
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:39:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5b8b212490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 490, '_step_count': 491, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.210755 valid_loss:0.215244 each epoch time:19.79454
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001159  valid_dq/boxsize 0.001184  train_dp 0.196091  valid_dp 0.200272 reg_loss 12.922084
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:41:17
run time  0:01:40.409572
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_7/backward_7_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524074
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:41:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3401f71350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 495, '_step_count': 496, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.263644 valid_loss:0.259999 each epoch time:19.86486
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001681  valid_dq/boxsize 0.001662  train_dp 0.245673  valid_dp 0.242235 reg_loss 13.345410
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:42:58
run time  0:01:39.696557
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_8/forward_8_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524091
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:42:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6b15ece590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 500, '_step_count': 501, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.209554 valid_loss:0.214049 each epoch time:20.32125
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001154  valid_dq/boxsize 0.001179  train_dp 0.194952  valid_dp 0.199139 reg_loss 12.781747
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:44:40
run time  0:01:40.450145
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_8/forward_8_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524108
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:44:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2a858fa110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 505, '_step_count': 506, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.313866 valid_loss:0.312216 each epoch time:20.01340
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002362  valid_dq/boxsize 0.002355  train_dp 0.292742  valid_dp 0.291149 reg_loss 28.766424
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:46:24
run time  0:01:41.541298
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_8/forward_8_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524125
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:46:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6415a1f590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 510, '_step_count': 511, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.208348 valid_loss:0.212825 each epoch time:19.44594
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001150  valid_dq/boxsize 0.001174  train_dp 0.193807  valid_dp 0.197976 reg_loss 12.656229
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:48:05
run time  0:01:39.444730
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_8/forward_8_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524142
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:48:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fed16e82dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 515, '_step_count': 516, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.260876 valid_loss:0.257260 each epoch time:20.47196
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001669  valid_dq/boxsize 0.001650  train_dp 0.243033  valid_dp 0.239625 reg_loss 13.032235
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:49:49
run time  0:01:41.655862
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_8/forward_8_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524160
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:49:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdf77eab2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 520, '_step_count': 521, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.359568 valid_loss:0.357364 each epoch time:20.47123
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003111  valid_dq/boxsize 0.003097  train_dp 0.335617  valid_dp 0.333524 reg_loss 34.115185
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:51:33
run time  0:01:42.500967
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_8/forward_8_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524177
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:51:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc87797ad90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 525, '_step_count': 526, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.421173 valid_loss:0.419241 each epoch time:20.70929
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.004270  valid_dq/boxsize 0.004257  train_dp 0.393467  valid_dp 0.391617 reg_loss 36.899368
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:53:20
run time  0:01:43.356368
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_8/forward_8_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524194
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:53:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbfc066cd50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 530, '_step_count': 531, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.356633 valid_loss:0.354556 each epoch time:20.60518
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003095  valid_dq/boxsize 0.003081  train_dp 0.332810  valid_dp 0.330839 reg_loss 33.381331
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:55:05
run time  0:01:42.203865
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_8/backward_8_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524210
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:55:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f86f083c8d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 535, '_step_count': 536, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.257525 valid_loss:0.253938 each epoch time:19.81473
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001656  valid_dq/boxsize 0.001637  train_dp 0.239824  valid_dp 0.236440 reg_loss 12.608467
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:56:47
run time  0:01:40.436850
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_8/backward_8_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524229
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:56:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f79e7dba290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 540, '_step_count': 541, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.204658 valid_loss:0.209004 each epoch time:20.11521
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001138  valid_dq/boxsize 0.001162  train_dp 0.190268  valid_dp 0.194307 reg_loss 12.208717
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:58:30
run time  0:01:40.641228
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_8/backward_8_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524246
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:58:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0b814dee90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 545, '_step_count': 546, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.306557 valid_loss:0.304918 each epoch time:20.35331
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002332  valid_dq/boxsize 0.002326  train_dp 0.285696  valid_dp 0.284115 reg_loss 27.557329
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:00:13
run time  0:01:41.287532
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_8/backward_8_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524263
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:00:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f57c0dc1390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 550, '_step_count': 551, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.203475 valid_loss:0.207836 each epoch time:20.23131
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001134  valid_dq/boxsize 0.001158  train_dp 0.189132  valid_dp 0.193188 reg_loss 12.073901
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:01:55
run time  0:01:40.733269
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_8/backward_8_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524280
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:01:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f10ae027dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 555, '_step_count': 556, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.254853 valid_loss:0.251325 each epoch time:20.33737
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001648  valid_dq/boxsize 0.001628  train_dp 0.237238  valid_dp 0.233918 reg_loss 12.295261
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:03:39
run time  0:01:41.047917
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_8/backward_8_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524296
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:03:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcf7dda5e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 560, '_step_count': 561, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.202371 valid_loss:0.206758 each epoch time:19.90870
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001130  valid_dq/boxsize 0.001154  train_dp 0.188081  valid_dp 0.192164 reg_loss 11.953748
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:05:21
run time  0:01:40.694584
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_8/backward_8_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524313
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:05:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd8bcb00210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 565, '_step_count': 566, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.253635 valid_loss:0.250141 each epoch time:19.89246
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001642  valid_dq/boxsize 0.001623  train_dp 0.236079  valid_dp 0.232793 reg_loss 12.158163
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:07:03
run time  0:01:40.408843
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_9/forward_9_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524332
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:07:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc17f6d78d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 570, '_step_count': 571, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.201313 valid_loss:0.205714 each epoch time:20.81870
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001125  valid_dq/boxsize 0.001149  train_dp 0.187080  valid_dp 0.191176 reg_loss 11.851511
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:08:45
run time  0:01:41.113002
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_9/forward_9_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524349
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:08:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0cf090ccd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 575, '_step_count': 576, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.302403 valid_loss:0.300779 each epoch time:20.04655
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002312  valid_dq/boxsize 0.002306  train_dp 0.281722  valid_dp 0.280158 reg_loss 26.950676
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:10:30
run time  0:01:40.691922
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_9/forward_9_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524365
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:10:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff7d9bdec90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 580, '_step_count': 581, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.200248 valid_loss:0.204641 each epoch time:19.94527
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001121  valid_dq/boxsize 0.001145  train_dp 0.186069  valid_dp 0.190158 reg_loss 11.758325
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:12:12
run time  0:01:41.170569
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_9/forward_9_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524382
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:12:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5b26696d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 585, '_step_count': 586, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.251199 valid_loss:0.247736 each epoch time:19.65102
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001631  valid_dq/boxsize 0.001612  train_dp 0.233758  valid_dp 0.230505 reg_loss 11.913604
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:13:54
run time  0:01:39.912392
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_9/forward_9_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524400
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:13:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcd0e2cedd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 590, '_step_count': 591, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.347082 valid_loss:0.345044 each epoch time:20.16815
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003053  valid_dq/boxsize 0.003039  train_dp 0.323582  valid_dp 0.321651 reg_loss 31.844010
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:15:40
run time  0:01:41.775670
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_9/forward_9_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524416
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:15:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdb716cced0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 595, '_step_count': 596, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.407340 valid_loss:0.405522 each epoch time:20.71982
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.004200  valid_dq/boxsize 0.004188  train_dp 0.380084  valid_dp 0.378345 reg_loss 34.753578
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:17:24
run time  0:01:42.757086
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_9/forward_9_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524436
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:17:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4bc3533290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 600, '_step_count': 601, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.344498 valid_loss:0.342554 each epoch time:19.83201
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003039  valid_dq/boxsize 0.003026  train_dp 0.321105  valid_dp 0.319261 reg_loss 31.288322
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:19:06
run time  0:01:40.992988
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_9/backward_9_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524453
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:19:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f31d03b24d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 605, '_step_count': 606, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.248253 valid_loss:0.244820 each epoch time:20.38460
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001620  valid_dq/boxsize 0.001601  train_dp 0.230931  valid_dp 0.227703 reg_loss 11.569819
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:20:51
run time  0:01:41.754391
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_9/backward_9_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524472
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:20:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe4ef7a8890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 610, '_step_count': 611, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.197027 valid_loss:0.201322 each epoch time:20.11661
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001111  valid_dq/boxsize 0.001134  train_dp 0.182979  valid_dp 0.186972 reg_loss 11.397460
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:22:34
run time  0:01:41.584098
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_9/backward_9_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524489
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:22:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f571f25eb50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 615, '_step_count': 616, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.296012 valid_loss:0.294401 each epoch time:20.09314
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002286  valid_dq/boxsize 0.002279  train_dp 0.275564  valid_dp 0.274016 reg_loss 26.010266
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:24:16
run time  0:01:40.260805
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_9/backward_9_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524506
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:24:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbcb008dc10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 620, '_step_count': 621, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.195991 valid_loss:0.200304 each epoch time:20.05152
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001107  valid_dq/boxsize 0.001131  train_dp 0.181988  valid_dp 0.186000 reg_loss 11.292962
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:25:59
run time  0:01:41.376358
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_9/backward_9_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524523
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:26:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3aa0f25590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 625, '_step_count': 626, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.245919 valid_loss:0.242544 each epoch time:20.44527
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001613  valid_dq/boxsize 0.001593  train_dp 0.228680  valid_dp 0.225515 reg_loss 11.310498
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:27:41
run time  0:01:40.853846
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_9/backward_9_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524541
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:27:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb325208150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 630, '_step_count': 631, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.195019 valid_loss:0.199361 each epoch time:19.91628
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001103  valid_dq/boxsize 0.001127  train_dp 0.181065  valid_dp 0.185107 reg_loss 11.195909
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:29:23
run time  0:01:40.469117
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_9/backward_9_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524558
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:29:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe6c569d790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 635, '_step_count': 636, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.244848 valid_loss:0.241506 each epoch time:19.73177
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001608  valid_dq/boxsize 0.001588  train_dp 0.227662  valid_dp 0.224529 reg_loss 11.208978
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:31:04
run time  0:01:39.906045
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_10/forward_10_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524577
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:31:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd220e37150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 640, '_step_count': 641, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.194090 valid_loss:0.198453 each epoch time:20.31360
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001099  valid_dq/boxsize 0.001123  train_dp 0.180187  valid_dp 0.184249 reg_loss 11.118070
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:32:46
run time  0:01:41.096170
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_10/forward_10_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524596
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:32:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2d6fefe050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 645, '_step_count': 646, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.292397 valid_loss:0.290798 each epoch time:19.85223
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002268  valid_dq/boxsize 0.002261  train_dp 0.272110  valid_dp 0.270574 reg_loss 25.595931
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:34:28
run time  0:01:40.242514
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_10/forward_10_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524612
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:34:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5cb309cf50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 650, '_step_count': 651, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.193161 valid_loss:0.197527 each epoch time:20.32542
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001095  valid_dq/boxsize 0.001119  train_dp 0.179305  valid_dp 0.183370 reg_loss 11.051031
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:36:11
run time  0:01:41.934231
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_10/forward_10_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524630
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:36:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff08fae42d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 655, '_step_count': 656, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.242716 valid_loss:0.239405 each epoch time:20.09496
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001598  valid_dq/boxsize 0.001579  train_dp 0.225631  valid_dp 0.222530 reg_loss 11.028052
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:37:53
run time  0:01:39.209049
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_10/forward_10_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524647
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:37:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff371df3310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 660, '_step_count': 661, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.336177 valid_loss:0.334225 each epoch time:20.39052
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.003001  valid_dq/boxsize 0.002988  train_dp 0.313075  valid_dp 0.311223 reg_loss 30.081663
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:39:36
run time  0:01:42.454132
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_10/forward_10_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524664
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:39:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb2317b90d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 665, '_step_count': 666, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.395247 valid_loss:0.393562 each epoch time:21.04630
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.004140  valid_dq/boxsize 0.004128  train_dp 0.368386  valid_dp 0.366776 reg_loss 33.084349
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:41:22
run time  0:01:44.287959
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_10/forward_10_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524681
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:41:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa26e999fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 670, '_step_count': 671, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.333882 valid_loss:0.332021 each epoch time:20.11681
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002989  valid_dq/boxsize 0.002977  train_dp 0.310870  valid_dp 0.309104 reg_loss 29.631703
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:43:05
run time  0:01:41.814259
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_10/backward_10_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524697
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:43:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe872dcef90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 675, '_step_count': 676, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.240125 valid_loss:0.236847 each epoch time:20.34021
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001589  valid_dq/boxsize 0.001570  train_dp 0.223140  valid_dp 0.220067 reg_loss 10.743294
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:44:50
run time  0:01:44.030474
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_10/backward_10_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524718
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:44:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd4764d36d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 680, '_step_count': 681, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.190361 valid_loss:0.194639 each epoch time:20.52473
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001086  valid_dq/boxsize 0.001110  train_dp 0.176618  valid_dp 0.180599 reg_loss 10.747963
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:46:32
run time  0:01:40.613514
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_10/backward_10_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524735
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:46:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faca90263d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 685, '_step_count': 686, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.286789 valid_loss:0.285199 each epoch time:20.01627
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002245  valid_dq/boxsize 0.002238  train_dp 0.266709  valid_dp 0.265185 reg_loss 24.825083
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:48:15
run time  0:01:41.412527
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_10/backward_10_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524751
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:48:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f081cad3250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 690, '_step_count': 691, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.189445 valid_loss:0.193738 each epoch time:20.22090
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001083  valid_dq/boxsize 0.001107  train_dp 0.175744  valid_dp 0.179740 reg_loss 10.662546
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:49:58
run time  0:01:41.491709
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_10/backward_10_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524768
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:49:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2a803f5f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 695, '_step_count': 696, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.238076 valid_loss:0.234850 each epoch time:20.65392
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001581  valid_dq/boxsize 0.001562  train_dp 0.221170  valid_dp 0.218152 reg_loss 10.526418
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:51:40
run time  0:01:41.352825
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_10/backward_10_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524786
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:51:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faa09954790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 700, '_step_count': 701, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.188582 valid_loss:0.192899 each epoch time:19.75676
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001080  valid_dq/boxsize 0.001103  train_dp 0.174924  valid_dp 0.178945 reg_loss 10.591443
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:53:21
run time  0:01:39.682711
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_10/backward_10_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524803
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:53:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fecaa91f1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 705, '_step_count': 706, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.237127 valid_loss:0.233936 each epoch time:20.50142
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001577  valid_dq/boxsize 0.001558  train_dp 0.220266  valid_dp 0.217283 reg_loss 10.452755
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:55:04
run time  0:01:40.884303
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_11/forward_11_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524820
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:55:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7329eb5190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 710, '_step_count': 711, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.187756 valid_loss:0.192090 each epoch time:20.19131
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001076  valid_dq/boxsize 0.001100  train_dp 0.174143  valid_dp 0.178179 reg_loss 10.535491
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:56:46
run time  0:01:41.048735
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_11/forward_11_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524837
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:56:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff74e460150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 715, '_step_count': 716, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.283598 valid_loss:0.282017 each epoch time:20.08138
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002229  valid_dq/boxsize 0.002222  train_dp 0.263660  valid_dp 0.262145 reg_loss 24.520122
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:58:27
run time  0:01:40.356636
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_11/forward_11_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524853
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:58:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff543e73fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 720, '_step_count': 721, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.186929 valid_loss:0.191263 each epoch time:20.56702
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001073  valid_dq/boxsize 0.001096  train_dp 0.173358  valid_dp 0.177394 reg_loss 10.479658
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:00:15
run time  0:01:44.451442
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_11/forward_11_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524870
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:00:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbbee643cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 725, '_step_count': 726, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.235234 valid_loss:0.232080 each epoch time:20.05908
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001569  valid_dq/boxsize 0.001549  train_dp 0.218463  valid_dp 0.215515 reg_loss 10.310555
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:01:59
run time  0:01:42.227826
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_11/forward_11_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524888
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:02:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9772992850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 730, '_step_count': 731, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.326537 valid_loss:0.324671 each epoch time:20.26444
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002955  valid_dq/boxsize 0.002943  train_dp 0.303786  valid_dp 0.302014 reg_loss 28.638903
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:03:42
run time  0:01:41.404311
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_11/forward_11_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524904
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:03:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdd47c8b290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 735, '_step_count': 736, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.384550 valid_loss:0.383004 each epoch time:21.05217
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.004086  valid_dq/boxsize 0.004075  train_dp 0.358036  valid_dp 0.356562 reg_loss 31.738765
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:05:28
run time  0:01:43.765248
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_11/forward_11_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524921
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:05:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4b408ea550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 740, '_step_count': 741, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.324461 valid_loss:0.322680 each epoch time:20.07114
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002945  valid_dq/boxsize 0.002934  train_dp 0.301788  valid_dp 0.300097 reg_loss 28.238442
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:07:10
run time  0:01:41.574033
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_11/backward_11_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524940
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:07:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f13b32f1650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 745, '_step_count': 746, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.232917 valid_loss:0.229797 each epoch time:20.26324
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001561  valid_dq/boxsize 0.001542  train_dp 0.216232  valid_dp 0.213316 reg_loss 10.048929
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:08:52
run time  0:01:40.292592
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_11/backward_11_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524957
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:08:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8eb3ba9210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 750, '_step_count': 751, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.184452 valid_loss:0.188670 each epoch time:19.99503
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001065  valid_dq/boxsize 0.001088  train_dp 0.170979  valid_dp 0.174903 reg_loss 10.221593
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:10:35
run time  0:01:41.608159
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_11/backward_11_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524974
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:10:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb9fa12c890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 755, '_step_count': 756, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.278592 valid_loss:0.277023 each epoch time:20.71417
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002209  valid_dq/boxsize 0.002201  train_dp 0.258836  valid_dp 0.257336 reg_loss 23.872743
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:12:19
run time  0:01:42.279113
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_11/backward_11_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  524991
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:12:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f76a4c12a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 760, '_step_count': 761, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.183626 valid_loss:0.187862 each epoch time:20.29302
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001062  valid_dq/boxsize 0.001085  train_dp 0.170190  valid_dp 0.174132 reg_loss 10.153924
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:14:01
run time  0:01:40.310038
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_11/backward_11_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525009
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:14:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f35cb5eba90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 765, '_step_count': 766, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.231076 valid_loss:0.227999 each epoch time:19.59898
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001554  valid_dq/boxsize 0.001535  train_dp 0.214463  valid_dp 0.211591 reg_loss 9.877579
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:15:42
run time  0:01:39.830877
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_11/backward_11_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525026
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:15:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7eeaaab2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 770, '_step_count': 771, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.182844 valid_loss:0.187105 each epoch time:20.22285
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001059  valid_dq/boxsize 0.001082  train_dp 0.169447  valid_dp 0.173414 reg_loss 10.100876
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:17:24
run time  0:01:40.857907
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_11/backward_11_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525046
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:17:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbabf92f290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 775, '_step_count': 776, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.230218 valid_loss:0.227175 each epoch time:20.23102
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001550  valid_dq/boxsize 0.001531  train_dp 0.213644  valid_dp 0.210807 reg_loss 9.825941
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:19:08
run time  0:01:41.006735
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_12/forward_12_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525064
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:19:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff6be180410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 780, '_step_count': 781, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.182099 valid_loss:0.186375 each epoch time:20.20571
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001056  valid_dq/boxsize 0.001079  train_dp 0.168740  valid_dp 0.172723 reg_loss 10.061757
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:20:50
run time  0:01:40.944316
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_12/forward_12_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525081
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:20:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f52f76fc710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 785, '_step_count': 786, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.275737 valid_loss:0.274183 each epoch time:20.35311
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002195  valid_dq/boxsize 0.002187  train_dp 0.256104  valid_dp 0.254620 reg_loss 23.669246
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:22:34
run time  0:01:42.234362
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_12/forward_12_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525097
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:22:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7f4bc1ce50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 790, '_step_count': 791, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.181354 valid_loss:0.185631 each epoch time:19.87193
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001053  valid_dq/boxsize 0.001076  train_dp 0.168033  valid_dp 0.172016 reg_loss 10.014974
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:24:16
run time  0:01:40.094029
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_12/forward_12_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525113
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:24:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fee271fb2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 795, '_step_count': 796, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.228519 valid_loss:0.225503 each epoch time:20.29844
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001543  valid_dq/boxsize 0.001524  train_dp 0.212023  valid_dp 0.209212 reg_loss 9.716027
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:25:57
run time  0:01:40.048937
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_12/forward_12_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525129
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:25:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff523027550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 800, '_step_count': 801, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.317896 valid_loss:0.316169 each epoch time:20.30256
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002915  valid_dq/boxsize 0.002904  train_dp 0.295453  valid_dp 0.293813 reg_loss 27.430267
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:27:39
run time  0:01:40.787132
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_12/forward_12_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525146
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:27:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc21cedebd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 805, '_step_count': 806, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.375001 valid_loss:0.373550 each epoch time:21.05244
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.004039  valid_dq/boxsize 0.004029  train_dp 0.348794  valid_dp 0.347409 reg_loss 30.655910
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:29:24
run time  0:01:44.451476
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_12/forward_12_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525162
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:29:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff45671e810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 810, '_step_count': 811, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.316020 valid_loss:0.314374 each epoch time:20.58560
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002906  valid_dq/boxsize 0.002895  train_dp 0.293647  valid_dp 0.292084 reg_loss 27.069308
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:31:09
run time  0:01:41.392708
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_12/backward_12_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525181
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:31:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f01aeaf1cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 815, '_step_count': 816, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.226447 valid_loss:0.223454 each epoch time:20.60585
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001536  valid_dq/boxsize 0.001517  train_dp 0.210026  valid_dp 0.207237 reg_loss 9.486477
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:32:50
run time  0:01:39.622637
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_12/backward_12_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525202
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:32:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f08e25b0390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 820, '_step_count': 821, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.179148 valid_loss:0.183307 each epoch time:20.39548
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001046  valid_dq/boxsize 0.001069  train_dp 0.165913  valid_dp 0.169781 reg_loss 9.777190
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:34:33
run time  0:01:42.024101
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_12/backward_12_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525219
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:34:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5a1370a810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 825, '_step_count': 826, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.271250 valid_loss:0.269717 each epoch time:20.58671
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002177  valid_dq/boxsize 0.002169  train_dp 0.251780  valid_dp 0.250321 reg_loss 23.091090
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:36:15
run time  0:01:40.893619
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_12/backward_12_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525236
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:36:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f73bbeb8250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 830, '_step_count': 831, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.178401 valid_loss:0.182580 each epoch time:20.18746
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001044  valid_dq/boxsize 0.001067  train_dp 0.165200  valid_dp 0.169088 reg_loss 9.718220
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:37:57
run time  0:01:40.812349
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_12/backward_12_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525253
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:37:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4fef1e0c10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 835, '_step_count': 836, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.224794 valid_loss:0.221847 each epoch time:19.43444
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001530  valid_dq/boxsize 0.001511  train_dp 0.208439  valid_dp 0.205695 reg_loss 9.353913
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:39:37
run time  0:01:39.081246
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_12/backward_12_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525271
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:39:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc303824490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 840, '_step_count': 841, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.177694 valid_loss:0.181895 each epoch time:19.91263
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001041  valid_dq/boxsize 0.001064  train_dp 0.164528  valid_dp 0.168438 reg_loss 9.676793
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:41:20
run time  0:01:39.968368
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_12/backward_12_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525287
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:41:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2b58cf3a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 845, '_step_count': 846, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.224019 valid_loss:0.221106 each epoch time:20.61133
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001527  valid_dq/boxsize 0.001508  train_dp 0.207699  valid_dp 0.204990 reg_loss 9.317372
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:43:04
run time  0:01:42.778735
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_13/forward_13_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525303
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:43:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff1dc68c4d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 850, '_step_count': 851, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.177021 valid_loss:0.181236 each epoch time:20.04364
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001038  valid_dq/boxsize 0.001061  train_dp 0.163889  valid_dp 0.167813 reg_loss 9.644986
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:44:46
run time  0:01:40.824546
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_13/forward_13_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525320
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:44:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faff6d4b890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 855, '_step_count': 856, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.268690 valid_loss:0.267175 each epoch time:20.39686
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002165  valid_dq/boxsize 0.002156  train_dp 0.249328  valid_dp 0.247888 reg_loss 22.944803
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:46:28
run time  0:01:41.322693
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_13/forward_13_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525337
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:46:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f16c1e88190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 860, '_step_count': 861, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.176349 valid_loss:0.180566 each epoch time:19.79300
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001036  valid_dq/boxsize 0.001059  train_dp 0.163249  valid_dp 0.167175 reg_loss 9.600247
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:48:11
run time  0:01:40.890820
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_13/forward_13_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525355
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:48:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f76e0a311d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 865, '_step_count': 866, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.222492 valid_loss:0.219606 each epoch time:20.46702
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001520  valid_dq/boxsize 0.001501  train_dp 0.206242  valid_dp 0.203558 reg_loss 9.233821
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:49:52
run time  0:01:40.711253
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_13/forward_13_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525373
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:49:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7c87f42510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 870, '_step_count': 871, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.310142 valid_loss:0.308584 each epoch time:20.23034
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002880  valid_dq/boxsize 0.002869  train_dp 0.287975  valid_dp 0.286497 reg_loss 26.369502
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:51:37
run time  0:01:40.751523
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_13/forward_13_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525389
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:51:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3bb592f510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 875, '_step_count': 876, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.366448 valid_loss:0.365088 each epoch time:20.70942
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.003997  valid_dq/boxsize 0.003987  train_dp 0.340514  valid_dp 0.339217 reg_loss 29.684601
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:53:22
run time  0:01:43.704261
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_13/forward_13_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525406
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:53:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5d4bc927d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 880, '_step_count': 881, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.308422 valid_loss:0.306961 each epoch time:20.61147
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002872  valid_dq/boxsize 0.002861  train_dp 0.286316  valid_dp 0.284934 reg_loss 26.035637
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:55:06
run time  0:01:41.462423
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_13/backward_13_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525424
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:55:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe3dcb004d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 885, '_step_count': 886, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.220629 valid_loss:0.217759 each epoch time:20.80578
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001514  valid_dq/boxsize 0.001495  train_dp 0.204445  valid_dp 0.201775 reg_loss 9.026336
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:56:49
run time  0:01:41.903592
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_13/backward_13_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525441
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:56:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f05a3cb9750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 890, '_step_count': 891, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.174364 valid_loss:0.178463 each epoch time:20.38597
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001030  valid_dq/boxsize 0.001052  train_dp 0.161340  valid_dp 0.165151 reg_loss 9.377091
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:58:31
run time  0:01:41.200713
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_13/backward_13_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525457
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:58:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0482c51250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 895, '_step_count': 896, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.264629 valid_loss:0.263099 each epoch time:20.37761
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002149  valid_dq/boxsize 0.002140  train_dp 0.245412  valid_dp 0.243960 reg_loss 22.440800
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:00:13
run time  0:01:40.832236
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_13/backward_13_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525474
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:00:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8b15156050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 900, '_step_count': 901, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.173678 valid_loss:0.177799 each epoch time:20.08389
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001027  valid_dq/boxsize 0.001050  train_dp 0.160682  valid_dp 0.164516 reg_loss 9.326976
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:01:58
run time  0:01:40.999038
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_13/backward_13_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525491
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:02:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6b7cb233d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 905, '_step_count': 906, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.219128 valid_loss:0.216298 each epoch time:20.16597
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001509  valid_dq/boxsize 0.001490  train_dp 0.203000  valid_dp 0.200372 reg_loss 8.918792
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:03:42
run time  0:01:41.556529
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_13/backward_13_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525509
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:03:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd9c92e3e10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 910, '_step_count': 911, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.173030 valid_loss:0.177172 each epoch time:20.99139
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001025  valid_dq/boxsize 0.001048  train_dp 0.160065  valid_dp 0.163920 reg_loss 9.293921
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:05:25
run time  0:01:41.741749
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_13/backward_13_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525525
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:05:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbbba632790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 915, '_step_count': 916, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.218422 valid_loss:0.215627 each epoch time:20.16247
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001506  valid_dq/boxsize 0.001487  train_dp 0.202325  valid_dp 0.199731 reg_loss 8.892541
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:07:08
run time  0:01:41.707233
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_14/forward_14_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525542
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:07:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff1f3f39150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 920, '_step_count': 921, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.172415 valid_loss:0.176570 each epoch time:20.76670
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001023  valid_dq/boxsize 0.001045  train_dp 0.159481  valid_dp 0.163347 reg_loss 9.267892
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:08:54
run time  0:01:42.662441
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_14/forward_14_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525559
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:08:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdc85d75550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 925, '_step_count': 926, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.262300 valid_loss:0.260775 each epoch time:20.11952
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002138  valid_dq/boxsize 0.002129  train_dp 0.243176  valid_dp 0.241731 reg_loss 22.346068
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:10:36
run time  0:01:40.980707
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_14/forward_14_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525575
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:10:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe241b9a910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 930, '_step_count': 931, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.171801 valid_loss:0.175959 each epoch time:19.88463
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001020  valid_dq/boxsize 0.001043  train_dp 0.158895  valid_dp 0.162765 reg_loss 9.227525
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:12:18
run time  0:01:40.279859
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_14/forward_14_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525592
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:12:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffb4c99cc90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 935, '_step_count': 936, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.217040 valid_loss:0.214264 each epoch time:19.62310
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001500  valid_dq/boxsize 0.001481  train_dp 0.201004  valid_dp 0.198429 reg_loss 8.821747
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:13:58
run time  0:01:39.121262
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_14/forward_14_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525609
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:14:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f95f7bee390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 940, '_step_count': 941, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.303088 valid_loss:0.301728 each epoch time:20.53421
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002848  valid_dq/boxsize 0.002838  train_dp 0.281163  valid_dp 0.279879 reg_loss 25.433751
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:15:41
run time  0:01:41.539107
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_14/forward_14_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525625
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:15:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1ab74efb90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 945, '_step_count': 946, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.358694 valid_loss:0.357428 each epoch time:20.56948
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.003959  valid_dq/boxsize 0.003950  train_dp 0.333002  valid_dp 0.331797 reg_loss 28.833150
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:17:27
run time  0:01:44.309761
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_14/forward_14_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525646
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:17:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fae96b5f290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 950, '_step_count': 951, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.301512 valid_loss:0.300253 each epoch time:21.25678
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002841  valid_dq/boxsize 0.002831  train_dp 0.279642  valid_dp 0.278457 reg_loss 25.128084
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:19:12
run time  0:01:43.507790
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_14/backward_14_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525663
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:19:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5d7edde190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 955, '_step_count': 956, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.215355 valid_loss:0.212579 each epoch time:20.48753
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001495  valid_dq/boxsize 0.001476  train_dp 0.199375  valid_dp 0.196799 reg_loss 8.621488
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:20:56
run time  0:01:40.365541
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_14/backward_14_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525679
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:20:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb51dead890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 960, '_step_count': 961, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.170011 valid_loss:0.174061 each epoch time:20.17754
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001015  valid_dq/boxsize 0.001038  train_dp 0.157170  valid_dp 0.160934 reg_loss 9.018639
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:22:38
run time  0:01:40.892138
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_14/backward_14_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525696
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:22:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff59968f150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 965, '_step_count': 966, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.258611 valid_loss:0.257070 each epoch time:19.69986
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002124  valid_dq/boxsize 0.002115  train_dp 0.239616  valid_dp 0.238157 reg_loss 21.909917
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:24:20
run time  0:01:39.626531
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_14/backward_14_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525712
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:24:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2d824b9d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 970, '_step_count': 971, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.169385 valid_loss:0.173454 each epoch time:20.61730
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001013  valid_dq/boxsize 0.001036  train_dp 0.156570  valid_dp 0.160353 reg_loss 8.980493
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:26:05
run time  0:01:41.671819
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_14/backward_14_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525728
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:26:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe36e13b510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 975, '_step_count': 976, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.213992 valid_loss:0.211254 each epoch time:19.70822
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001490  valid_dq/boxsize 0.001471  train_dp 0.198065  valid_dp 0.195527 reg_loss 8.533308
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:27:47
run time  0:01:40.499398
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_14/backward_14_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525745
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:27:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe41b6e3050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 980, '_step_count': 981, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.168796 valid_loss:0.172884 each epoch time:20.38519
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001011  valid_dq/boxsize 0.001034  train_dp 0.156009  valid_dp 0.159810 reg_loss 8.955864
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:29:30
run time  0:01:41.735894
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_14/backward_14_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525762
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:29:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f19818d1b50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 985, '_step_count': 986, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.213350 valid_loss:0.210645 each epoch time:20.47627
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001487  valid_dq/boxsize 0.001469  train_dp 0.197450  valid_dp 0.194945 reg_loss 8.514644
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:31:13
run time  0:01:41.202829
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_15/forward_15_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525780
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:31:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7fcac6e650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 990, '_step_count': 991, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.168236 valid_loss:0.172338 each epoch time:20.18975
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001009  valid_dq/boxsize 0.001031  train_dp 0.155476  valid_dp 0.159291 reg_loss 8.934582
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:32:58
run time  0:01:41.103087
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_15/forward_15_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525797
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:33:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f57a1fa34d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 995, '_step_count': 996, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.256506 valid_loss:0.254984 each epoch time:20.04299
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002115  valid_dq/boxsize 0.002105  train_dp 0.237593  valid_dp 0.236154 reg_loss 21.836057
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:34:42
run time  0:01:40.290887
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_15/forward_15_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525816
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:34:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fba390264d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1000, '_step_count': 1001, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.167683 valid_loss:0.171793 each epoch time:20.22911
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001007  valid_dq/boxsize 0.001030  train_dp 0.154947  valid_dp 0.158771 reg_loss 8.901378
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:36:24
run time  0:01:40.718056
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_15/forward_15_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525833
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:36:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc4d979a0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1005, '_step_count': 1006, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.212108 valid_loss:0.209419 each epoch time:19.94067
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001482  valid_dq/boxsize 0.001464  train_dp 0.196261  valid_dp 0.193771 reg_loss 8.455336
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:38:06
run time  0:01:39.711281
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_15/forward_15_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525849
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:38:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2479aed450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1010, '_step_count': 1011, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.296724 valid_loss:0.295536 each epoch time:20.34069
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002820  valid_dq/boxsize 0.002811  train_dp 0.275017  valid_dp 0.273900 reg_loss 24.611117
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:39:48
run time  0:01:40.186867
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_15/forward_15_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525865
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:39:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5d7bf4ccd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1015, '_step_count': 1016, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.351729 valid_loss:0.350546 each epoch time:20.36346
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.003926  valid_dq/boxsize 0.003916  train_dp 0.326256  valid_dp 0.325132 reg_loss 28.081258
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:41:33
run time  0:01:44.121176
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_15/forward_15_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525882
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:41:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f89896aa690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1020, '_step_count': 1021, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.295306 valid_loss:0.294208 each epoch time:20.28763
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002813  valid_dq/boxsize 0.002804  train_dp 0.273649  valid_dp 0.272619 reg_loss 24.333164
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:43:15
run time  0:01:40.764676
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_15/backward_15_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525900
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:43:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7bffd9e310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1025, '_step_count': 1026, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.210611 valid_loss:0.207920 each epoch time:19.94235
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001459  train_dp 0.194813  valid_dp 0.192321 reg_loss 8.272022
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:44:58
run time  0:01:41.618680
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_15/backward_15_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525919
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:45:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa45ffe7710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1030, '_step_count': 1031, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.166101 valid_loss:0.170124 each epoch time:20.74815
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001002  valid_dq/boxsize 0.001025  train_dp 0.153422  valid_dp 0.157160 reg_loss 8.708909
memory usage : 3.6  at e= 5
end date/time : 20211025, 20:46:44
run time  0:01:43.371546
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_15/backward_15_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525938
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:46:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fab89a54f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1035, '_step_count': 1036, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.253222 valid_loss:0.251701 each epoch time:20.00899
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002102  valid_dq/boxsize 0.002092  train_dp 0.234424  valid_dp 0.232987 reg_loss 21.434343
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:48:25
run time  0:01:40.719269
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_15/backward_15_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525954
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:48:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f305a3d7a50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1040, '_step_count': 1041, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.165536 valid_loss:0.169586 each epoch time:20.40963
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.001001  valid_dq/boxsize 0.001023  train_dp 0.152879  valid_dp 0.156645 reg_loss 8.676691
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:50:09
run time  0:01:40.631535
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_15/backward_15_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525970
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:50:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feda2bad690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1045, '_step_count': 1046, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.209387 valid_loss:0.206723 each epoch time:20.45004
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001473  valid_dq/boxsize 0.001455  train_dp 0.193636  valid_dp 0.191170 reg_loss 8.200541
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:51:52
run time  0:01:40.998849
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_15/backward_15_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  525987
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:51:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcefd58aa10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1050, '_step_count': 1051, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.165003 valid_loss:0.169074 each epoch time:20.14897
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000999  valid_dq/boxsize 0.001021  train_dp 0.152372  valid_dp 0.156157 reg_loss 8.654732
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:53:37
run time  0:01:42.268093
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_15/backward_15_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526005
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:53:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fef7f217990>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1055, '_step_count': 1056, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.208808 valid_loss:0.206171 each epoch time:19.98302
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001471  valid_dq/boxsize 0.001453  train_dp 0.193081  valid_dp 0.190642 reg_loss 8.185877
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:55:21
run time  0:01:41.195565
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_16/forward_16_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526021
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:55:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f54e842b890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1060, '_step_count': 1061, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.164500 valid_loss:0.168588 each epoch time:19.69131
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000997  valid_dq/boxsize 0.001019  train_dp 0.151892  valid_dp 0.155695 reg_loss 8.635109
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:57:01
run time  0:01:39.230592
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_16/forward_16_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526038
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:57:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff037a87090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1065, '_step_count': 1066, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.251335 valid_loss:0.249852 each epoch time:19.98221
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002094  valid_dq/boxsize 0.002084  train_dp 0.232609  valid_dp 0.231212 reg_loss 21.387772
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:58:44
run time  0:01:41.433828
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_16/forward_16_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526056
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:58:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe2ed07edd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1070, '_step_count': 1071, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.163998 valid_loss:0.168102 each epoch time:20.02230
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000995  valid_dq/boxsize 0.001018  train_dp 0.151413  valid_dp 0.155231 reg_loss 8.605131
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:00:25
run time  0:01:40.203345
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_16/forward_16_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526073
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:00:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7e2bb6ed10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1075, '_step_count': 1076, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.207688 valid_loss:0.205059 each epoch time:20.34799
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001467  valid_dq/boxsize 0.001448  train_dp 0.192009  valid_dp 0.189577 reg_loss 8.130137
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:02:09
run time  0:01:42.157039
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_16/forward_16_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526090
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:02:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4a7bdea210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1080, '_step_count': 1081, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.291021 valid_loss:0.289956 each epoch time:20.38481
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002794  valid_dq/boxsize 0.002786  train_dp 0.269510  valid_dp 0.268512 reg_loss 23.888379
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:03:52
run time  0:01:41.007892
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_16/forward_16_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526107
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:03:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb65e76ce90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1085, '_step_count': 1086, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.345463 valid_loss:0.344345 each epoch time:20.67702
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.003895  valid_dq/boxsize 0.003886  train_dp 0.320188  valid_dp 0.319129 reg_loss 27.406704
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:05:39
run time  0:01:45.381544
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_16/forward_16_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526124
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:05:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4e7f4b4250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1090, '_step_count': 1091, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.289714 valid_loss:0.288733 each epoch time:19.88237
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002788  valid_dq/boxsize 0.002780  train_dp 0.268249  valid_dp 0.267334 reg_loss 23.610890
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:07:22
run time  0:01:40.026537
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_16/backward_16_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526141
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:07:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f70b736cd50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1095, '_step_count': 1096, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.206330 valid_loss:0.203703 each epoch time:20.64246
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001462  valid_dq/boxsize 0.001444  train_dp 0.190695  valid_dp 0.188265 reg_loss 7.945408
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:09:04
run time  0:01:41.568856
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_16/backward_16_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526158
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:09:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f211e834250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1100, '_step_count': 1101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.162567 valid_loss:0.166596 each epoch time:20.01636
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000991  valid_dq/boxsize 0.001013  train_dp 0.150032  valid_dp 0.153777 reg_loss 8.420309
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:10:48
run time  0:01:41.981384
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/backward_16/backward_16_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526175
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:10:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4af92e44d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1105, '_step_count': 1106, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.248340 valid_loss:0.246872 each epoch time:20.49786
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002082  valid_dq/boxsize 0.002072  train_dp 0.229720  valid_dp 0.228338 reg_loss 20.999875
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:12:32
run time  0:01:42.469574
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/backward_16/backward_16_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526193
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:12:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f506504bd50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1110, '_step_count': 1111, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.162051 valid_loss:0.166109 each epoch time:20.09513
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000989  valid_dq/boxsize 0.001012  train_dp 0.149537  valid_dp 0.153311 reg_loss 8.394182
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:14:13
run time  0:01:40.475333
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/backward_16/backward_16_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526210
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:14:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f06aac85d90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1115, '_step_count': 1116, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.205217 valid_loss:0.202621 each epoch time:20.01253
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001458  valid_dq/boxsize 0.001440  train_dp 0.189626  valid_dp 0.187225 reg_loss 7.890082
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:15:56
run time  0:01:41.446092
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/backward_16/backward_16_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526227
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:15:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f97a8dfffd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1120, '_step_count': 1121, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.161566 valid_loss:0.165648 each epoch time:20.45345
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000987  valid_dq/boxsize 0.001010  train_dp 0.149075  valid_dp 0.152872 reg_loss 8.376664
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:17:40
run time  0:01:42.094048
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/backward_16/backward_16_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526248
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:17:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f246d01c490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1125, '_step_count': 1126, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.204689 valid_loss:0.202125 each epoch time:20.46657
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001456  valid_dq/boxsize 0.001438  train_dp 0.189119  valid_dp 0.186751 reg_loss 7.878822
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:19:22
run time  0:01:40.261939
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/forward_17/forward_17_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526265
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:19:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7099d5e310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1130, '_step_count': 1131, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.161110 valid_loss:0.165213 each epoch time:20.54195
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000986  valid_dq/boxsize 0.001008  train_dp 0.148641  valid_dp 0.152459 reg_loss 8.361069
memory usage : 3.5  at e= 5
end date/time : 20211025, 21:21:04
run time  0:01:40.505313
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/forward_17/forward_17_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526282
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:21:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7effc7245890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1135, '_step_count': 1136, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.246635 valid_loss:0.245205 each epoch time:20.10394
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.002074  valid_dq/boxsize 0.002065  train_dp 0.228081  valid_dp 0.226740 reg_loss 20.968468
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:22:49
run time  0:01:41.030503
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/forward_17/forward_17_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526300
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:22:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fef4ddd9510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1140, '_step_count': 1141, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.160656 valid_loss:0.164776 each epoch time:20.54893
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000984  valid_dq/boxsize 0.001007  train_dp 0.148208  valid_dp 0.152041 reg_loss 8.333968
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:24:34
run time  0:01:43.301329
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/forward_17/forward_17_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526317
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:24:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5c49342250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1145, '_step_count': 1146, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.203679 valid_loss:0.201126 each epoch time:20.07847
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001452  valid_dq/boxsize 0.001434  train_dp 0.188153  valid_dp 0.185794 reg_loss 7.832413
memory usage : 3.5  at e= 5
end date/time : 20211025, 21:26:18
run time  0:01:41.531058
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/forward_17/forward_17_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526334
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:26:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa1ee2e55d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1150, '_step_count': 1151, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.285855 valid_loss:0.284860 each epoch time:19.92673
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002771  valid_dq/boxsize 0.002763  train_dp 0.264524  valid_dp 0.263592 reg_loss 23.234399
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:28:01
run time  0:01:41.514829
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/forward_17/forward_17_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526351
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:28:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd04ebfd250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1155, '_step_count': 1156, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.339769 valid_loss:0.338737 each epoch time:20.61372
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.003867  valid_dq/boxsize 0.003858  train_dp 0.314678  valid_dp 0.313701 reg_loss 26.773062
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:29:46
run time  0:01:43.855017
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/forward_17/forward_17_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526367
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:29:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa928de32d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1160, '_step_count': 1161, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.284656 valid_loss:0.283742 each epoch time:20.08376
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.002765  valid_dq/boxsize 0.002757  train_dp 0.263369  valid_dp 0.262517 reg_loss 22.949002
memory usage : 3.5  at e= 5
end date/time : 20211025, 21:31:29
run time  0:01:41.860341
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/backward_17/backward_17_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  526389
uname :  posix.uname_result(sysname='Linux', nodename='jae11', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:31:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7facad2063d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1165, '_step_count': 1166, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.202460 valid_loss:0.199904 each epoch time:20.22767
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.001449  valid_dq/boxsize 0.001430  train_dp 0.186974  valid_dp 0.184612 reg_loss 7.655633
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:33:12
run time  0:01:41.841009
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l1reg/6rho0.14/backward_17/backward_17_loss.txt
backward 5rho0.10
