forward 1rho0.10, first run no save model .....
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545750
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:16:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f099056d1d0>
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.241494 valid_loss:0.245320 each epoch time:20.09392
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000057  train_dp 0.240792  valid_dp 0.244600 reg_loss 35.261681
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:18:34
run time  0:01:40.228882
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/rho0/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/forward_1/forward_1_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545774
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:18:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f44d1642e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 5, '_step_count': 6, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.293850 valid_loss:0.285711 each epoch time:19.52225
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000081  valid_dq/boxsize 0.000079  train_dp 0.292984  valid_dp 0.284867 reg_loss 37.247914
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:20:16
run time  0:01:39.331378
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_1/forward_1_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545794
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:20:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb57d9d4390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 10, '_step_count': 11, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.218410 valid_loss:0.222136 each epoch time:19.82115
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000053  train_dp 0.217760  valid_dp 0.221468 reg_loss 29.483624
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:21:56
run time  0:01:38.791898
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_1/forward_1_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545811
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:21:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe980b0a9d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 15, '_step_count': 16, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.328473 valid_loss:0.323203 each epoch time:19.91858
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000111  valid_dq/boxsize 0.000110  train_dp 0.327480  valid_dp 0.322219 reg_loss 56.905847
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:23:37
run time  0:01:39.725280
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_1/forward_1_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545829
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:23:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f717c72ea90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 20, '_step_count': 21, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.201312 valid_loss:0.204852 each epoch time:19.87191
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000050  train_dp 0.200698  valid_dp 0.204220 reg_loss 25.445349
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:25:17
run time  0:01:39.276292
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_1/forward_1_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545846
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:25:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe2286a23d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 25, '_step_count': 26, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.252562 valid_loss:0.245405 each epoch time:20.46805
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000073  valid_dq/boxsize 0.000071  train_dp 0.251782  valid_dp 0.244644 reg_loss 27.544828
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:27:02
run time  0:01:41.316117
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_1/forward_1_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545863
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:27:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f153f9a6cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 30, '_step_count': 31, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.352575 valid_loss:0.347590 each epoch time:19.96328
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000143  valid_dq/boxsize 0.000143  train_dp 0.351471  valid_dp 0.346490 reg_loss 58.974322
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:28:45
run time  0:01:42.167603
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_1/forward_1_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545881
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:28:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc8681d1f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 35, '_step_count': 36, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.413589 valid_loss:0.407276 each epoch time:20.54626
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000203  valid_dq/boxsize 0.000202  train_dp 0.412270  valid_dp 0.405965 reg_loss 60.932396
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:30:29
run time  0:01:43.267519
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_1/forward_1_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545899
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:30:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa26c4a4f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 40, '_step_count': 41, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.327643 valid_loss:0.323297 each epoch time:20.13870
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000138  valid_dq/boxsize 0.000137  train_dp 0.326583  valid_dp 0.322239 reg_loss 52.200825
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:32:15
run time  0:01:41.977149
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_1/backward_1_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545916
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:32:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa370a210d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 45, '_step_count': 46, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.223242 valid_loss:0.216758 each epoch time:20.73683
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000068  valid_dq/boxsize 0.000067  train_dp 0.222512  valid_dp 0.216046 reg_loss 21.071569
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:34:01
run time  0:01:42.765251
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_1/backward_1_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545932
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:34:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5a0d516390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 50, '_step_count': 51, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.171154 valid_loss:0.174015 each epoch time:19.93445
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000045  valid_dq/boxsize 0.000046  train_dp 0.170590  valid_dp 0.173435 reg_loss 18.351031
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:35:43
run time  0:01:40.269670
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_1/backward_1_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545949
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:35:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4a8d105810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 55, '_step_count': 56, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.263740 valid_loss:0.260204 each epoch time:20.03741
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000098  valid_dq/boxsize 0.000097  train_dp 0.262862  valid_dp 0.259333 reg_loss 38.918311
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:37:26
run time  0:01:41.545299
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_1/backward_1_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545966
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:37:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f90c82590d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 60, '_step_count': 61, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.166574 valid_loss:0.169270 each epoch time:19.61648
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000044  valid_dq/boxsize 0.000045  train_dp 0.166016  valid_dp 0.168697 reg_loss 17.528716
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:39:10
run time  0:01:39.844618
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_1/backward_1_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  545983
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:39:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f01a150e550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 65, '_step_count': 66, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.211761 valid_loss:0.205569 each epoch time:19.97726
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000067  valid_dq/boxsize 0.000065  train_dp 0.211046  valid_dp 0.204873 reg_loss 19.251647
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:40:52
run time  0:01:40.107290
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_1/backward_1_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546000
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:40:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd1b1eff550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 70, '_step_count': 71, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.162862 valid_loss:0.165443 each epoch time:20.57222
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000044  valid_dq/boxsize 0.000045  train_dp 0.162309  valid_dp 0.164876 reg_loss 17.040807
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:42:34
run time  0:01:40.850099
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_1/backward_1_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546017
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:42:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f06b1084f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 75, '_step_count': 76, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.207141 valid_loss:0.201071 each epoch time:20.21010
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000066  valid_dq/boxsize 0.000065  train_dp 0.206432  valid_dp 0.200381 reg_loss 18.679856
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:44:18
run time  0:01:41.818175
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_2/forward_2_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546035
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:44:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb91351e150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 80, '_step_count': 81, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.159410 valid_loss:0.161896 each epoch time:19.93430
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000045  train_dp 0.158862  valid_dp 0.161332 reg_loss 16.633297
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:45:59
run time  0:01:40.027679
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_2/forward_2_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546052
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:46:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f176b62af10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 85, '_step_count': 86, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.245793 valid_loss:0.242483 each epoch time:21.06283
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000096  valid_dq/boxsize 0.000095  train_dp 0.244938  valid_dp 0.241634 reg_loss 35.807353
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:47:45
run time  0:01:44.302738
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_2/forward_2_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546069
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:47:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcd262fa290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 90, '_step_count': 91, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.155877 valid_loss:0.158253 each epoch time:20.40546
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000044  train_dp 0.155333  valid_dp 0.157694 reg_loss 16.147237
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:49:28
run time  0:01:41.810349
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_2/forward_2_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546087
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:49:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3c79dde650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 95, '_step_count': 96, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.198316 valid_loss:0.192490 each epoch time:19.79522
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000065  valid_dq/boxsize 0.000064  train_dp 0.197618  valid_dp 0.191810 reg_loss 17.632198
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:51:10
run time  0:01:41.063053
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_2/forward_2_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546104
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:51:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff741047310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 100, '_step_count': 101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.279887 valid_loss:0.276239 each epoch time:20.01970
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000129  valid_dq/boxsize 0.000129  train_dp 0.278891  valid_dp 0.275245 reg_loss 42.931817
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:52:53
run time  0:01:42.261858
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_2/forward_2_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546120
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:52:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fce65475f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 105, '_step_count': 106, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.333157 valid_loss:0.327845 each epoch time:20.30152
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000185  valid_dq/boxsize 0.000184  train_dp 0.331954  valid_dp 0.326649 reg_loss 45.486583
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:54:41
run time  0:01:43.400163
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_2/forward_2_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546137
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:54:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe980dfda10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 110, '_step_count': 111, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.269384 valid_loss:0.265906 each epoch time:20.03708
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000128  valid_dq/boxsize 0.000128  train_dp 0.268400  valid_dp 0.264923 reg_loss 40.406246
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:56:24
run time  0:01:41.831805
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_2/backward_2_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546154
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:56:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd6c0037c50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 115, '_step_count': 116, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.187677 valid_loss:0.182154 each epoch time:20.26246
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000064  valid_dq/boxsize 0.000063  train_dp 0.186989  valid_dp 0.181485 reg_loss 15.725053
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:58:08
run time  0:01:43.162832
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_2/backward_2_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546171
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:58:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f531d07aa10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 120, '_step_count': 121, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.145638 valid_loss:0.147555 each epoch time:20.12690
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000043  train_dp 0.145104  valid_dp 0.147007 reg_loss 14.517689
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:59:50
run time  0:01:40.865140
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_2/backward_2_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546189
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:59:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb430a9ee90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 125, '_step_count': 126, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.222475 valid_loss:0.219600 each epoch time:20.44553
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000093  valid_dq/boxsize 0.000092  train_dp 0.221646  valid_dp 0.218777 reg_loss 31.872120
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:01:34
run time  0:01:42.381997
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_2/backward_2_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546206
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:01:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb921ce4710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 130, '_step_count': 131, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.142759 valid_loss:0.144630 each epoch time:20.52439
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000043  train_dp 0.142227  valid_dp 0.144085 reg_loss 14.432092
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:03:16
run time  0:01:41.316420
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_2/backward_2_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546224
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:03:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9798ab9790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 135, '_step_count': 136, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.180886 valid_loss:0.175588 each epoch time:19.82864
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000064  valid_dq/boxsize 0.000062  train_dp 0.180206  valid_dp 0.174926 reg_loss 15.592029
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:04:59
run time  0:01:41.279545
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_2/backward_2_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546241
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:05:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9d51bde350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 140, '_step_count': 141, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.140124 valid_loss:0.141983 each epoch time:20.25284
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000043  train_dp 0.139596  valid_dp 0.141441 reg_loss 14.457903
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:06:43
run time  0:01:41.902296
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_2/backward_2_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546258
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:06:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1154495090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 145, '_step_count': 146, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.177893 valid_loss:0.172697 each epoch time:19.53008
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000063  valid_dq/boxsize 0.000062  train_dp 0.177216  valid_dp 0.172037 reg_loss 15.573973
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:08:27
run time  0:01:40.791841
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_3/forward_3_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546275
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:08:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa77f86a5d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 150, '_step_count': 151, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.137665 valid_loss:0.139507 each epoch time:20.92926
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000043  train_dp 0.137140  valid_dp 0.138968 reg_loss 14.462445
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:10:11
run time  0:01:42.568889
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_3/forward_3_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546293
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:10:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8dcf0be710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 155, '_step_count': 156, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.211845 valid_loss:0.209090 each epoch time:20.14582
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000092  valid_dq/boxsize 0.000091  train_dp 0.211025  valid_dp 0.208275 reg_loss 31.662910
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:11:54
run time  0:01:41.597368
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_3/forward_3_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546309
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:11:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9f039df7d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 160, '_step_count': 161, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.135250 valid_loss:0.137038 each epoch time:20.16562
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000042  train_dp 0.134727  valid_dp 0.136501 reg_loss 14.341247
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:13:37
run time  0:01:42.099080
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_3/forward_3_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546325
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:13:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5877b53c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 165, '_step_count': 166, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.172035 valid_loss:0.167027 each epoch time:20.41356
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000063  valid_dq/boxsize 0.000061  train_dp 0.171363  valid_dp 0.166373 reg_loss 15.375157
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:15:19
run time  0:01:40.175857
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_3/forward_3_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546342
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:15:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb2be9eff50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 170, '_step_count': 171, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.243275 valid_loss:0.240041 each epoch time:19.66042
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000125  valid_dq/boxsize 0.000125  train_dp 0.242314  valid_dp 0.239081 reg_loss 38.913634
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:17:02
run time  0:01:41.620973
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_3/forward_3_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546362
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:17:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f050e9a98d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 175, '_step_count': 176, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.290927 valid_loss:0.285781 each epoch time:20.76873
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000179  valid_dq/boxsize 0.000178  train_dp 0.289764  valid_dp 0.284624 reg_loss 41.738913
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:18:49
run time  0:01:43.155497
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_3/forward_3_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546379
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:18:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa91a625110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 180, '_step_count': 181, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.235709 valid_loss:0.232615 each epoch time:20.70577
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000124  valid_dq/boxsize 0.000124  train_dp 0.234757  valid_dp 0.231663 reg_loss 37.188808
memory usage : 3.6  at e= 5
end date/time : 20211025, 01:20:35
run time  0:01:43.005401
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_3/backward_3_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546396
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:20:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd81f91b450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 185, '_step_count': 186, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.164960 valid_loss:0.160184 each epoch time:20.46450
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000062  valid_dq/boxsize 0.000061  train_dp 0.164295  valid_dp 0.159536 reg_loss 14.201310
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:22:19
run time  0:01:41.161567
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_3/backward_3_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546413
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:22:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcbf1ea8490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 190, '_step_count': 191, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.128397 valid_loss:0.129834 each epoch time:19.79394
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000042  train_dp 0.127880  valid_dp 0.129304 reg_loss 13.497892
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:24:01
run time  0:01:41.116856
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_3/backward_3_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546431
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:24:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8c146cfdd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 195, '_step_count': 196, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.195884 valid_loss:0.193472 each epoch time:20.27592
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000090  valid_dq/boxsize 0.000089  train_dp 0.195078  valid_dp 0.192672 reg_loss 29.846761
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:25:43
run time  0:01:41.247186
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_3/backward_3_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546447
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:25:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa13870c090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 200, '_step_count': 201, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.126154 valid_loss:0.127587 each epoch time:20.35876
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000042  train_dp 0.125640  valid_dp 0.127059 reg_loss 13.533554
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:27:29
run time  0:01:42.000374
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_3/backward_3_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546464
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:27:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f66ad4f0a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 205, '_step_count': 206, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.159848 valid_loss:0.155237 each epoch time:20.25327
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000062  valid_dq/boxsize 0.000060  train_dp 0.159187  valid_dp 0.154593 reg_loss 14.374344
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:29:13
run time  0:01:40.883799
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_3/backward_3_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546480
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:29:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6c640f8d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 210, '_step_count': 211, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.124076 valid_loss:0.125530 each epoch time:20.44177
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000042  train_dp 0.123563  valid_dp 0.125004 reg_loss 13.641124
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:30:57
run time  0:01:42.289847
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_3/backward_3_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546498
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:30:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7f6224b590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 215, '_step_count': 216, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.157646 valid_loss:0.153103 each epoch time:19.78945
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000062  valid_dq/boxsize 0.000060  train_dp 0.156987  valid_dp 0.152461 reg_loss 14.468823
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:32:38
run time  0:01:39.616271
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_4/forward_4_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546515
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:32:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdbdf5c0450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 220, '_step_count': 221, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.122181 valid_loss:0.123643 each epoch time:20.68631
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000041  train_dp 0.121670  valid_dp 0.123119 reg_loss 13.714645
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:34:22
run time  0:01:42.723196
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_4/forward_4_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546532
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:34:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9f16ce7210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 225, '_step_count': 226, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.188352 valid_loss:0.186055 each epoch time:20.34728
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000090  valid_dq/boxsize 0.000089  train_dp 0.187551  valid_dp 0.185260 reg_loss 30.227176
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:36:05
run time  0:01:41.100873
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_4/forward_4_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546548
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:36:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2d1cecc2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 230, '_step_count': 231, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.120388 valid_loss:0.121812 each epoch time:20.14584
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000041  train_dp 0.119878  valid_dp 0.121289 reg_loss 13.668792
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:37:47
run time  0:01:40.545555
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_4/forward_4_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546566
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:37:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fde8d723690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 235, '_step_count': 236, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.153349 valid_loss:0.148924 each epoch time:20.09254
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000060  train_dp 0.152693  valid_dp 0.148284 reg_loss 14.468419
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:39:29
run time  0:01:39.528374
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_4/forward_4_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546583
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:39:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1f32584910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 240, '_step_count': 241, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.217525 valid_loss:0.214650 each epoch time:19.75321
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000122  valid_dq/boxsize 0.000122  train_dp 0.216583  valid_dp 0.213709 reg_loss 37.325560
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:41:11
run time  0:01:40.652126
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_4/forward_4_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546600
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:41:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f957f010190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 245, '_step_count': 246, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.261107 valid_loss:0.256005 each epoch time:20.20187
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000176  valid_dq/boxsize 0.000175  train_dp 0.259963  valid_dp 0.254868 reg_loss 40.215913
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:42:56
run time  0:01:43.367217
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_4/forward_4_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546616
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:42:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe289eff190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 250, '_step_count': 251, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.211590 valid_loss:0.208854 each epoch time:20.39120
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000121  valid_dq/boxsize 0.000121  train_dp 0.210656  valid_dp 0.207920 reg_loss 35.886472
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:44:40
run time  0:01:40.658599
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_4/backward_4_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546632
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:44:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3f74638c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 255, '_step_count': 256, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.148321 valid_loss:0.144053 each epoch time:19.96989
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000059  train_dp 0.147670  valid_dp 0.143419 reg_loss 13.543183
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:46:24
run time  0:01:40.919868
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_4/backward_4_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546649
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:46:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8a89754f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 260, '_step_count': 261, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.115524 valid_loss:0.116647 each epoch time:20.36178
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000041  train_dp 0.115019  valid_dp 0.116129 reg_loss 13.052833
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:48:06
run time  0:01:41.309862
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_4/backward_4_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546668
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:48:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f20d9b6bf10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 265, '_step_count': 266, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.176489 valid_loss:0.174448 each epoch time:20.26291
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000088  valid_dq/boxsize 0.000088  train_dp 0.175698  valid_dp 0.173663 reg_loss 29.022238
memory usage : 3.6  at e= 5
end date/time : 20211025, 01:49:50
run time  0:01:42.205210
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_4/backward_4_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546685
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:49:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3f23c9ff50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 270, '_step_count': 271, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.113670 valid_loss:0.114810 each epoch time:19.98886
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000041  train_dp 0.113167  valid_dp 0.114294 reg_loss 13.112167
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:51:32
run time  0:01:41.630805
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_4/backward_4_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546701
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:51:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcbd48a5990>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 275, '_step_count': 276, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.144242 valid_loss:0.140090 each epoch time:20.36417
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000059  train_dp 0.143593  valid_dp 0.139458 reg_loss 13.801479
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:53:15
run time  0:01:41.682305
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_4/backward_4_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546718
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:53:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcea6429190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 280, '_step_count': 281, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.111915 valid_loss:0.113096 each epoch time:20.22055
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000041  train_dp 0.111413  valid_dp 0.112581 reg_loss 13.229102
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:54:57
run time  0:01:41.123071
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_4/backward_4_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546735
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:54:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc2fea24a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 285, '_step_count': 286, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.142494 valid_loss:0.138387 each epoch time:20.43901
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000059  train_dp 0.141846  valid_dp 0.137755 reg_loss 13.923303
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:56:40
run time  0:01:40.990183
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_5/forward_5_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546752
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:56:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7c96564810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 290, '_step_count': 291, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.110333 valid_loss:0.111537 each epoch time:20.97184
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000041  train_dp 0.109832  valid_dp 0.111022 reg_loss 13.308057
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:58:24
run time  0:01:43.054883
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_5/forward_5_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546769
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:58:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdbda946ed0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 295, '_step_count': 296, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.170770 valid_loss:0.168789 each epoch time:20.71499
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000088  valid_dq/boxsize 0.000088  train_dp 0.169981  valid_dp 0.168005 reg_loss 29.530326
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:00:09
run time  0:01:43.463926
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_5/forward_5_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546786
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:00:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6eb03c2610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 300, '_step_count': 301, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.108876 valid_loss:0.110057 each epoch time:20.30277
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000041  train_dp 0.108376  valid_dp 0.109543 reg_loss 13.273793
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:01:51
run time  0:01:40.662954
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_5/forward_5_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546803
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:01:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbd332010d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 305, '_step_count': 306, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.139064 valid_loss:0.135034 each epoch time:19.51299
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000060  valid_dq/boxsize 0.000059  train_dp 0.138418  valid_dp 0.134404 reg_loss 13.981685
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:03:32
run time  0:01:40.012498
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_5/forward_5_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546821
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:03:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9ae45d0490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 310, '_step_count': 311, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.198123 valid_loss:0.195526 each epoch time:20.15321
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000121  valid_dq/boxsize 0.000121  train_dp 0.197193  valid_dp 0.194596 reg_loss 36.569518
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:05:16
run time  0:01:41.608445
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_5/forward_5_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546838
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:05:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f36f630c490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 315, '_step_count': 316, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.238738 valid_loss:0.233696 each epoch time:20.58096
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000174  valid_dq/boxsize 0.000173  train_dp 0.237606  valid_dp 0.232571 reg_loss 39.343035
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:07:01
run time  0:01:43.048945
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_5/forward_5_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546854
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:07:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8a025f1f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 320, '_step_count': 321, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.193295 valid_loss:0.190815 each epoch time:20.21559
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000120  valid_dq/boxsize 0.000120  train_dp 0.192370  valid_dp 0.189892 reg_loss 35.286069
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:08:45
run time  0:01:40.877100
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_5/backward_5_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546870
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:08:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f51602fe290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 325, '_step_count': 326, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.135225 valid_loss:0.131317 each epoch time:19.85744
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000060  valid_dq/boxsize 0.000058  train_dp 0.134583  valid_dp 0.130692 reg_loss 13.209768
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:10:28
run time  0:01:41.284175
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_5/backward_5_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546886
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:10:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6fb49262d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 330, '_step_count': 331, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.105040 valid_loss:0.105987 each epoch time:20.21732
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.104543  valid_dp 0.105476 reg_loss 12.723870
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:12:10
run time  0:01:40.784733
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_5/backward_5_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546904
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:12:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9d19739a50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 335, '_step_count': 336, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.161348 valid_loss:0.159531 each epoch time:20.46227
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000087  valid_dq/boxsize 0.000087  train_dp 0.160566  valid_dp 0.158754 reg_loss 28.535340
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:13:53
run time  0:01:41.825478
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_5/backward_5_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546920
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:13:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa149fe4d90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 340, '_step_count': 341, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.103375 valid_loss:0.104365 each epoch time:20.05038
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.102879  valid_dp 0.103856 reg_loss 12.774387
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:15:36
run time  0:01:42.150769
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_5/backward_5_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546937
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:15:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f89ba33f390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 345, '_step_count': 346, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.131675 valid_loss:0.127862 each epoch time:20.43815
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000060  valid_dq/boxsize 0.000058  train_dp 0.131035  valid_dp 0.127238 reg_loss 13.463367
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:17:33
run time  0:01:43.164971
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_5/backward_5_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546956
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:17:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa664b366d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 350, '_step_count': 351, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.101779 valid_loss:0.102831 each epoch time:19.64753
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.101284  valid_dp 0.102322 reg_loss 12.874021
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:19:14
run time  0:01:40.632730
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_5/backward_5_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546973
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:19:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9626ed9b50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 355, '_step_count': 356, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.130161 valid_loss:0.126381 each epoch time:20.75985
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000060  valid_dq/boxsize 0.000058  train_dp 0.129521  valid_dp 0.125757 reg_loss 13.573221
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:20:59
run time  0:01:42.889538
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_6/forward_6_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  546990
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:21:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9aada75250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 360, '_step_count': 361, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.100354 valid_loss:0.101446 each epoch time:20.28228
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.099859  valid_dp 0.100938 reg_loss 12.935012
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:22:42
run time  0:01:41.890348
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_6/forward_6_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547007
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:22:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb9608b9d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 365, '_step_count': 366, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.156588 valid_loss:0.154800 each epoch time:19.97878
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000087  valid_dq/boxsize 0.000087  train_dp 0.155807  valid_dp 0.154023 reg_loss 28.992711
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:24:25
run time  0:01:41.647334
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_6/forward_6_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547024
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:24:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4555617110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 370, '_step_count': 371, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.099068 valid_loss:0.100154 each epoch time:19.80569
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.098574  valid_dp 0.099646 reg_loss 12.891280
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:26:06
run time  0:01:40.493289
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_6/forward_6_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547042
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:26:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc9615a3ad0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 375, '_step_count': 376, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.127197 valid_loss:0.123474 each epoch time:20.55602
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000060  valid_dq/boxsize 0.000058  train_dp 0.126558  valid_dp 0.122850 reg_loss 13.625509
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:27:49
run time  0:01:41.581810
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_6/forward_6_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547058
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:27:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6ee2e7e1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 380, '_step_count': 381, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.182515 valid_loss:0.180111 each epoch time:20.70613
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000120  valid_dq/boxsize 0.000120  train_dp 0.181592  valid_dp 0.179188 reg_loss 36.107697
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:29:34
run time  0:01:43.544677
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_6/forward_6_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547074
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:29:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f73346d8590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 385, '_step_count': 386, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.221034 valid_loss:0.216082 each epoch time:20.68278
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000173  valid_dq/boxsize 0.000172  train_dp 0.219910  valid_dp 0.214965 reg_loss 38.618856
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:31:20
run time  0:01:43.578857
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_6/forward_6_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547091
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:31:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd25f4cb250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 390, '_step_count': 391, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.178506 valid_loss:0.176201 each epoch time:19.80487
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000119  valid_dq/boxsize 0.000119  train_dp 0.177589  valid_dp 0.175284 reg_loss 34.926852
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:33:02
run time  0:01:40.588384
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_6/backward_6_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547108
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:33:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff64f65a6d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 395, '_step_count': 396, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.124058 valid_loss:0.120424 each epoch time:20.21651
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000058  train_dp 0.123422  valid_dp 0.119804 reg_loss 12.924242
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:34:44
run time  0:01:41.237678
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_6/backward_6_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547125
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:34:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8fa5e1a0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 400, '_step_count': 401, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.095770 valid_loss:0.096690 each epoch time:20.10947
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.095278  valid_dp 0.096185 reg_loss 12.362696
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:36:28
run time  0:01:41.425702
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_6/backward_6_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547143
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:36:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7423cf7390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 405, '_step_count': 406, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.148669 valid_loss:0.147024 each epoch time:20.50597
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000087  valid_dq/boxsize 0.000086  train_dp 0.147893  valid_dp 0.146254 reg_loss 28.055546
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:38:11
run time  0:01:42.078367
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_6/backward_6_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547159
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:38:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9a427b3050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 410, '_step_count': 411, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.094257 valid_loss:0.095234 each epoch time:20.12943
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.093765  valid_dp 0.094729 reg_loss 12.394453
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:39:54
run time  0:01:41.300443
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_6/backward_6_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547177
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:39:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1950fabc90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 415, '_step_count': 416, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.120882 valid_loss:0.117328 each epoch time:20.18649
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000058  train_dp 0.120246  valid_dp 0.116708 reg_loss 13.131604
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:41:37
run time  0:01:41.745518
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_6/backward_6_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547195
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:41:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe550e50350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 420, '_step_count': 421, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.092820 valid_loss:0.093868 each epoch time:20.12200
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.092329  valid_dp 0.093363 reg_loss 12.468058
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:43:19
run time  0:01:41.076071
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_6/backward_6_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547212
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:43:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8093393450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 425, '_step_count': 426, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.119556 valid_loss:0.116025 each epoch time:20.57764
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000058  train_dp 0.118920  valid_dp 0.115406 reg_loss 13.217406
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:45:03
run time  0:01:42.766454
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_7/forward_7_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547229
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:45:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f65d3a50790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 430, '_step_count': 431, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.091556 valid_loss:0.092650 each epoch time:20.15122
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.091065  valid_dp 0.092146 reg_loss 12.506037
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:46:46
run time  0:01:42.014812
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_7/forward_7_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547246
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:46:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9c96585cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 435, '_step_count': 436, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.144565 valid_loss:0.142947 each epoch time:20.61996
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000087  valid_dq/boxsize 0.000086  train_dp 0.143788  valid_dp 0.142175 reg_loss 28.389688
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:48:30
run time  0:01:42.065099
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_7/forward_7_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547263
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:48:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f63013d30d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 440, '_step_count': 441, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.090431 valid_loss:0.091527 each epoch time:20.20234
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.089940  valid_dp 0.091022 reg_loss 12.449722
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:50:13
run time  0:01:42.198657
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_7/forward_7_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547280
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:50:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f92c1eec750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 445, '_step_count': 446, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.116980 valid_loss:0.113485 each epoch time:19.96842
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000058  train_dp 0.116344  valid_dp 0.112865 reg_loss 13.225285
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:51:55
run time  0:01:39.218816
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_7/forward_7_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547297
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:51:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1de0a3bc50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 450, '_step_count': 451, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.169432 valid_loss:0.167176 each epoch time:20.38586
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000119  valid_dq/boxsize 0.000119  train_dp 0.168515  valid_dp 0.166259 reg_loss 35.630636
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:53:38
run time  0:01:41.118545
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_7/forward_7_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547315
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:53:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb69da71f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 455, '_step_count': 456, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.206381 valid_loss:0.201570 each epoch time:20.93342
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000172  valid_dq/boxsize 0.000171  train_dp 0.205264  valid_dp 0.200461 reg_loss 37.808113
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:55:22
run time  0:01:43.539714
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_7/forward_7_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547331
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:55:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0b3ad854d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 460, '_step_count': 461, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.166034 valid_loss:0.163863 each epoch time:19.87895
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000118  valid_dq/boxsize 0.000118  train_dp 0.165123  valid_dp 0.162952 reg_loss 34.540690
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:57:05
run time  0:01:40.800617
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_7/backward_7_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547351
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:57:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbbac308a50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 465, '_step_count': 466, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.114307 valid_loss:0.110871 each epoch time:19.66610
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000058  train_dp 0.113675  valid_dp 0.110255 reg_loss 12.558621
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:58:48
run time  0:01:39.785291
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_7/backward_7_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547367
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:58:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc9173da6d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 470, '_step_count': 471, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.087548 valid_loss:0.088513 each epoch time:19.89281
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.087059  valid_dp 0.088011 reg_loss 11.940802
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:00:31
run time  0:01:42.216350
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_7/backward_7_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547384
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:00:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa1ab1d1d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 475, '_step_count': 476, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.137757 valid_loss:0.136262 each epoch time:19.55285
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000086  valid_dq/boxsize 0.000086  train_dp 0.136986  valid_dp 0.135496 reg_loss 27.463851
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:02:11
run time  0:01:39.069560
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_7/backward_7_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547401
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:02:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdf79eedbd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 480, '_step_count': 481, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.086222 valid_loss:0.087244 each epoch time:20.10610
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.085733  valid_dp 0.086742 reg_loss 11.952992
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:03:53
run time  0:01:40.347259
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_7/backward_7_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547419
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:03:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f821c2d4290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 485, '_step_count': 486, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.111518 valid_loss:0.108148 each epoch time:20.26379
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000058  train_dp 0.110886  valid_dp 0.107532 reg_loss 12.711673
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:05:35
run time  0:01:40.060360
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_7/backward_7_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547436
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:05:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc828148f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 490, '_step_count': 491, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.084982 valid_loss:0.086070 each epoch time:19.99178
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.084493  valid_dp 0.085568 reg_loss 12.000862
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:07:16
run time  0:01:40.221551
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_7/backward_7_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547453
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:07:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f152ef15210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 495, '_step_count': 496, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.110375 valid_loss:0.107022 each epoch time:19.95929
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000058  train_dp 0.109743  valid_dp 0.106405 reg_loss 12.765216
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:08:57
run time  0:01:39.358152
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_8/forward_8_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547471
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:08:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f21ee5ea350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 500, '_step_count': 501, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.083910 valid_loss:0.085039 each epoch time:20.23378
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.083421  valid_dp 0.084536 reg_loss 12.016818
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:10:39
run time  0:01:40.297129
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_8/forward_8_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547491
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:10:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0a49d286d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 505, '_step_count': 506, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.134226 valid_loss:0.132753 each epoch time:19.88830
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000086  valid_dq/boxsize 0.000086  train_dp 0.133454  valid_dp 0.131986 reg_loss 27.670177
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:12:20
run time  0:01:40.166813
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_8/forward_8_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547508
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:12:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb895732990>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 510, '_step_count': 511, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.082966 valid_loss:0.084094 each epoch time:20.32148
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.082477  valid_dp 0.083592 reg_loss 11.953666
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:14:03
run time  0:01:41.283544
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_8/forward_8_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547524
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:14:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f78b10b3810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 515, '_step_count': 516, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.108199 valid_loss:0.104872 each epoch time:19.51269
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000058  train_dp 0.107566  valid_dp 0.104255 reg_loss 12.734055
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:15:45
run time  0:01:41.146035
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_8/forward_8_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547542
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:15:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f04c4635fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 520, '_step_count': 521, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.158237 valid_loss:0.156110 each epoch time:20.27814
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000118  valid_dq/boxsize 0.000118  train_dp 0.157325  valid_dp 0.155199 reg_loss 35.061434
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:17:29
run time  0:01:42.429535
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_8/forward_8_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547562
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:17:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdfa1b2ec10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 525, '_step_count': 526, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.193899 valid_loss:0.189260 each epoch time:20.77561
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000171  valid_dq/boxsize 0.000170  train_dp 0.192789  valid_dp 0.188158 reg_loss 36.899106
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:19:14
run time  0:01:43.926485
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_8/forward_8_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547579
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:19:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbdf6553710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 530, '_step_count': 531, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.155359 valid_loss:0.153304 each epoch time:20.17128
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000118  valid_dq/boxsize 0.000118  train_dp 0.154452  valid_dp 0.152398 reg_loss 34.074846
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:21:00
run time  0:01:42.790898
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_8/backward_8_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547606
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:21:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0862460d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 535, '_step_count': 536, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.105923 valid_loss:0.102647 each epoch time:19.95512
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000057  train_dp 0.105293  valid_dp 0.102034 reg_loss 12.115600
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:22:42
run time  0:01:39.754166
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_8/backward_8_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547623
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:22:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa891a32090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 540, '_step_count': 541, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.080518 valid_loss:0.081531 each epoch time:19.82230
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.080031  valid_dp 0.081030 reg_loss 11.477504
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:24:24
run time  0:01:40.460553
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_8/backward_8_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547640
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:24:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff934a83bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 545, '_step_count': 546, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.128451 valid_loss:0.127072 each epoch time:20.11375
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000086  valid_dq/boxsize 0.000085  train_dp 0.127683  valid_dp 0.126310 reg_loss 26.779731
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:26:06
run time  0:01:41.485480
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_8/backward_8_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547659
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:26:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f30e0af4b50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 550, '_step_count': 551, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.079414 valid_loss:0.080477 each epoch time:20.07153
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.078927  valid_dp 0.079976 reg_loss 11.476664
memory usage : 3.6  at e= 5
end date/time : 20211025, 03:27:47
run time  0:01:39.636797
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_8/backward_8_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547676
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:27:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb1e6a4a3d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 555, '_step_count': 556, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.103577 valid_loss:0.100361 each epoch time:19.69078
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000057  train_dp 0.102947  valid_dp 0.099747 reg_loss 12.218324
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:29:28
run time  0:01:39.459522
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_8/backward_8_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547693
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:29:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2107fee050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 560, '_step_count': 561, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.078395 valid_loss:0.079512 each epoch time:19.69538
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.077908  valid_dp 0.079011 reg_loss 11.503606
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:31:09
run time  0:01:38.874877
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_8/backward_8_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547709
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:31:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4b46a7d710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 565, '_step_count': 566, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.102627 valid_loss:0.099427 each epoch time:20.34594
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000057  train_dp 0.101996  valid_dp 0.098812 reg_loss 12.248299
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:32:52
run time  0:01:42.148909
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_9/forward_9_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547726
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:32:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f97a2c89210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 570, '_step_count': 571, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.077511 valid_loss:0.078659 each epoch time:20.15217
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.077023  valid_dp 0.078158 reg_loss 11.504486
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:34:35
run time  0:01:42.016678
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_9/forward_9_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547742
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:34:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f94cf501150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 575, '_step_count': 576, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.125456 valid_loss:0.124096 each epoch time:20.55935
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000086  valid_dq/boxsize 0.000085  train_dp 0.124688  valid_dp 0.123332 reg_loss 26.879151
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:36:17
run time  0:01:40.309429
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_9/forward_9_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547762
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:36:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fae274eaf90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 580, '_step_count': 581, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.076722 valid_loss:0.077866 each epoch time:20.38637
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000040  train_dp 0.076234  valid_dp 0.077365 reg_loss 11.440354
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:38:01
run time  0:01:42.899870
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_9/forward_9_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547779
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:38:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f227022e1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 585, '_step_count': 586, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.100785 valid_loss:0.097609 each epoch time:20.41164
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000057  train_dp 0.100155  valid_dp 0.096994 reg_loss 12.190562
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:39:46
run time  0:01:41.801704
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_9/forward_9_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547796
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:39:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1cccf1a210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 590, '_step_count': 591, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.148650 valid_loss:0.146617 each epoch time:20.56542
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000118  valid_dq/boxsize 0.000118  train_dp 0.147743  valid_dp 0.145711 reg_loss 34.421804
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:41:32
run time  0:01:41.852454
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_9/forward_9_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547814
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:41:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f630451f6d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 595, '_step_count': 596, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.183077 valid_loss:0.178608 each epoch time:20.96767
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000170  valid_dq/boxsize 0.000169  train_dp 0.181975  valid_dp 0.177514 reg_loss 35.898799
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:43:19
run time  0:01:44.125017
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_9/forward_9_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547831
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:43:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe68f488610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 600, '_step_count': 601, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.146187 valid_loss:0.144214 each epoch time:19.75496
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000117  valid_dq/boxsize 0.000117  train_dp 0.145285  valid_dp 0.143313 reg_loss 33.530734
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:45:00
run time  0:01:39.629555
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_9/backward_9_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547848
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:45:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9df737aa50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 605, '_step_count': 606, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.098818 valid_loss:0.095684 each epoch time:20.71215
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000057  train_dp 0.098191  valid_dp 0.095073 reg_loss 11.624443
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:46:44
run time  0:01:43.183276
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_9/backward_9_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547865
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:46:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9ccdb0f410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 610, '_step_count': 611, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.074630 valid_loss:0.075674 each epoch time:20.29635
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.074144  valid_dp 0.075175 reg_loss 11.013888
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:48:27
run time  0:01:41.408440
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_9/backward_9_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547882
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:48:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0426238890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 615, '_step_count': 616, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.120510 valid_loss:0.119224 each epoch time:20.23412
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000085  valid_dq/boxsize 0.000085  train_dp 0.119746  valid_dp 0.118465 reg_loss 26.018350
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:50:09
run time  0:01:41.179302
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_9/backward_9_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547901
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:50:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fda5f2f0510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 620, '_step_count': 621, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.073719 valid_loss:0.074807 each epoch time:19.57382
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.073233  valid_dp 0.074308 reg_loss 11.008545
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:51:49
run time  0:01:38.358946
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_9/backward_9_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547918
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:51:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f091119d490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 625, '_step_count': 626, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.096855 valid_loss:0.093775 each epoch time:20.22756
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000057  train_dp 0.096227  valid_dp 0.093163 reg_loss 11.694006
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:53:32
run time  0:01:40.853927
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_9/backward_9_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547935
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:53:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f23397413d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 630, '_step_count': 631, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.072887 valid_loss:0.074021 each epoch time:20.28082
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.072401  valid_dp 0.073522 reg_loss 11.025271
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:55:17
run time  0:01:40.507018
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_9/backward_9_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547952
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:55:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efd47358110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 635, '_step_count': 636, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.096063 valid_loss:0.092999 each epoch time:20.20378
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000057  train_dp 0.095436  valid_dp 0.092387 reg_loss 11.708778
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:56:59
run time  0:01:41.404031
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_10/forward_10_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547968
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:57:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feacc90b2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 640, '_step_count': 641, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.072165 valid_loss:0.073325 each epoch time:19.81796
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000040  train_dp 0.071678  valid_dp 0.072826 reg_loss 11.019311
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:58:41
run time  0:01:40.727154
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_10/forward_10_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  547985
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:58:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f165d681f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 645, '_step_count': 646, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.117970 valid_loss:0.116704 each epoch time:20.32306
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000086  valid_dq/boxsize 0.000085  train_dp 0.117206  valid_dp 0.115944 reg_loss 26.063204
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:00:24
run time  0:01:41.682781
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_10/forward_10_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548001
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:00:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8c5d360410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 650, '_step_count': 651, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.071514 valid_loss:0.072669 each epoch time:20.18820
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.071027  valid_dp 0.072170 reg_loss 10.960654
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:02:05
run time  0:01:40.146793
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_10/forward_10_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548018
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:02:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7febaa07a590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 655, '_step_count': 656, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.094524 valid_loss:0.091483 each epoch time:19.81684
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000057  train_dp 0.093897  valid_dp 0.090871 reg_loss 11.640006
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:03:48
run time  0:01:39.142346
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_10/forward_10_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548035
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:03:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffa12875210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 660, '_step_count': 661, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.140404 valid_loss:0.138450 each epoch time:20.52709
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000117  valid_dq/boxsize 0.000117  train_dp 0.139503  valid_dp 0.137550 reg_loss 33.771732
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:05:33
run time  0:01:41.846080
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_10/forward_10_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548052
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:05:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd1d7719310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 665, '_step_count': 666, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.173667 valid_loss:0.169359 each epoch time:21.03045
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000169  valid_dq/boxsize 0.000168  train_dp 0.172573  valid_dp 0.168272 reg_loss 34.912734
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:07:19
run time  0:01:44.551470
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_10/forward_10_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548069
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:07:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4cb997ba90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 670, '_step_count': 671, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.138288 valid_loss:0.136386 each epoch time:20.55119
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000117  valid_dq/boxsize 0.000116  train_dp 0.137391  valid_dp 0.135490 reg_loss 32.952459
memory usage : 3.6  at e= 5
end date/time : 20211025, 04:09:03
run time  0:01:42.277936
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_10/backward_10_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548087
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:09:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0f793bd210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 675, '_step_count': 676, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.092822 valid_loss:0.089822 each epoch time:19.88006
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000057  train_dp 0.092198  valid_dp 0.089213 reg_loss 11.145215
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:10:46
run time  0:01:40.779651
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_10/backward_10_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548106
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:10:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5947720790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 680, '_step_count': 681, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.069744 valid_loss:0.070812 each epoch time:20.38178
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.069260  valid_dp 0.070315 reg_loss 10.585079
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:12:28
run time  0:01:40.815186
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_10/backward_10_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548123
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:12:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcbb8673490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 685, '_step_count': 686, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.113751 valid_loss:0.112535 each epoch time:19.88840
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000085  valid_dq/boxsize 0.000084  train_dp 0.112991  valid_dp 0.111779 reg_loss 25.277506
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:14:12
run time  0:01:40.521515
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_10/backward_10_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548139
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:14:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb138e301d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 690, '_step_count': 691, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.069002 valid_loss:0.070105 each epoch time:20.00770
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.068518  valid_dp 0.069608 reg_loss 10.573130
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:15:54
run time  0:01:40.803602
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_10/backward_10_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548158
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:15:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3e80cab850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 695, '_step_count': 696, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.091194 valid_loss:0.088242 each epoch time:20.22926
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000057  train_dp 0.090570  valid_dp 0.087633 reg_loss 11.188995
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:17:36
run time  0:01:40.431360
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_10/backward_10_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548178
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:17:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb9abaf1590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 700, '_step_count': 701, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.068328 valid_loss:0.069468 each epoch time:20.06451
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.067843  valid_dp 0.068970 reg_loss 10.579232
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:19:17
run time  0:01:40.485029
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_10/backward_10_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548194
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:19:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6fd0843150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 705, '_step_count': 706, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.090537 valid_loss:0.087600 each epoch time:19.92213
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000057  train_dp 0.089912  valid_dp 0.086991 reg_loss 11.192770
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:21:00
run time  0:01:41.210724
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_11/forward_11_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548212
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:21:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5216f66b50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 710, '_step_count': 711, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.067740 valid_loss:0.068901 each epoch time:20.46508
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.067255  valid_dp 0.068403 reg_loss 10.566834
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:22:42
run time  0:01:41.236579
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_11/forward_11_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548229
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:22:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f496f8e9cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 715, '_step_count': 716, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.111602 valid_loss:0.110402 each epoch time:20.28787
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000085  valid_dq/boxsize 0.000085  train_dp 0.110841  valid_dp 0.109647 reg_loss 25.266746
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:24:25
run time  0:01:41.432229
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_11/forward_11_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548245
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:24:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f634ae73d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 720, '_step_count': 721, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.067204 valid_loss:0.068359 each epoch time:20.00612
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.066719  valid_dp 0.067861 reg_loss 10.511668
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:26:07
run time  0:01:40.692452
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_11/forward_11_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548262
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:26:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0181469750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 725, '_step_count': 726, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.089253 valid_loss:0.086339 each epoch time:19.38922
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000057  train_dp 0.088628  valid_dp 0.085729 reg_loss 11.122623
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:27:48
run time  0:01:39.699990
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_11/forward_11_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548279
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:27:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f01edc61f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 730, '_step_count': 731, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.133304 valid_loss:0.131427 each epoch time:20.64195
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000116  valid_dq/boxsize 0.000116  train_dp 0.132409  valid_dp 0.130532 reg_loss 33.084714
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:29:31
run time  0:01:41.684203
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_11/forward_11_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548295
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:29:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f226a06d690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 735, '_step_count': 736, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.165473 valid_loss:0.161311 each epoch time:20.64085
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000168  valid_dq/boxsize 0.000166  train_dp 0.164386  valid_dp 0.160232 reg_loss 33.936066
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:31:15
run time  0:01:42.597253
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_11/forward_11_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548312
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:31:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f11a4c58050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 740, '_step_count': 741, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.131484 valid_loss:0.129664 each epoch time:20.41267
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000116  valid_dq/boxsize 0.000116  train_dp 0.130592  valid_dp 0.128773 reg_loss 32.353368
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:32:57
run time  0:01:41.059842
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_11/backward_11_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548330
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:32:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc0e8856f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 745, '_step_count': 746, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.087784 valid_loss:0.084909 each epoch time:19.67350
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000057  train_dp 0.087162  valid_dp 0.084302 reg_loss 10.678446
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:34:38
run time  0:01:39.511731
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_11/backward_11_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548347
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:34:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1b5a4026d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 750, '_step_count': 751, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.065714 valid_loss:0.066798 each epoch time:20.67037
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.065231  valid_dp 0.066302 reg_loss 10.175538
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:36:26
run time  0:01:44.171924
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_11/backward_11_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548363
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:36:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f16d43a44d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 755, '_step_count': 756, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.108002 valid_loss:0.106837 each epoch time:19.87092
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000085  valid_dq/boxsize 0.000084  train_dp 0.107245  valid_dp 0.106085 reg_loss 24.530224
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:38:08
run time  0:01:40.402985
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_11/backward_11_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548380
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:38:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd470fd7f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 760, '_step_count': 761, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.065106 valid_loss:0.066220 each epoch time:19.40820
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.064623  valid_dp 0.065724 reg_loss 10.161638
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:39:49
run time  0:01:39.105656
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_11/backward_11_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548399
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:39:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8cd23cf590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 765, '_step_count': 766, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.086429 valid_loss:0.083600 each epoch time:20.02710
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000057  train_dp 0.085807  valid_dp 0.082994 reg_loss 10.708788
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:41:32
run time  0:01:40.818855
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_11/backward_11_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548416
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:41:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f911e4b2dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 770, '_step_count': 771, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.064553 valid_loss:0.065700 each epoch time:20.16751
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.064069  valid_dp 0.065204 reg_loss 10.163654
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:43:14
run time  0:01:40.959247
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_11/backward_11_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548433
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:43:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f12619f55d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 775, '_step_count': 776, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.085878 valid_loss:0.083066 each epoch time:20.03289
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000057  train_dp 0.085256  valid_dp 0.082459 reg_loss 10.708031
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:44:56
run time  0:01:40.757457
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_12/forward_12_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548449
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:44:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f50bb6c4950>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 780, '_step_count': 781, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.064068 valid_loss:0.065235 each epoch time:19.98927
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.063585  valid_dp 0.064739 reg_loss 10.149611
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:46:39
run time  0:01:41.619516
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_12/forward_12_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548466
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:46:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdae53ea110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 785, '_step_count': 786, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.106171 valid_loss:0.105026 each epoch time:20.64205
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000085  valid_dq/boxsize 0.000084  train_dp 0.105415  valid_dp 0.104274 reg_loss 24.503549
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:48:22
run time  0:01:42.252951
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_12/forward_12_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548483
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:48:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efccd5e1350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 790, '_step_count': 791, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.063621 valid_loss:0.064785 each epoch time:19.78682
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.063137  valid_dp 0.064289 reg_loss 10.098343
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:50:03
run time  0:01:39.511046
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_12/forward_12_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548501
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:50:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7facaabc4890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 795, '_step_count': 796, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.084796 valid_loss:0.082006 each epoch time:20.37827
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000057  train_dp 0.084174  valid_dp 0.081399 reg_loss 10.640650
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:51:45
run time  0:01:40.985091
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_12/forward_12_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548517
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:51:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f420a524e90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 800, '_step_count': 801, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.127179 valid_loss:0.125384 each epoch time:19.84443
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000116  valid_dq/boxsize 0.000115  train_dp 0.126290  valid_dp 0.124495 reg_loss 32.400165
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:53:29
run time  0:01:41.269179
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_12/forward_12_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548534
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:53:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f918ba66510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 805, '_step_count': 806, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.158316 valid_loss:0.154285 each epoch time:20.59745
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000166  valid_dq/boxsize 0.000165  train_dp 0.157237  valid_dp 0.153214 reg_loss 33.031899
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:55:15
run time  0:01:42.689864
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_12/forward_12_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548551
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:55:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fac33640e90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 810, '_step_count': 811, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.125600 valid_loss:0.123863 each epoch time:20.25797
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000115  valid_dq/boxsize 0.000115  train_dp 0.124715  valid_dp 0.122979 reg_loss 31.731993
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:57:00
run time  0:01:42.485481
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_12/backward_12_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548568
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:57:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f03d1d73210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 815, '_step_count': 816, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.083511 valid_loss:0.080761 each epoch time:20.30769
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000056  train_dp 0.082892  valid_dp 0.080157 reg_loss 10.250972
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:58:43
run time  0:01:41.862084
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_12/backward_12_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548586
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:58:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbbdfcc4fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 820, '_step_count': 821, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.062345 valid_loss:0.063464 each epoch time:19.68476
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.061863  valid_dp 0.062970 reg_loss 9.800113
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:00:25
run time  0:01:40.410965
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_12/backward_12_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548603
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:00:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc96d979850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 825, '_step_count': 826, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.103066 valid_loss:0.101952 each epoch time:20.92460
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000084  valid_dq/boxsize 0.000084  train_dp 0.102314  valid_dp 0.101205 reg_loss 23.847842
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:02:08
run time  0:01:41.683476
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_12/backward_12_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548620
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:02:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7784a17b90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 830, '_step_count': 831, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.061836 valid_loss:0.062984 each epoch time:19.70891
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.061355  valid_dp 0.062490 reg_loss 9.786876
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:03:49
run time  0:01:39.418858
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_12/backward_12_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548637
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:03:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f61c61027d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 835, '_step_count': 836, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.082365 valid_loss:0.079659 each epoch time:20.26991
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000056  train_dp 0.081747  valid_dp 0.079056 reg_loss 10.269282
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:05:30
run time  0:01:39.708806
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_12/backward_12_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548655
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:05:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc385868890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 840, '_step_count': 841, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.061374 valid_loss:0.062553 each epoch time:19.40257
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.060893  valid_dp 0.062059 reg_loss 9.785513
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:07:10
run time  0:01:39.163400
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_12/backward_12_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548672
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:07:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6749069790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 845, '_step_count': 846, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.081894 valid_loss:0.079205 each epoch time:20.32966
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000056  train_dp 0.081275  valid_dp 0.078601 reg_loss 10.264821
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:08:53
run time  0:01:40.963230
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_13/forward_13_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548688
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:08:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbe3461ec90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 850, '_step_count': 851, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.060966 valid_loss:0.062164 each epoch time:20.31163
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.060485  valid_dp 0.061670 reg_loss 9.771146
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:10:35
run time  0:01:40.717703
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_13/forward_13_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548705
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:10:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7febd658b710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 855, '_step_count': 856, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.101481 valid_loss:0.100388 each epoch time:20.72580
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000084  valid_dq/boxsize 0.000084  train_dp 0.100729  valid_dp 0.099641 reg_loss 23.816114
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:12:21
run time  0:01:42.767943
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_13/forward_13_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548722
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:12:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f022b143bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 860, '_step_count': 861, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.060584 valid_loss:0.061782 each epoch time:20.44049
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.060103  valid_dp 0.061288 reg_loss 9.728702
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:14:02
run time  0:01:39.965794
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_13/forward_13_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548739
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:14:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff6ac940c50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 865, '_step_count': 866, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.080964 valid_loss:0.078298 each epoch time:20.47875
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000056  train_dp 0.080346  valid_dp 0.077695 reg_loss 10.203987
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:15:45
run time  0:01:41.536657
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_13/forward_13_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548756
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:15:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f644565ddd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 870, '_step_count': 871, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.121830 valid_loss:0.120130 each epoch time:20.51285
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000115  valid_dq/boxsize 0.000115  train_dp 0.120946  valid_dp 0.119248 reg_loss 31.708769
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:17:28
run time  0:01:42.494745
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_13/forward_13_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548775
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:17:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f67fd5d7290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 875, '_step_count': 876, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.151985 valid_loss:0.148069 each epoch time:20.64929
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000165  valid_dq/boxsize 0.000164  train_dp 0.150914  valid_dp 0.147006 reg_loss 32.167969
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:19:12
run time  0:01:42.633114
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_13/forward_13_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548792
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:19:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc8833e9bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 880, '_step_count': 881, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.120442 valid_loss:0.118803 each epoch time:20.40840
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000114  valid_dq/boxsize 0.000114  train_dp 0.119563  valid_dp 0.117925 reg_loss 31.103005
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:20:57
run time  0:01:43.237781
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_13/backward_13_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548809
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:21:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1baa84a250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 885, '_step_count': 886, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.079825 valid_loss:0.077202 each epoch time:20.19319
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000056  train_dp 0.079210  valid_dp 0.076603 reg_loss 9.864148
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:22:40
run time  0:01:39.972864
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_13/backward_13_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548827
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:22:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe5f14bf590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 890, '_step_count': 891, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.059473 valid_loss:0.060634 each epoch time:19.85183
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.058995  valid_dp 0.060143 reg_loss 9.468480
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:24:22
run time  0:01:40.705585
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_13/backward_13_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548844
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:24:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f43289ea590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 895, '_step_count': 896, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.098766 valid_loss:0.097713 each epoch time:20.24562
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000084  valid_dq/boxsize 0.000083  train_dp 0.098019  valid_dp 0.096971 reg_loss 23.233542
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:26:06
run time  0:01:40.416964
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_13/backward_13_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548861
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:26:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa7a04213d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 900, '_step_count': 901, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.059040 valid_loss:0.060229 each epoch time:19.42447
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.058561  valid_dp 0.059737 reg_loss 9.455563
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:27:47
run time  0:01:39.352984
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_13/backward_13_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548878
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:27:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd36e054a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 905, '_step_count': 906, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.078843 valid_loss:0.076262 each epoch time:20.62118
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000056  train_dp 0.078228  valid_dp 0.075662 reg_loss 9.880796
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:29:30
run time  0:01:41.524843
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_13/backward_13_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548895
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:29:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f22f4c714d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 910, '_step_count': 911, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.058646 valid_loss:0.059865 each epoch time:19.49618
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.058167  valid_dp 0.059374 reg_loss 9.452181
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:31:11
run time  0:01:39.553772
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_13/backward_13_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548912
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:31:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f226e85d410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 915, '_step_count': 916, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.078434 valid_loss:0.075870 each epoch time:20.03544
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000056  train_dp 0.077819  valid_dp 0.075270 reg_loss 9.875877
memory usage : 3.6  at e= 5
end date/time : 20211025, 05:32:53
run time  0:01:41.016238
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_14/forward_14_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548928
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:32:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdb2d114450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 920, '_step_count': 921, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.058297 valid_loss:0.059535 each epoch time:20.00601
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.057818  valid_dp 0.059043 reg_loss 9.437665
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:34:35
run time  0:01:40.579549
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_14/forward_14_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548944
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:34:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fadbbe2f750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 925, '_step_count': 926, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.097378 valid_loss:0.096349 each epoch time:20.23924
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000083  valid_dq/boxsize 0.000083  train_dp 0.096631  valid_dp 0.095607 reg_loss 23.200514
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:36:17
run time  0:01:40.643688
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_14/forward_14_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548961
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:36:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8198a01e10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 930, '_step_count': 931, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.057965 valid_loss:0.059206 each epoch time:20.25518
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.057487  valid_dp 0.058715 reg_loss 9.400050
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:37:58
run time  0:01:39.577890
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_14/forward_14_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548978
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:37:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9bb5e67250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 935, '_step_count': 936, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.077625 valid_loss:0.075083 each epoch time:19.65560
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000056  train_dp 0.077011  valid_dp 0.074484 reg_loss 9.821961
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:39:38
run time  0:01:38.744135
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_14/forward_14_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  548994
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:39:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f19770a93d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 940, '_step_count': 941, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.117112 valid_loss:0.115523 each epoch time:20.43356
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000114  valid_dq/boxsize 0.000114  train_dp 0.116235  valid_dp 0.114647 reg_loss 31.066479
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:41:22
run time  0:01:42.374083
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_14/forward_14_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549011
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:41:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdf22c17210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 945, '_step_count': 946, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.146348 valid_loss:0.142550 each epoch time:20.31664
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000164  valid_dq/boxsize 0.000162  train_dp 0.145286  valid_dp 0.141496 reg_loss 31.392856
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:43:07
run time  0:01:43.522853
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_14/forward_14_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549029
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:43:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f329653e590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 950, '_step_count': 951, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.115890 valid_loss:0.114360 each epoch time:20.42192
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000113  valid_dq/boxsize 0.000113  train_dp 0.115017  valid_dp 0.113488 reg_loss 30.528720
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:44:50
run time  0:01:40.903637
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_14/backward_14_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549046
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:44:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f960215fc10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 955, '_step_count': 956, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.076612 valid_loss:0.074112 each epoch time:19.63779
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000056  train_dp 0.076001  valid_dp 0.073516 reg_loss 9.531927
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:46:32
run time  0:01:40.679552
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_14/backward_14_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549063
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:46:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcb517a2f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 960, '_step_count': 961, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.056989 valid_loss:0.058205 each epoch time:20.03906
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.056513  valid_dp 0.057716 reg_loss 9.181148
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:48:16
run time  0:01:40.428683
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_14/backward_14_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549079
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:48:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f71751b6050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 965, '_step_count': 966, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.094989 valid_loss:0.093991 each epoch time:20.43253
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000083  valid_dq/boxsize 0.000082  train_dp 0.094247  valid_dp 0.093254 reg_loss 22.705386
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:49:59
run time  0:01:42.204504
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_14/backward_14_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549096
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:50:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f761dcecb90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 970, '_step_count': 971, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.056615 valid_loss:0.057856 each epoch time:19.95356
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.056140  valid_dp 0.057367 reg_loss 9.169293
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:51:41
run time  0:01:40.422036
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_14/backward_14_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549113
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:51:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcb70c6ba50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 975, '_step_count': 976, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.075760 valid_loss:0.073296 each epoch time:19.81380
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000056  train_dp 0.075150  valid_dp 0.072701 reg_loss 9.544276
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:53:23
run time  0:01:40.776863
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_14/backward_14_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549131
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:53:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6d37f7d490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 980, '_step_count': 981, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.056276 valid_loss:0.057542 each epoch time:20.10071
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.055800  valid_dp 0.057054 reg_loss 9.163987
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:55:06
run time  0:01:40.644792
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_14/backward_14_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549148
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:55:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc05e2f5b90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 985, '_step_count': 986, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.075402 valid_loss:0.072954 each epoch time:19.90565
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000056  train_dp 0.074791  valid_dp 0.072358 reg_loss 9.538423
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:56:51
run time  0:01:41.064647
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_15/forward_15_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549165
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:56:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdc3ea7a390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 990, '_step_count': 991, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.055973 valid_loss:0.057256 each epoch time:19.60393
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.055497  valid_dp 0.056768 reg_loss 9.149379
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:58:32
run time  0:01:39.419083
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_15/forward_15_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549182
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:58:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efeb3510090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 995, '_step_count': 996, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.093768 valid_loss:0.092789 each epoch time:20.24019
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000083  valid_dq/boxsize 0.000082  train_dp 0.093026  valid_dp 0.092053 reg_loss 22.678288
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:00:15
run time  0:01:41.913144
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_15/forward_15_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549199
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:00:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f15a0dc05d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1000, '_step_count': 1001, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.055687 valid_loss:0.056973 each epoch time:20.25651
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000038  valid_dq/boxsize 0.000039  train_dp 0.055211  valid_dp 0.056485 reg_loss 9.116903
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:01:58
run time  0:01:40.778902
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_15/forward_15_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549217
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:02:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff98ca18610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1005, '_step_count': 1006, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.074699 valid_loss:0.072273 each epoch time:20.40981
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000056  train_dp 0.074089  valid_dp 0.071678 reg_loss 9.490470
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:03:45
run time  0:01:42.382387
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_15/forward_15_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549234
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:03:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4832e5bdd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1010, '_step_count': 1011, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.112954 valid_loss:0.111483 each epoch time:20.75266
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000113  valid_dq/boxsize 0.000113  train_dp 0.112084  valid_dp 0.110615 reg_loss 30.467196
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:05:33
run time  0:01:43.807628
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_15/forward_15_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549251
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:05:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc99486efd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1015, '_step_count': 1016, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.141365 valid_loss:0.137674 each epoch time:21.01790
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000162  valid_dq/boxsize 0.000161  train_dp 0.140311  valid_dp 0.136628 reg_loss 30.713379
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:07:19
run time  0:01:44.577685
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_15/forward_15_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549294
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:07:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe95857a650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1020, '_step_count': 1021, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.111888 valid_loss:0.110480 each epoch time:20.03050
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000113  valid_dq/boxsize 0.000112  train_dp 0.111022  valid_dp 0.109615 reg_loss 29.992288
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:09:03
run time  0:01:40.189464
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_15/backward_15_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549311
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:09:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fefa7a42190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1025, '_step_count': 1026, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.073813 valid_loss:0.071428 each epoch time:19.94946
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000055  train_dp 0.073207  valid_dp 0.070836 reg_loss 9.238875
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:10:45
run time  0:01:39.962236
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_15/backward_15_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549328
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:10:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5fc1b83090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1030, '_step_count': 1031, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054842 valid_loss:0.056110 each epoch time:20.52600
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.054369  valid_dp 0.055625 reg_loss 8.934164
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:12:27
run time  0:01:40.587228
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_15/backward_15_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549345
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:12:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f08449bc290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1035, '_step_count': 1036, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.091694 valid_loss:0.090735 each epoch time:19.99779
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000082  valid_dq/boxsize 0.000082  train_dp 0.090958  valid_dp 0.090003 reg_loss 22.264491
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:14:09
run time  0:01:41.122718
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_15/backward_15_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549362
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:14:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f891c0c9410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1040, '_step_count': 1041, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054521 valid_loss:0.055811 each epoch time:20.13142
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.054049  valid_dp 0.055326 reg_loss 8.922825
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:15:51
run time  0:01:40.363184
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_15/backward_15_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549380
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:15:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa74096c250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1045, '_step_count': 1046, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.073078 valid_loss:0.070727 each epoch time:19.88057
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000055  train_dp 0.072472  valid_dp 0.070135 reg_loss 9.249469
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:17:33
run time  0:01:40.529670
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_15/backward_15_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549399
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:17:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5e4ade3150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1050, '_step_count': 1051, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054229 valid_loss:0.055541 each epoch time:20.12970
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.053756  valid_dp 0.055056 reg_loss 8.918890
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:19:15
run time  0:01:41.065842
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_15/backward_15_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549417
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:19:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4065904590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1055, '_step_count': 1056, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.072766 valid_loss:0.070430 each epoch time:19.91274
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000055  train_dp 0.072159  valid_dp 0.069839 reg_loss 9.243909
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:20:57
run time  0:01:40.371710
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_16/forward_16_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549434
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:20:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f66f850e1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1060, '_step_count': 1061, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.053967 valid_loss:0.055294 each epoch time:20.37702
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.053494  valid_dp 0.054809 reg_loss 8.906420
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:22:39
run time  0:01:40.821533
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_16/forward_16_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549450
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:22:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fba346743d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1065, '_step_count': 1066, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.090628 valid_loss:0.089688 each epoch time:20.02826
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000082  valid_dq/boxsize 0.000082  train_dp 0.089892  valid_dp 0.088957 reg_loss 22.240311
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:24:21
run time  0:01:40.972021
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_16/forward_16_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549468
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:24:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb8516f4a50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1070, '_step_count': 1071, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.053715 valid_loss:0.055044 each epoch time:20.11452
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.053243  valid_dp 0.054560 reg_loss 8.878094
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:26:04
run time  0:01:39.736774
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_16/forward_16_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549487
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:26:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f131c86a1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1075, '_step_count': 1076, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.072146 valid_loss:0.069831 each epoch time:20.36124
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000055  train_dp 0.071540  valid_dp 0.069240 reg_loss 9.200284
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:27:47
run time  0:01:41.308827
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_16/forward_16_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549504
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:27:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa829563310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1080, '_step_count': 1081, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.109295 valid_loss:0.107943 each epoch time:20.01959
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000112  valid_dq/boxsize 0.000112  train_dp 0.108431  valid_dp 0.107080 reg_loss 29.931522
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:29:29
run time  0:01:40.645989
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_16/forward_16_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549529
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:29:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5f24228110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1085, '_step_count': 1086, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.136946 valid_loss:0.133350 each epoch time:20.51490
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000161  valid_dq/boxsize 0.000160  train_dp 0.135900  valid_dp 0.132312 reg_loss 30.112509
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:31:14
run time  0:01:44.328056
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_16/forward_16_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549564
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:31:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7a28405e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1090, '_step_count': 1091, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.108346 valid_loss:0.107042 each epoch time:19.99985
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000112  valid_dq/boxsize 0.000112  train_dp 0.107485  valid_dp 0.106183 reg_loss 29.527066
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:32:59
run time  0:01:40.878757
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_16/backward_16_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549582
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:33:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f97a79e0390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1095, '_step_count': 1096, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.071341 valid_loss:0.069069 each epoch time:20.19957
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000055  train_dp 0.070738  valid_dp 0.068482 reg_loss 8.975082
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:34:41
run time  0:01:40.031999
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_16/backward_16_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549599
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:34:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff206fa9b90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1100, '_step_count': 1101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.052955 valid_loss:0.054265 each epoch time:20.08060
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.052486  valid_dp 0.053783 reg_loss 8.716528
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:36:23
run time  0:01:40.811437
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_16/backward_16_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549615
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:36:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb36a705a50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1105, '_step_count': 1106, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.088768 valid_loss:0.087840 each epoch time:20.67961
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000082  valid_dq/boxsize 0.000081  train_dp 0.088037  valid_dp 0.087114 reg_loss 21.869080
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:38:06
run time  0:01:41.359902
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_16/backward_16_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549632
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:38:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff9c310a790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1110, '_step_count': 1111, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.052670 valid_loss:0.053998 each epoch time:20.17707
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.052201  valid_dp 0.053516 reg_loss 8.707082
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:39:47
run time  0:01:38.903341
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_16/backward_16_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549649
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:39:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9fa6516a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1115, '_step_count': 1116, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.070683 valid_loss:0.068444 each epoch time:20.28554
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000055  train_dp 0.070081  valid_dp 0.067857 reg_loss 8.982977
memory usage : 3.6  at e= 5
end date/time : 20211025, 06:41:32
run time  0:01:40.368894
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_16/backward_16_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549666
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:41:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8d8a70ec50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1120, '_step_count': 1121, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.052409 valid_loss:0.053757 each epoch time:20.22563
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.051940  valid_dp 0.053275 reg_loss 8.700624
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:43:13
run time  0:01:40.115352
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_16/backward_16_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549683
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:43:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f19209c1d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1125, '_step_count': 1126, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.070400 valid_loss:0.068178 each epoch time:19.33941
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000055  train_dp 0.069798  valid_dp 0.067591 reg_loss 8.976058
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:44:54
run time  0:01:39.882997
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_17/forward_17_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549706
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:44:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f02e60e8390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1130, '_step_count': 1131, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.052174 valid_loss:0.053534 each epoch time:20.65299
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.051705  valid_dp 0.053053 reg_loss 8.687623
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:46:36
run time  0:01:40.049635
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_17/forward_17_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549723
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:46:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3232083910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1135, '_step_count': 1136, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.087803 valid_loss:0.086896 each epoch time:19.86256
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000082  valid_dq/boxsize 0.000081  train_dp 0.087073  valid_dp 0.086171 reg_loss 21.846318
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:48:21
run time  0:01:40.263837
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_17/forward_17_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549741
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:48:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f64faefb3d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1140, '_step_count': 1141, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.051947 valid_loss:0.053309 each epoch time:20.03356
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.051479  valid_dp 0.052828 reg_loss 8.664077
memory usage : 3.6  at e= 5
end date/time : 20211025, 06:50:01
run time  0:01:39.687850
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_17/forward_17_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549758
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:50:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd53a896d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1145, '_step_count': 1146, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.069837 valid_loss:0.067640 each epoch time:20.24827
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000055  train_dp 0.069236  valid_dp 0.067054 reg_loss 8.938106
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:51:48
run time  0:01:41.885498
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_17/forward_17_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549776
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:51:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc60c393350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1150, '_step_count': 1151, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.105996 valid_loss:0.104738 each epoch time:20.10193
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000111  valid_dq/boxsize 0.000111  train_dp 0.105139  valid_dp 0.103882 reg_loss 29.430283
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:53:30
run time  0:01:41.199340
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_17/forward_17_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549793
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:53:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7eaf86cad0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1155, '_step_count': 1156, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.132950 valid_loss:0.129441 each epoch time:20.17954
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000160  valid_dq/boxsize 0.000159  train_dp 0.131911  valid_dp 0.128411 reg_loss 29.571676
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:55:17
run time  0:01:42.290821
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_17/forward_17_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549809
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:55:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f705ace35d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1160, '_step_count': 1161, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.105137 valid_loss:0.103922 each epoch time:19.98584
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000111  valid_dq/boxsize 0.000111  train_dp 0.104283  valid_dp 0.103070 reg_loss 29.049746
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:56:59
run time  0:01:39.919302
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_17/backward_17_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549827
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:57:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f97c30d5850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1165, '_step_count': 1166, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.069100 valid_loss:0.066951 each epoch time:19.58993
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000055  train_dp 0.068503  valid_dp 0.066369 reg_loss 8.741555
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:58:40
run time  0:01:40.083271
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_17/backward_17_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549844
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:58:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f88fc594550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1170, '_step_count': 1171, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.051260 valid_loss:0.052598 each epoch time:19.93841
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.050795  valid_dp 0.052120 reg_loss 8.523114
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:00:21
run time  0:01:40.332249
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_17/backward_17_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549861
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:00:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd39bba7790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1175, '_step_count': 1176, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.086121 valid_loss:0.085222 each epoch time:19.55120
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000081  valid_dq/boxsize 0.000081  train_dp 0.085395  valid_dp 0.084501 reg_loss 21.530106
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:02:03
run time  0:01:39.906062
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_17/backward_17_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549878
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:02:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f76fc3a9110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1180, '_step_count': 1181, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.051005 valid_loss:0.052357 each epoch time:19.77164
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.050539  valid_dp 0.051879 reg_loss 8.514644
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:03:45
run time  0:01:40.203435
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_17/backward_17_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549895
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:03:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdf0d5a6910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1185, '_step_count': 1186, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.068509 valid_loss:0.066390 each epoch time:20.19604
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000054  train_dp 0.067912  valid_dp 0.065807 reg_loss 8.747320
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:05:26
run time  0:01:40.212699
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_17/backward_17_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549913
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:05:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0805d184d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1190, '_step_count': 1191, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.050770 valid_loss:0.052140 each epoch time:19.78726
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.050305  valid_dp 0.051662 reg_loss 8.506387
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:07:10
run time  0:01:41.115907
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_17/backward_17_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549929
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:07:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc0b28405d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1195, '_step_count': 1196, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.068252 valid_loss:0.066150 each epoch time:20.07537
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000054  train_dp 0.067654  valid_dp 0.065567 reg_loss 8.738799
memory usage : 3.6  at e= 5
end date/time : 20211025, 07:08:51
run time  0:01:39.633270
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_18/forward_18_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549945
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:08:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f50cc3a3390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1200, '_step_count': 1201, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.050558 valid_loss:0.051938 each epoch time:20.37601
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.050093  valid_dp 0.051461 reg_loss 8.492228
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:10:34
run time  0:01:41.355006
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_18/forward_18_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549962
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:10:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb16b000650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1205, '_step_count': 1206, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.085242 valid_loss:0.084366 each epoch time:20.20673
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000081  valid_dq/boxsize 0.000080  train_dp 0.084518  valid_dp 0.083646 reg_loss 21.500219
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:12:14
run time  0:01:39.430909
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_18/forward_18_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549979
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:12:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f55b4ae6490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1210, '_step_count': 1211, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.050352 valid_loss:0.051733 each epoch time:19.85117
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.049887  valid_dp 0.051256 reg_loss 8.471310
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:13:57
run time  0:01:41.275316
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_18/forward_18_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  549995
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:13:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3828de44d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1215, '_step_count': 1216, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.067742 valid_loss:0.065663 each epoch time:19.78252
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000054  train_dp 0.067146  valid_dp 0.065082 reg_loss 8.704498
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:15:39
run time  0:01:40.799739
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_18/forward_18_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550012
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:15:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8956302f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1220, '_step_count': 1221, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.102997 valid_loss:0.101819 each epoch time:19.67296
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000111  valid_dq/boxsize 0.000110  train_dp 0.102147  valid_dp 0.100970 reg_loss 28.946431
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:17:21
run time  0:01:40.894706
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_18/forward_18_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550032
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:17:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8a7ce9f0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1225, '_step_count': 1226, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.129313 valid_loss:0.125892 each epoch time:20.14045
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000159  valid_dq/boxsize 0.000158  train_dp 0.128282  valid_dp 0.124869 reg_loss 29.083574
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:19:06
run time  0:01:43.483973
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_18/forward_18_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550051
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:19:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1cb06742d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1230, '_step_count': 1231, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.102211 valid_loss:0.101076 each epoch time:20.07159
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000110  valid_dq/boxsize 0.000110  train_dp 0.101363  valid_dp 0.100230 reg_loss 28.589101
memory usage : 3.6  at e= 5
end date/time : 20211025, 07:20:49
run time  0:01:41.900393
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_18/backward_18_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550068
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:20:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f253dc12350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1235, '_step_count': 1236, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.067067 valid_loss:0.065035 each epoch time:20.03053
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000055  valid_dq/boxsize 0.000054  train_dp 0.066474  valid_dp 0.064457 reg_loss 8.531283
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:22:32
run time  0:01:40.934485
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_18/backward_18_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550085
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:22:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f934b6ba1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1240, '_step_count': 1241, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.049724 valid_loss:0.051079 each epoch time:19.88197
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000037  train_dp 0.049262  valid_dp 0.050605 reg_loss 8.347452
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:24:13
run time  0:01:40.035874
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_18/backward_18_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550103
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:24:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff286924410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1245, '_step_count': 1246, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.083705 valid_loss:0.082839 each epoch time:19.75869
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000080  valid_dq/boxsize 0.000080  train_dp 0.082986  valid_dp 0.082124 reg_loss 21.207775
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:25:58
run time  0:01:39.890810
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_18/backward_18_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550120
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:25:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb5b71705d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1250, '_step_count': 1251, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.049491 valid_loss:0.050859 each epoch time:20.03034
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.049029  valid_dp 0.050385 reg_loss 8.339513
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:27:40
run time  0:01:41.066420
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_18/backward_18_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550137
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:27:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2d293cd390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1255, '_step_count': 1256, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.066528 valid_loss:0.064524 each epoch time:20.15412
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000055  valid_dq/boxsize 0.000054  train_dp 0.065936  valid_dp 0.063947 reg_loss 8.534228
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:29:22
run time  0:01:40.897734
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_18/backward_18_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550154
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:29:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1fd5096d90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1260, '_step_count': 1261, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.049277 valid_loss:0.050661 each epoch time:20.22213
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.048816  valid_dp 0.050187 reg_loss 8.330928
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:31:06
run time  0:01:42.077277
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_18/backward_18_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550173
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:31:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbe95c0d210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1265, '_step_count': 1266, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.066292 valid_loss:0.064305 each epoch time:20.15791
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000055  valid_dq/boxsize 0.000054  train_dp 0.065699  valid_dp 0.063728 reg_loss 8.524957
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:32:49
run time  0:01:40.954250
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_19/forward_19_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550189
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:32:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1004f790d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1270, '_step_count': 1271, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.049084 valid_loss:0.050476 each epoch time:20.05397
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.048622  valid_dp 0.050003 reg_loss 8.317686
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:34:30
run time  0:01:39.475743
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_19/forward_19_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550206
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:34:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3a48810f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1275, '_step_count': 1276, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.082896 valid_loss:0.082051 each epoch time:20.02504
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000080  valid_dq/boxsize 0.000080  train_dp 0.082178  valid_dp 0.081337 reg_loss 21.176241
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:36:11
run time  0:01:39.551632
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_19/forward_19_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550226
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:36:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f27528876d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1280, '_step_count': 1281, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.048894 valid_loss:0.050286 each epoch time:20.01607
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.048433  valid_dp 0.049813 reg_loss 8.299493
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:37:53
run time  0:01:40.308485
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_19/forward_19_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550242
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:37:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f19f6719510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1285, '_step_count': 1286, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.065823 valid_loss:0.063860 each epoch time:19.83069
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000055  valid_dq/boxsize 0.000054  train_dp 0.065232  valid_dp 0.063283 reg_loss 8.494396
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:39:35
run time  0:01:39.158562
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_19/forward_19_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550259
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:39:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f19bf85e1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1290, '_step_count': 1291, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.100241 valid_loss:0.099139 each epoch time:20.47743
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000110  valid_dq/boxsize 0.000109  train_dp 0.099397  valid_dp 0.098296 reg_loss 28.476616
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:41:19
run time  0:01:40.369774
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_19/forward_19_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550319
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:41:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1408be2d90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1295, '_step_count': 1296, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.125971 valid_loss:0.122642 each epoch time:20.49043
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000158  valid_dq/boxsize 0.000157  train_dp 0.124948  valid_dp 0.121626 reg_loss 28.639375
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:43:06
run time  0:01:44.953431
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_19/forward_19_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550336
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:43:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4d1b2658d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1300, '_step_count': 1301, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.099520 valid_loss:0.098458 each epoch time:20.32958
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000109  valid_dq/boxsize 0.000109  train_dp 0.098679  valid_dp 0.097619 reg_loss 28.157297
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:44:48
run time  0:01:40.989072
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_19/backward_19_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550356
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:44:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3a16fc3350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1305, '_step_count': 1306, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.065200 valid_loss:0.063279 each epoch time:19.84080
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000055  valid_dq/boxsize 0.000054  train_dp 0.064612  valid_dp 0.062705 reg_loss 8.340555
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:46:29
run time  0:01:39.849610
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_19/backward_19_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550372
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:46:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4905002590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1310, '_step_count': 1311, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.048314 valid_loss:0.049679 each epoch time:20.37665
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.047856  valid_dp 0.049209 reg_loss 8.189763
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:48:12
run time  0:01:40.618101
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_19/backward_19_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550388
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:48:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f54841e0490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1315, '_step_count': 1316, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.081482 valid_loss:0.080642 each epoch time:20.08412
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000080  valid_dq/boxsize 0.000079  train_dp 0.080768  valid_dp 0.079933 reg_loss 20.931042
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:49:54
run time  0:01:40.464110
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_19/backward_19_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550406
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:49:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa59a249c50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1320, '_step_count': 1321, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.048101 valid_loss:0.049478 each epoch time:20.31582
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.047643  valid_dp 0.049008 reg_loss 8.183439
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:51:35
run time  0:01:40.200850
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_19/backward_19_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550423
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:51:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f97ee57f290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1325, '_step_count': 1326, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.064706 valid_loss:0.062810 each epoch time:20.06253
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000055  valid_dq/boxsize 0.000054  train_dp 0.064118  valid_dp 0.062238 reg_loss 8.344799
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:53:18
run time  0:01:41.119297
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_19/backward_19_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550440
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:53:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3afe3fde50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1330, '_step_count': 1331, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.047906 valid_loss:0.049297 each epoch time:20.32539
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.047448  valid_dp 0.048827 reg_loss 8.175640
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:55:00
run time  0:01:40.539970
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_19/backward_19_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550456
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:55:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f550cef47d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1335, '_step_count': 1336, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.064487 valid_loss:0.062609 each epoch time:20.37650
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000055  valid_dq/boxsize 0.000054  train_dp 0.063900  valid_dp 0.062036 reg_loss 8.336695
memory usage : 3.6  at e= 5
end date/time : 20211025, 07:56:43
run time  0:01:41.127933
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_20/forward_20_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550473
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:56:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fee0cc2c8d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1340, '_step_count': 1341, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.047728 valid_loss:0.049128 each epoch time:20.17053
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.047271  valid_dp 0.048659 reg_loss 8.163422
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:58:26
run time  0:01:41.041682
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_20/forward_20_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550489
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:58:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f698cdd4050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1345, '_step_count': 1346, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.080735 valid_loss:0.079912 each epoch time:20.90578
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000080  valid_dq/boxsize 0.000079  train_dp 0.080022  valid_dp 0.079204 reg_loss 20.907214
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:00:09
run time  0:01:42.003209
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_20/forward_20_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550508
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:00:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7824661290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1350, '_step_count': 1351, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.047553 valid_loss:0.048953 each epoch time:19.98205
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.047096  valid_dp 0.048485 reg_loss 8.147718
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:01:50
run time  0:01:39.925145
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_20/forward_20_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550525
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:01:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faa998d45d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1355, '_step_count': 1356, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.064056 valid_loss:0.062199 each epoch time:20.02075
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000055  valid_dq/boxsize 0.000053  train_dp 0.063470  valid_dp 0.061627 reg_loss 8.311115
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:03:34
run time  0:01:40.506469
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_20/forward_20_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550541
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:03:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6e96fde050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1360, '_step_count': 1361, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.097708 valid_loss:0.096670 each epoch time:20.35057
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000109  valid_dq/boxsize 0.000109  train_dp 0.096870  valid_dp 0.095833 reg_loss 28.055146
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:05:16
run time  0:01:40.983742
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_20/forward_20_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550557
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:05:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff5fe5be590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1365, '_step_count': 1366, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.122896 valid_loss:0.119666 each epoch time:20.60146
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000157  valid_dq/boxsize 0.000155  train_dp 0.121880  valid_dp 0.118657 reg_loss 28.261657
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:07:00
run time  0:01:42.722326
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_20/forward_20_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550574
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:07:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9c99ba9d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1370, '_step_count': 1371, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.097046 valid_loss:0.096043 each epoch time:20.27800
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000108  valid_dq/boxsize 0.000108  train_dp 0.096211  valid_dp 0.095210 reg_loss 27.763959
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:08:42
run time  0:01:40.807188
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_20/backward_20_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550591
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:08:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe554de5690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1375, '_step_count': 1376, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.063481 valid_loss:0.061659 each epoch time:20.42499
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000055  valid_dq/boxsize 0.000053  train_dp 0.062898  valid_dp 0.061091 reg_loss 8.178711
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:10:23
run time  0:01:39.390560
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_20/backward_20_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550607
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:10:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8dfc177490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1380, '_step_count': 1381, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.047019 valid_loss:0.048392 each epoch time:19.77830
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.046565  valid_dp 0.047926 reg_loss 8.048747
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:12:03
run time  0:01:39.421379
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_20/backward_20_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550623
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:12:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2e42ba0250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1385, '_step_count': 1386, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.079435 valid_loss:0.078615 each epoch time:20.39249
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000079  valid_dq/boxsize 0.000079  train_dp 0.078727  valid_dp 0.077911 reg_loss 20.681973
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:13:47
run time  0:01:42.464513
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_20/backward_20_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550641
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:13:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc8bcbec9d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1390, '_step_count': 1391, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046824 valid_loss:0.048207 each epoch time:20.02162
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.046370  valid_dp 0.047741 reg_loss 8.043606
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:15:29
run time  0:01:40.170508
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_20/backward_20_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550659
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:15:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f869e9bb410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1395, '_step_count': 1396, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.063028 valid_loss:0.061230 each epoch time:20.08994
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000055  valid_dq/boxsize 0.000053  train_dp 0.062445  valid_dp 0.060662 reg_loss 8.183494
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:17:15
run time  0:01:42.107054
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_20/backward_20_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550679
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:17:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb4688db450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1400, '_step_count': 1401, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046645 valid_loss:0.048043 each epoch time:20.39053
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.046191  valid_dp 0.047577 reg_loss 8.035231
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:19:01
run time  0:01:41.532644
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_20/backward_20_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550698
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:19:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd608f4f650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1405, '_step_count': 1406, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.062826 valid_loss:0.061045 each epoch time:19.93324
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000053  train_dp 0.062243  valid_dp 0.060477 reg_loss 8.175298
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:20:43
run time  0:01:40.629904
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_21/forward_21_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550715
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:20:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f75a64e7b10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1410, '_step_count': 1411, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046481 valid_loss:0.047888 each epoch time:20.70402
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.046028  valid_dp 0.047423 reg_loss 8.023250
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:22:25
run time  0:01:40.802874
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_21/forward_21_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550732
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:22:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4f399aed50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1415, '_step_count': 1416, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.078748 valid_loss:0.077941 each epoch time:19.53436
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000079  valid_dq/boxsize 0.000079  train_dp 0.078041  valid_dp 0.077239 reg_loss 20.657737
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:24:04
run time  0:01:38.000015
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_21/forward_21_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550749
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:24:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2f76f87450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1420, '_step_count': 1421, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046319 valid_loss:0.047727 each epoch time:20.22345
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.045867  valid_dp 0.047262 reg_loss 8.009794
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:25:47
run time  0:01:41.324096
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_21/forward_21_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550767
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:25:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcfb61a1390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1425, '_step_count': 1426, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.062429 valid_loss:0.060667 each epoch time:20.13438
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000053  train_dp 0.061847  valid_dp 0.060100 reg_loss 8.154357
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:27:30
run time  0:01:40.426857
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_21/forward_21_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550784
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:27:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fddf3f8c090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1430, '_step_count': 1431, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.095374 valid_loss:0.094390 each epoch time:20.80518
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000108  valid_dq/boxsize 0.000108  train_dp 0.094542  valid_dp 0.093560 reg_loss 27.659818
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:29:16
run time  0:01:42.757973
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_21/forward_21_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550800
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:29:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe49c2c0410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1435, '_step_count': 1436, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.120067 valid_loss:0.116932 each epoch time:20.72529
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000156  valid_dq/boxsize 0.000154  train_dp 0.119057  valid_dp 0.115930 reg_loss 27.924230
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:31:03
run time  0:01:43.542472
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_21/forward_21_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550819
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:31:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2bd05ce450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1440, '_step_count': 1441, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.094764 valid_loss:0.093811 each epoch time:20.37376
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000108  valid_dq/boxsize 0.000107  train_dp 0.093935  valid_dp 0.092983 reg_loss 27.393191
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:32:45
run time  0:01:40.983669
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_21/backward_21_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550839
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:32:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9bf22a18d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1445, '_step_count': 1446, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.061898 valid_loss:0.060164 each epoch time:19.86259
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000053  train_dp 0.061319  valid_dp 0.059600 reg_loss 8.041465
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:34:29
run time  0:01:40.567925
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_21/backward_21_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550856
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:34:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f10ef0d65d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1450, '_step_count': 1451, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045827 valid_loss:0.047207 each epoch time:19.76884
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.045377  valid_dp 0.046745 reg_loss 7.921474
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:36:11
run time  0:01:39.484028
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_21/backward_21_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550874
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:36:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6194352b90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1455, '_step_count': 1456, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.077548 valid_loss:0.076742 each epoch time:20.36507
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000079  valid_dq/boxsize 0.000078  train_dp 0.076845  valid_dp 0.076044 reg_loss 20.462112
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:37:53
run time  0:01:40.990349
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_21/backward_21_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550890
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:37:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5bf9cbce10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1460, '_step_count': 1461, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045647 valid_loss:0.047037 each epoch time:19.49363
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.045197  valid_dp 0.046575 reg_loss 7.918068
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:39:34
run time  0:01:39.734090
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_21/backward_21_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550907
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:39:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2c2655a410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1465, '_step_count': 1466, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.061481 valid_loss:0.059768 each epoch time:19.62769
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000053  train_dp 0.060903  valid_dp 0.059205 reg_loss 8.048992
memory usage : 3.6  at e= 5
end date/time : 20211025, 08:41:14
run time  0:01:39.316872
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_21/backward_21_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550924
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:41:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f72e5152f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1470, '_step_count': 1471, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045481 valid_loss:0.046885 each epoch time:19.82334
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000036  train_dp 0.045032  valid_dp 0.046423 reg_loss 7.910142
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:42:56
run time  0:01:40.605522
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_21/backward_21_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550941
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:42:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f49747b2710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1475, '_step_count': 1476, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.061294 valid_loss:0.059597 each epoch time:20.83331
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000053  train_dp 0.060716  valid_dp 0.059034 reg_loss 8.042480
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:44:40
run time  0:01:42.348304
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_22/forward_22_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550957
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:44:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f010b2af210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1480, '_step_count': 1481, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045330 valid_loss:0.046742 each epoch time:19.47455
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000036  train_dp 0.044881  valid_dp 0.046281 reg_loss 7.898919
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:46:19
run time  0:01:38.241236
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_22/forward_22_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550974
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:46:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8e5e36e5d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1485, '_step_count': 1486, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.076912 valid_loss:0.076119 each epoch time:20.15396
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000078  valid_dq/boxsize 0.000078  train_dp 0.076210  valid_dp 0.075422 reg_loss 20.445391
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:48:01
run time  0:01:40.226217
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_22/forward_22_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  550992
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:48:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffa42240850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1490, '_step_count': 1491, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045180 valid_loss:0.046592 each epoch time:19.80546
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.044731  valid_dp 0.046131 reg_loss 7.888122
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:49:41
run time  0:01:39.230321
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_22/forward_22_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551009
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:49:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa570e36750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1495, '_step_count': 1496, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.060927 valid_loss:0.059248 each epoch time:20.78497
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000053  train_dp 0.060350  valid_dp 0.058686 reg_loss 8.025899
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:51:23
run time  0:01:41.097991
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_22/forward_22_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551025
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:51:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbbdfab1110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1500, '_step_count': 1501, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.093223 valid_loss:0.092286 each epoch time:20.15190
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000107  valid_dq/boxsize 0.000107  train_dp 0.092398  valid_dp 0.091461 reg_loss 27.316306
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:53:07
run time  0:01:40.878899
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_22/forward_22_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551043
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:53:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2d9a609c50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1505, '_step_count': 1506, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.117476 valid_loss:0.114421 each epoch time:20.74603
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000155  valid_dq/boxsize 0.000153  train_dp 0.116472  valid_dp 0.113425 reg_loss 27.638657
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:54:52
run time  0:01:43.402067
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_22/forward_22_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551061
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:54:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb83122ad90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1510, '_step_count': 1511, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.092668 valid_loss:0.091756 each epoch time:19.95048
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000107  valid_dq/boxsize 0.000107  train_dp 0.091845  valid_dp 0.090934 reg_loss 27.066645
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:56:32
run time  0:01:39.227704
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_22/backward_22_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551078
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:56:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4f6c8f3850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1515, '_step_count': 1516, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.060445 valid_loss:0.058791 each epoch time:19.90282
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000052  train_dp 0.059871  valid_dp 0.058232 reg_loss 7.927100
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:58:15
run time  0:01:40.833098
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_22/backward_22_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551095
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:58:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f27b30915d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1520, '_step_count': 1521, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044733 valid_loss:0.046117 each epoch time:20.27176
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.044287  valid_dp 0.045659 reg_loss 7.808609
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:59:58
run time  0:01:41.660319
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_22/backward_22_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551111
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:59:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4b271c8650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1525, '_step_count': 1526, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.075819 valid_loss:0.075024 each epoch time:20.11907
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000078  valid_dq/boxsize 0.000077  train_dp 0.075121  valid_dp 0.074331 reg_loss 20.266118
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:01:40
run time  0:01:40.913439
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_22/backward_22_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551127
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:01:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1b01840110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1530, '_step_count': 1531, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044570 valid_loss:0.045962 each epoch time:19.84501
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.044124  valid_dp 0.045504 reg_loss 7.804854
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:03:26
run time  0:01:41.603761
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_22/backward_22_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551145
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:03:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8556f21410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1535, '_step_count': 1536, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.060067 valid_loss:0.058434 each epoch time:20.28711
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000052  train_dp 0.059494  valid_dp 0.057875 reg_loss 7.935041
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:05:07
run time  0:01:40.626222
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_22/backward_22_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551162
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:05:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5502a51210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1540, '_step_count': 1541, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044419 valid_loss:0.045826 each epoch time:20.41664
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.043973  valid_dp 0.045368 reg_loss 7.797714
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:06:49
run time  0:01:40.426797
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_22/backward_22_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551179
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:06:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f253bad2450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1545, '_step_count': 1546, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.059896 valid_loss:0.058279 each epoch time:20.34153
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000052  train_dp 0.059323  valid_dp 0.057720 reg_loss 7.930012
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:08:33
run time  0:01:42.437321
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_23/forward_23_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551196
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:08:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2d86399b10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1550, '_step_count': 1551, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044281 valid_loss:0.045697 each epoch time:20.19929
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.043836  valid_dp 0.045239 reg_loss 7.788079
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:10:14
run time  0:01:39.836209
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_23/forward_23_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551213
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:10:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f104f8ba550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1555, '_step_count': 1556, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.075241 valid_loss:0.074455 each epoch time:19.55826
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000078  valid_dq/boxsize 0.000077  train_dp 0.074544  valid_dp 0.073763 reg_loss 20.249560
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:11:55
run time  0:01:39.629187
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_23/forward_23_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551231
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:11:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0c3ec23bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1560, '_step_count': 1561, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044144 valid_loss:0.045559 each epoch time:20.10066
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.043699  valid_dp 0.045102 reg_loss 7.777853
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:13:36
run time  0:01:40.594383
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_23/forward_23_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551247
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:13:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4469117a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1565, '_step_count': 1566, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.059563 valid_loss:0.057962 each epoch time:19.91182
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000052  train_dp 0.058990  valid_dp 0.057404 reg_loss 7.915890
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:15:21
run time  0:01:40.677130
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_23/forward_23_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551264
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:15:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f61d3c89490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1570, '_step_count': 1571, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.091261 valid_loss:0.090368 each epoch time:20.67237
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000107  valid_dq/boxsize 0.000106  train_dp 0.090441  valid_dp 0.089549 reg_loss 26.984706
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:17:06
run time  0:01:41.736249
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_23/forward_23_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551284
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:17:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f73b9e7ea90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1575, '_step_count': 1576, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.115107 valid_loss:0.112127 each epoch time:20.17494
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000154  valid_dq/boxsize 0.000153  train_dp 0.114110  valid_dp 0.111137 reg_loss 27.373679
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:18:51
run time  0:01:43.391948
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_23/forward_23_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551300
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:18:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0d206480d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1580, '_step_count': 1581, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.090744 valid_loss:0.089876 each epoch time:20.25484
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000106  valid_dq/boxsize 0.000106  train_dp 0.089926  valid_dp 0.089059 reg_loss 26.753097
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:20:32
run time  0:01:40.568472
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_23/backward_23_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551316
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:20:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd33389ed90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1585, '_step_count': 1586, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.059116 valid_loss:0.057536 each epoch time:19.90018
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.058546  valid_dp 0.056981 reg_loss 7.829128
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:22:16
run time  0:01:40.218001
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_23/backward_23_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551335
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:22:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feb498ca350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1590, '_step_count': 1591, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043730 valid_loss:0.045115 each epoch time:19.81552
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.043288  valid_dp 0.044661 reg_loss 7.708668
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:23:57
run time  0:01:39.951559
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_23/backward_23_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551352
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:23:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9d0a1e7210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1595, '_step_count': 1596, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.074230 valid_loss:0.073441 each epoch time:20.07368
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000077  valid_dq/boxsize 0.000077  train_dp 0.073537  valid_dp 0.072753 reg_loss 20.084688
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:25:37
run time  0:01:39.326419
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_23/backward_23_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551368
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:25:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb128cd4750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1600, '_step_count': 1601, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043579 valid_loss:0.044972 each epoch time:19.92580
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.043137  valid_dp 0.044518 reg_loss 7.706388
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:27:18
run time  0:01:39.530236
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_23/backward_23_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551385
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:27:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f665a13bdd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1605, '_step_count': 1606, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.058765 valid_loss:0.057205 each epoch time:19.78998
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.058196  valid_dp 0.056650 reg_loss 7.839109
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:28:59
run time  0:01:39.365897
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_23/backward_23_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551402
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:29:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5353a96790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1610, '_step_count': 1611, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043438 valid_loss:0.044846 each epoch time:19.98878
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.042997  valid_dp 0.044392 reg_loss 7.700028
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:30:40
run time  0:01:39.588658
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_23/backward_23_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551421
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:30:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb586aed110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1615, '_step_count': 1616, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.058605 valid_loss:0.057062 each epoch time:19.82233
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.058037  valid_dp 0.056507 reg_loss 7.835571
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:32:20
run time  0:01:38.448193
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_24/forward_24_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551437
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:32:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f136bad41d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1620, '_step_count': 1621, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043310 valid_loss:0.044727 each epoch time:20.06710
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.042868  valid_dp 0.044274 reg_loss 7.691112
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:34:02
run time  0:01:40.757479
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_24/forward_24_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551457
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:34:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9dbc24d590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1625, '_step_count': 1626, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.073692 valid_loss:0.072911 each epoch time:20.47077
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000077  valid_dq/boxsize 0.000077  train_dp 0.073001  valid_dp 0.072224 reg_loss 20.069560
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:35:45
run time  0:01:41.390498
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_24/forward_24_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551473
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:35:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f94765e2e90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1630, '_step_count': 1631, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043182 valid_loss:0.044599 each epoch time:19.82564
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.042741  valid_dp 0.044146 reg_loss 7.683199
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:37:27
run time  0:01:40.607501
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_24/forward_24_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551489
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:37:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f55b4a17950>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1635, '_step_count': 1636, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.058295 valid_loss:0.056768 each epoch time:20.39147
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.057727  valid_dp 0.056214 reg_loss 7.824975
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:39:10
run time  0:01:41.449117
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_24/forward_24_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551505
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:39:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8e4fea74d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1640, '_step_count': 1641, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.089432 valid_loss:0.088586 each epoch time:19.78630
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000106  valid_dq/boxsize 0.000106  train_dp 0.088617  valid_dp 0.087773 reg_loss 26.681032
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:40:51
run time  0:01:39.684554
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_24/forward_24_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551525
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:40:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe2b4d76910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1645, '_step_count': 1646, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.112903 valid_loss:0.110003 each epoch time:20.73360
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000153  valid_dq/boxsize 0.000152  train_dp 0.111912  valid_dp 0.109019 reg_loss 27.140498
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:42:37
run time  0:01:44.324457
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_24/forward_24_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551542
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:42:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0461f67210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1650, '_step_count': 1651, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.088948 valid_loss:0.088126 each epoch time:20.07001
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000106  valid_dq/boxsize 0.000105  train_dp 0.088136  valid_dp 0.087315 reg_loss 26.471501
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:44:19
run time  0:01:40.666695
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_24/backward_24_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551558
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:44:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff945175a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1655, '_step_count': 1656, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.057878 valid_loss:0.056370 each epoch time:20.57450
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.057313  valid_dp 0.055819 reg_loss 7.747216
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:46:01
run time  0:01:40.082733
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_24/backward_24_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551575
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:46:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5c1d8f17d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1660, '_step_count': 1661, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042796 valid_loss:0.044186 each epoch time:19.99109
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.042357  valid_dp 0.043735 reg_loss 7.621770
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:47:41
run time  0:01:39.124249
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_24/backward_24_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551592
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:47:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6a8531c290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1665, '_step_count': 1666, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.072751 valid_loss:0.071967 each epoch time:19.93940
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000077  valid_dq/boxsize 0.000076  train_dp 0.072063  valid_dp 0.071284 reg_loss 19.923191
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:49:25
run time  0:01:40.173823
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_24/backward_24_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551610
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:49:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f31486f6190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1670, '_step_count': 1671, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042654 valid_loss:0.044054 each epoch time:20.07222
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.042216  valid_dp 0.043603 reg_loss 7.621468
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:51:05
run time  0:01:39.010141
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_24/backward_24_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551627
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:51:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f21d3333a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1675, '_step_count': 1676, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.057552 valid_loss:0.056062 each epoch time:20.08155
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000051  train_dp 0.056987  valid_dp 0.055512 reg_loss 7.760853
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:52:47
run time  0:01:40.768078
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_24/backward_24_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551644
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:52:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7e18006110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1680, '_step_count': 1681, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042523 valid_loss:0.043937 each epoch time:19.88430
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.042085  valid_dp 0.043486 reg_loss 7.614674
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:54:28
run time  0:01:40.106523
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_24/backward_24_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551660
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:54:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5d2f262750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1685, '_step_count': 1686, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.057403 valid_loss:0.055929 each epoch time:20.25310
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000051  train_dp 0.056838  valid_dp 0.055379 reg_loss 7.757901
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:56:11
run time  0:01:41.205539
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_25/forward_25_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551677
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:56:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8e6193f150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1690, '_step_count': 1691, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042402 valid_loss:0.043826 each epoch time:20.14453
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.041964  valid_dp 0.043376 reg_loss 7.605857
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:57:54
run time  0:01:39.886241
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_25/forward_25_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551694
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:57:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f96ff195d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1695, '_step_count': 1696, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.072250 valid_loss:0.071473 each epoch time:19.87432
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000077  valid_dq/boxsize 0.000076  train_dp 0.071563  valid_dp 0.070791 reg_loss 19.915477
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:59:36
run time  0:01:38.661351
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_25/forward_25_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551712
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:59:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f96c8518610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1700, '_step_count': 1701, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042283 valid_loss:0.043708 each epoch time:19.84465
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.041845  valid_dp 0.043258 reg_loss 7.600132
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:01:19
run time  0:01:39.446257
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_25/forward_25_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551729
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:01:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f978332ed90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1705, '_step_count': 1706, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.057113 valid_loss:0.055655 each epoch time:20.13073
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000051  train_dp 0.056550  valid_dp 0.055105 reg_loss 7.751604
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:03:01
run time  0:01:40.755397
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_25/forward_25_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551745
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:03:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f95665a9250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1710, '_step_count': 1711, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.087726 valid_loss:0.086921 each epoch time:20.47972
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000105  valid_dq/boxsize 0.000105  train_dp 0.086916  valid_dp 0.086112 reg_loss 26.399377
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:04:42
run time  0:01:39.593730
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_25/forward_25_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551763
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:04:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd4011b2050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1715, '_step_count': 1716, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.110852 valid_loss:0.108022 each epoch time:20.90665
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000152  valid_dq/boxsize 0.000151  train_dp 0.109866  valid_dp 0.107042 reg_loss 26.940288
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:06:27
run time  0:01:43.536061
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_25/forward_25_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551779
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:06:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa61ec4ec50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1720, '_step_count': 1721, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.087274 valid_loss:0.086491 each epoch time:20.22540
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000105  valid_dq/boxsize 0.000105  train_dp 0.086466  valid_dp 0.085685 reg_loss 26.205749
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:08:09
run time  0:01:40.847959
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_25/backward_25_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551796
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:08:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0801f90310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1725, '_step_count': 1726, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.056721 valid_loss:0.055281 each epoch time:20.47789
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000051  train_dp 0.056160  valid_dp 0.054734 reg_loss 7.676455
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:09:52
run time  0:01:41.597933
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_25/backward_25_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551814
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:09:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff53f67c450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1730, '_step_count': 1731, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041922 valid_loss:0.043323 each epoch time:19.69926
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.041487  valid_dp 0.042876 reg_loss 7.544115
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:11:35
run time  0:01:39.704978
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_25/backward_25_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551830
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:11:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fecddaa6c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1735, '_step_count': 1736, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.071370 valid_loss:0.070588 each epoch time:20.21297
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000076  valid_dq/boxsize 0.000076  train_dp 0.070687  valid_dp 0.069909 reg_loss 19.776167
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:13:18
run time  0:01:40.357101
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_25/backward_25_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551847
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:13:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f60a9f570d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1740, '_step_count': 1741, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041789 valid_loss:0.043200 each epoch time:20.10545
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.041354  valid_dp 0.042753 reg_loss 7.543410
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:15:02
run time  0:01:40.084506
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_25/backward_25_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551864
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:15:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcde01614d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1745, '_step_count': 1746, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.056417 valid_loss:0.054993 each epoch time:20.25979
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.055856  valid_dp 0.054446 reg_loss 7.689588
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:16:43
run time  0:01:39.694563
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_25/backward_25_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551881
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:16:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff96cfae0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1750, '_step_count': 1751, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041666 valid_loss:0.043091 each epoch time:20.04212
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.041231  valid_dp 0.042644 reg_loss 7.536486
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:18:27
run time  0:01:41.720021
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_25/backward_25_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551901
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:18:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc501971a50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1755, '_step_count': 1756, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.056276 valid_loss:0.054868 each epoch time:19.69901
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.055716  valid_dp 0.054322 reg_loss 7.685861
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:20:07
run time  0:01:39.070955
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_26/forward_26_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551918
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:20:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fde9b0c98d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1760, '_step_count': 1761, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041553 valid_loss:0.042988 each epoch time:19.50994
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.041118  valid_dp 0.042542 reg_loss 7.527695
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:21:48
run time  0:01:39.240493
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_26/forward_26_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551937
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:21:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5260e38b90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1765, '_step_count': 1766, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.070901 valid_loss:0.070123 each epoch time:20.05550
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000076  valid_dq/boxsize 0.000076  train_dp 0.070219  valid_dp 0.069446 reg_loss 19.770542
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:23:35
run time  0:01:43.135340
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_26/forward_26_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551954
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:23:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f524f3651d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1770, '_step_count': 1771, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041440 valid_loss:0.042878 each epoch time:20.16990
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.041006  valid_dp 0.042432 reg_loss 7.521924
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:25:17
run time  0:01:40.433583
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_26/forward_26_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551971
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:25:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4419b84590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1775, '_step_count': 1776, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.056006 valid_loss:0.054611 each epoch time:20.08543
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.055446  valid_dp 0.054066 reg_loss 7.679448
memory usage : 3.6  at e= 5
end date/time : 20211025, 10:26:59
run time  0:01:41.399555
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_26/forward_26_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  551990
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:27:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efbd8c5d250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1780, '_step_count': 1781, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.086130 valid_loss:0.085360 each epoch time:20.11421
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000105  valid_dq/boxsize 0.000104  train_dp 0.085325  valid_dp 0.084556 reg_loss 26.116012
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:28:43
run time  0:01:42.613473
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_26/forward_26_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552006
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:28:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4b5f0ea310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1785, '_step_count': 1786, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.108931 valid_loss:0.106172 each epoch time:21.05663
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000151  valid_dq/boxsize 0.000150  train_dp 0.107950  valid_dp 0.105198 reg_loss 26.745066
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:30:31
run time  0:01:45.941528
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_26/forward_26_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552028
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:30:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe48cc77d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1790, '_step_count': 1791, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.085706 valid_loss:0.084960 each epoch time:20.16516
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000104  valid_dq/boxsize 0.000104  train_dp 0.084904  valid_dp 0.084159 reg_loss 25.937700
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:32:13
run time  0:01:39.764747
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_26/backward_26_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552047
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:32:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffa3ccdd610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1795, '_step_count': 1796, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.055642 valid_loss:0.054260 each epoch time:19.53671
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.055084  valid_dp 0.053717 reg_loss 7.612086
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:33:53
run time  0:01:38.215607
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_26/backward_26_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552063
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:33:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f88aaa4fc10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1800, '_step_count': 1801, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041103 valid_loss:0.042519 each epoch time:19.75712
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.040671  valid_dp 0.042075 reg_loss 7.471323
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:35:37
run time  0:01:40.384076
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_26/backward_26_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552080
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:35:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f10bd5bf710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1805, '_step_count': 1806, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.070079 valid_loss:0.069291 each epoch time:20.35466
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000076  valid_dq/boxsize 0.000075  train_dp 0.069400  valid_dp 0.068617 reg_loss 19.653495
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:37:20
run time  0:01:41.485156
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_26/backward_26_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552097
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:37:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7a6b7bfb90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1810, '_step_count': 1811, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.040978 valid_loss:0.042405 each epoch time:20.51885
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.040547  valid_dp 0.041961 reg_loss 7.471324
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:39:02
run time  0:01:41.564310
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_26/backward_26_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552113
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:39:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f11c83b41d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1815, '_step_count': 1816, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.055358 valid_loss:0.053990 each epoch time:19.93693
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.054801  valid_dp 0.053448 reg_loss 7.626866
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:40:44
run time  0:01:40.307063
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_26/backward_26_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552131
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:40:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f903a7be350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1820, '_step_count': 1821, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.040863 valid_loss:0.042304 each epoch time:20.00593
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.040432  valid_dp 0.041860 reg_loss 7.464825
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:42:26
run time  0:01:39.823990
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_26/backward_26_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552148
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:42:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd88bb52810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1825, '_step_count': 1826, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.055227 valid_loss:0.053874 each epoch time:20.35780
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.054670  valid_dp 0.053331 reg_loss 7.623473
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:44:08
run time  0:01:40.254373
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_27/forward_27_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552164
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:44:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa5ff434d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1830, '_step_count': 1831, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.040757 valid_loss:0.042208 each epoch time:19.55752
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.040326  valid_dp 0.041765 reg_loss 7.456861
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:45:48
run time  0:01:38.329192
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_27/forward_27_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552181
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:45:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f556f0a6910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1835, '_step_count': 1836, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.069641 valid_loss:0.068858 each epoch time:20.35812
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000076  valid_dq/boxsize 0.000075  train_dp 0.068962  valid_dp 0.068184 reg_loss 19.651559
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:47:30
run time  0:01:40.678248
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_27/forward_27_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552198
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:47:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f39e54ec590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1840, '_step_count': 1841, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.040651 valid_loss:0.042105 each epoch time:20.21179
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.040221  valid_dp 0.041662 reg_loss 7.452391
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:49:11
run time  0:01:40.429119
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_27/forward_27_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552215
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:49:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff4a8902250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1845, '_step_count': 1846, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054975 valid_loss:0.053633 each epoch time:19.67169
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.054419  valid_dp 0.053091 reg_loss 7.619396
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:50:52
run time  0:01:38.941976
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_27/forward_27_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552232
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:50:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4e4a07e590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1850, '_step_count': 1851, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.084640 valid_loss:0.083907 each epoch time:20.16475
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000104  valid_dq/boxsize 0.000104  train_dp 0.083840  valid_dp 0.083108 reg_loss 25.865937
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:52:35
run time  0:01:41.311670
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_27/forward_27_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552248
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:52:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f37f536a590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1855, '_step_count': 1856, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.107133 valid_loss:0.104449 each epoch time:20.23580
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000150  valid_dq/boxsize 0.000149  train_dp 0.106157  valid_dp 0.103480 reg_loss 26.575934
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:54:18
run time  0:01:41.901917
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_27/forward_27_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552266
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:54:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f426f896e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1860, '_step_count': 1861, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.084242 valid_loss:0.083531 each epoch time:19.57635
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000104  valid_dq/boxsize 0.000104  train_dp 0.083444  valid_dp 0.082734 reg_loss 25.694007
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:55:58
run time  0:01:39.042558
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_27/backward_27_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552284
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:56:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa22a09a250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1865, '_step_count': 1866, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054636 valid_loss:0.053303 each epoch time:19.69844
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000050  train_dp 0.054083  valid_dp 0.052764 reg_loss 7.557193
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:57:41
run time  0:01:38.202905
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_27/backward_27_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552301
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:57:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1bac434fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1870, '_step_count': 1871, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.040339 valid_loss:0.041769 each epoch time:20.42280
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.039910  valid_dp 0.041328 reg_loss 7.407974
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:59:24
run time  0:01:40.847363
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_27/backward_27_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552318
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:59:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f39fd6ca450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1875, '_step_count': 1876, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.068872 valid_loss:0.068080 each epoch time:19.91196
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000075  train_dp 0.068197  valid_dp 0.067410 reg_loss 19.542583
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:01:05
run time  0:01:40.836586
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_27/backward_27_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552334
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:01:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8778d0ea90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1880, '_step_count': 1881, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.040223 valid_loss:0.041662 each epoch time:20.50923
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.039794  valid_dp 0.041222 reg_loss 7.408538
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:02:48
run time  0:01:41.622147
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_27/backward_27_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552351
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:02:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f951f226350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1885, '_step_count': 1886, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054373 valid_loss:0.053053 each epoch time:20.01453
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000050  train_dp 0.053820  valid_dp 0.052514 reg_loss 7.570715
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:04:31
run time  0:01:41.282547
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_27/backward_27_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552367
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:04:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f54e4a91b10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1890, '_step_count': 1891, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.040116 valid_loss:0.041569 each epoch time:19.79499
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.039687  valid_dp 0.041129 reg_loss 7.402653
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:06:11
run time  0:01:38.749698
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_27/backward_27_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552384
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:06:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5844c082d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1895, '_step_count': 1896, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054251 valid_loss:0.052945 each epoch time:20.16733
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000050  train_dp 0.053697  valid_dp 0.052406 reg_loss 7.566581
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:07:53
run time  0:01:41.014678
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_28/forward_28_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552401
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:07:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7effa02d6b50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1900, '_step_count': 1901, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.040017 valid_loss:0.041481 each epoch time:20.03352
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.039589  valid_dp 0.041041 reg_loss 7.395285
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:09:36
run time  0:01:41.300840
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_28/forward_28_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552417
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:09:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2d5ca4ec50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1905, '_step_count': 1906, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.068464 valid_loss:0.067678 each epoch time:20.05327
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000075  train_dp 0.067790  valid_dp 0.067008 reg_loss 19.541589
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:11:18
run time  0:01:40.227405
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_28/forward_28_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552436
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:11:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f801992e710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1910, '_step_count': 1911, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.039919 valid_loss:0.041385 each epoch time:20.12122
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.039492  valid_dp 0.040945 reg_loss 7.391628
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:13:01
run time  0:01:40.546006
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_28/forward_28_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552452
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:13:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3540d44450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1915, '_step_count': 1916, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054017 valid_loss:0.052721 each epoch time:19.81829
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000050  train_dp 0.053465  valid_dp 0.052183 reg_loss 7.563294
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:14:43
run time  0:01:40.597624
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_28/forward_28_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552469
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:14:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8838fdb510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1920, '_step_count': 1921, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.083249 valid_loss:0.082552 each epoch time:20.53809
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000103  valid_dq/boxsize 0.000103  train_dp 0.082453  valid_dp 0.081758 reg_loss 25.628046
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:16:29
run time  0:01:41.957014
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_28/forward_28_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552486
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:16:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8d6838f190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1925, '_step_count': 1926, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.105453 valid_loss:0.102847 each epoch time:20.35829
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000150  valid_dq/boxsize 0.000149  train_dp 0.104482  valid_dp 0.101882 reg_loss 26.421148
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:18:14
run time  0:01:43.049544
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_28/forward_28_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552506
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:18:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f93085021d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1930, '_step_count': 1931, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.082875 valid_loss:0.082204 each epoch time:19.77918
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000103  valid_dq/boxsize 0.000103  train_dp 0.082081  valid_dp 0.081411 reg_loss 25.467736
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:19:58
run time  0:01:40.301485
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_28/backward_28_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552523
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:19:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f62cea6f710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1935, '_step_count': 1936, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.053702 valid_loss:0.052414 each epoch time:20.36354
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.053152  valid_dp 0.051878 reg_loss 7.506354
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:21:40
run time  0:01:40.860500
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_28/backward_28_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552542
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:21:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8416f57150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1940, '_step_count': 1941, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.039631 valid_loss:0.041072 each epoch time:19.62436
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.039205  valid_dp 0.040634 reg_loss 7.354340
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:23:22
run time  0:01:39.444103
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_28/backward_28_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552559
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:23:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f756188cad0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1945, '_step_count': 1946, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.067748 valid_loss:0.066954 each epoch time:19.53460
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.067077  valid_dp 0.066288 reg_loss 19.439328
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:25:04
run time  0:01:40.515681
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_28/backward_28_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552576
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:25:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcc30678f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1950, '_step_count': 1951, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.039523 valid_loss:0.040973 each epoch time:19.93401
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.039097  valid_dp 0.040535 reg_loss 7.355342
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:26:46
run time  0:01:40.229245
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_28/backward_28_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552593
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:26:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faec6c60b10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1955, '_step_count': 1956, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.053457 valid_loss:0.052181 each epoch time:19.72706
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.052907  valid_dp 0.051646 reg_loss 7.521186
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:28:27
run time  0:01:38.982820
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_28/backward_28_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552610
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:28:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc86fcde910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1960, '_step_count': 1961, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.039423 valid_loss:0.040886 each epoch time:19.86137
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.038997  valid_dp 0.040449 reg_loss 7.349220
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:30:08
run time  0:01:39.555136
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_28/backward_28_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552629
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:30:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efe098c3f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1965, '_step_count': 1966, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.053343 valid_loss:0.052081 each epoch time:20.20558
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.052793  valid_dp 0.051546 reg_loss 7.516990
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:31:51
run time  0:01:41.167848
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_29/forward_29_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552645
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:31:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4b81463e90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1970, '_step_count': 1971, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.039331 valid_loss:0.040804 each epoch time:19.87345
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.038906  valid_dp 0.040367 reg_loss 7.341661
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:33:33
run time  0:01:40.533962
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_29/forward_29_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552663
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:33:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd429fe03d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1975, '_step_count': 1976, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.067368 valid_loss:0.066577 each epoch time:20.03690
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.066697  valid_dp 0.065912 reg_loss 19.438649
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:35:16
run time  0:01:41.062861
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_29/forward_29_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552682
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:35:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff5ce064310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1980, '_step_count': 1981, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.039239 valid_loss:0.040715 each epoch time:20.12961
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.038815  valid_dp 0.040278 reg_loss 7.337434
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:36:56
run time  0:01:39.274840
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_29/forward_29_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552699
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:36:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8841668f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1985, '_step_count': 1986, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.053125 valid_loss:0.051874 each epoch time:19.22772
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.052576  valid_dp 0.051339 reg_loss 7.513046
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:38:38
run time  0:01:40.754499
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_29/forward_29_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552715
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:38:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feb0f533190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1990, '_step_count': 1991, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.081951 valid_loss:0.081295 each epoch time:20.45928
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000103  valid_dq/boxsize 0.000103  train_dp 0.081159  valid_dp 0.080505 reg_loss 25.409691
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:40:22
run time  0:01:41.618692
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_29/forward_29_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552732
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:40:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcb0fcc7450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1995, '_step_count': 1996, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.103886 valid_loss:0.101359 each epoch time:20.31603
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000149  valid_dq/boxsize 0.000148  train_dp 0.102919  valid_dp 0.100398 reg_loss 26.282707
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:42:07
run time  0:01:43.189705
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_29/forward_29_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552749
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:42:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5a74ae0050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2000, '_step_count': 2001, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.081601 valid_loss:0.080972 each epoch time:19.90523
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000103  valid_dq/boxsize 0.000102  train_dp 0.080811  valid_dp 0.080183 reg_loss 25.264988
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:43:49
run time  0:01:41.062018
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_29/backward_29_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552767
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:43:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb659a15350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2005, '_step_count': 2006, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.052834 valid_loss:0.051590 each epoch time:20.31234
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.052287  valid_dp 0.051058 reg_loss 7.464718
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:45:32
run time  0:01:41.450483
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_29/backward_29_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552783
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:45:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb597a9f0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2010, '_step_count': 2011, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.038975 valid_loss:0.040424 each epoch time:19.86809
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.038552  valid_dp 0.039989 reg_loss 7.302617
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:47:13
run time  0:01:39.872867
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_29/backward_29_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552799
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:47:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4f0631c850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2015, '_step_count': 2016, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.066702 valid_loss:0.065901 each epoch time:19.85128
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.066035  valid_dp 0.065238 reg_loss 19.350200
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:48:54
run time  0:01:40.184656
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_29/backward_29_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552816
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:48:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fac5eff7f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2020, '_step_count': 2021, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.038876 valid_loss:0.040333 each epoch time:20.17856
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.038453  valid_dp 0.039898 reg_loss 7.301899
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:50:35
run time  0:01:39.851313
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_29/backward_29_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552834
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:50:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb179d45250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2025, '_step_count': 2026, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.052610 valid_loss:0.051378 each epoch time:20.10766
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.052063  valid_dp 0.050845 reg_loss 7.476350
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:52:17
run time  0:01:40.581668
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_29/backward_29_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552851
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:52:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f44571abe90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2030, '_step_count': 2031, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.038784 valid_loss:0.040253 each epoch time:20.75848
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.038362  valid_dp 0.039819 reg_loss 7.296132
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:54:02
run time  0:01:42.581275
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_29/backward_29_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552868
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:54:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f84186ea610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2035, '_step_count': 2036, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.052504 valid_loss:0.051287 each epoch time:20.10768
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.051957  valid_dp 0.050754 reg_loss 7.471853
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:55:45
run time  0:01:41.280608
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_30/forward_30_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552885
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:55:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe7a8b3df10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2040, '_step_count': 2041, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.038700 valid_loss:0.040178 each epoch time:20.01301
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.038277  valid_dp 0.039743 reg_loss 7.289019
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:57:26
run time  0:01:39.617186
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_30/forward_30_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552902
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:57:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcb5c8090d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2045, '_step_count': 2046, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.066353 valid_loss:0.065555 each epoch time:19.70658
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.065686  valid_dp 0.064893 reg_loss 19.348055
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:59:07
run time  0:01:39.950421
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_30/forward_30_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552918
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:59:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f65685b9110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2050, '_step_count': 2051, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.038616 valid_loss:0.040096 each epoch time:19.60478
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.038194  valid_dp 0.039661 reg_loss 7.284267
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:00:48
run time  0:01:39.837610
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_30/forward_30_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552937
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:00:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbab6db0a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2055, '_step_count': 2056, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.052305 valid_loss:0.051097 each epoch time:20.09484
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.051759  valid_dp 0.050565 reg_loss 7.467598
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:02:29
run time  0:01:40.071712
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_30/forward_30_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552954
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:02:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2fa1910550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2060, '_step_count': 2061, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.080757 valid_loss:0.080139 each epoch time:20.10465
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000102  valid_dq/boxsize 0.000102  train_dp 0.079969  valid_dp 0.079353 reg_loss 25.191538
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:04:15
run time  0:01:41.391209
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_30/forward_30_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552971
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:04:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8cf1795850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2065, '_step_count': 2066, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.102448 valid_loss:0.099997 each epoch time:20.95289
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000148  valid_dq/boxsize 0.000147  train_dp 0.101485  valid_dp 0.099040 reg_loss 26.136837
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:06:03
run time  0:01:44.397843
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_30/forward_30_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  552987
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:06:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe685d23dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2070, '_step_count': 2071, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.080428 valid_loss:0.079837 each epoch time:20.28791
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000102  valid_dq/boxsize 0.000102  train_dp 0.079642  valid_dp 0.079052 reg_loss 25.045687
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:07:46
run time  0:01:41.606591
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_30/backward_30_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553005
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:07:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f014a499790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2075, '_step_count': 2076, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.052036 valid_loss:0.050835 each epoch time:19.95897
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.051492  valid_dp 0.050305 reg_loss 7.419766
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:09:27
run time  0:01:39.548959
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_30/backward_30_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553022
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:09:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe73740d150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2080, '_step_count': 2081, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.038373 valid_loss:0.039824 each epoch time:20.21984
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.037952  valid_dp 0.039391 reg_loss 7.250916
memory usage : 3.6  at e= 5
end date/time : 20211025, 12:11:09
run time  0:01:40.303131
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_30/backward_30_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553039
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:11:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6563ce0210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2085, '_step_count': 2086, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.065736 valid_loss:0.064936 each epoch time:20.28597
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000074  train_dp 0.065072  valid_dp 0.064277 reg_loss 19.266171
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:12:50
run time  0:01:39.410946
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_30/backward_30_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553056
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:12:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff4f4901110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2090, '_step_count': 2091, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.038280 valid_loss:0.039739 each epoch time:20.05396
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.037859  valid_dp 0.039307 reg_loss 7.251553
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:14:32
run time  0:01:40.224968
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_30/backward_30_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553072
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:14:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8add2c0210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2095, '_step_count': 2096, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.051826 valid_loss:0.050636 each epoch time:19.85181
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.051282  valid_dp 0.050107 reg_loss 7.432400
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:16:14
run time  0:01:40.618919
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_30/backward_30_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553088
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:16:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f338bb5a2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2100, '_step_count': 2101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.038193 valid_loss:0.039665 each epoch time:19.88120
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.037773  valid_dp 0.039233 reg_loss 7.246057
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:17:54
run time  0:01:38.696260
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_30/backward_30_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553108
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:17:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faa3166b110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2105, '_step_count': 2106, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.051726 valid_loss:0.050551 each epoch time:20.11464
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.051182  valid_dp 0.050022 reg_loss 7.428028
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:19:37
run time  0:01:41.278496
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_31/forward_31_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553124
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:19:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0cbb329990>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2110, '_step_count': 2111, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.038114 valid_loss:0.039594 each epoch time:20.22205
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.037694  valid_dp 0.039162 reg_loss 7.239948
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:21:18
run time  0:01:40.237692
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_31/forward_31_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553141
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:21:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fad5a389390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2115, '_step_count': 2116, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.065409 valid_loss:0.064616 each epoch time:19.42063
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000074  train_dp 0.064746  valid_dp 0.063957 reg_loss 19.267137
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:23:00
run time  0:01:40.607119
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_31/forward_31_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553157
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:23:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc38aa20d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2120, '_step_count': 2121, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.038035 valid_loss:0.039518 each epoch time:19.65916
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.037615  valid_dp 0.039086 reg_loss 7.236591
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:24:42
run time  0:01:39.965395
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_31/forward_31_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553174
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:24:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe2f1fbec90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2125, '_step_count': 2126, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.051539 valid_loss:0.050374 each epoch time:19.76566
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000049  train_dp 0.050996  valid_dp 0.049846 reg_loss 7.424965
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:26:24
run time  0:01:41.059676
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_31/forward_31_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553192
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:26:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0851dc4f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2130, '_step_count': 2131, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.079636 valid_loss:0.079055 each epoch time:20.01927
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000102  valid_dq/boxsize 0.000102  train_dp 0.078851  valid_dp 0.078271 reg_loss 24.976264
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:28:06
run time  0:01:40.877147
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_31/forward_31_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553208
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:28:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9e71531ed0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2135, '_step_count': 2136, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.101096 valid_loss:0.098711 each epoch time:20.76813
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000148  valid_dq/boxsize 0.000147  train_dp 0.100137  valid_dp 0.097758 reg_loss 26.001647
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:29:51
run time  0:01:42.824849
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_31/forward_31_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553225
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:29:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fef874e6f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2140, '_step_count': 2141, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.079323 valid_loss:0.078769 each epoch time:20.20476
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000102  valid_dq/boxsize 0.000102  train_dp 0.078540  valid_dp 0.077987 reg_loss 24.834251
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:31:33
run time  0:01:40.992761
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_31/backward_31_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553243
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:31:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f25dae66fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2145, '_step_count': 2146, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.051287 valid_loss:0.050126 each epoch time:19.99031
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000049  train_dp 0.050746  valid_dp 0.049599 reg_loss 7.378583
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:33:14
run time  0:01:39.952530
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_31/backward_31_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553263
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:33:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3d5f1414d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2150, '_step_count': 2151, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.037807 valid_loss:0.039260 each epoch time:20.78354
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.037389  valid_dp 0.038830 reg_loss 7.206156
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:34:58
run time  0:01:42.796821
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_31/backward_31_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553279
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:35:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbfcf8d43d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2155, '_step_count': 2156, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.064829 valid_loss:0.064034 each epoch time:20.46883
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000073  train_dp 0.064168  valid_dp 0.063378 reg_loss 19.189896
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:36:44
run time  0:01:41.910783
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_31/backward_31_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553297
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:36:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe9b8018390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2160, '_step_count': 2161, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.037719 valid_loss:0.039182 each epoch time:20.00070
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.037301  valid_dp 0.038752 reg_loss 7.207366
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:38:26
run time  0:01:39.975848
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_31/backward_31_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553314
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:38:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe55b3fb590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2165, '_step_count': 2166, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.051089 valid_loss:0.049940 each epoch time:20.22404
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000049  train_dp 0.050548  valid_dp 0.049413 reg_loss 7.390313
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:40:09
run time  0:01:42.152498
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_31/backward_31_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553331
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:40:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f59180c5350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2170, '_step_count': 2171, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.037637 valid_loss:0.039112 each epoch time:20.15553
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.037220  valid_dp 0.038682 reg_loss 7.202329
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:41:51
run time  0:01:40.350521
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_31/backward_31_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553347
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:41:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5f5e0a3f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2175, '_step_count': 2176, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.050995 valid_loss:0.049860 each epoch time:20.16573
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000049  train_dp 0.050454  valid_dp 0.049334 reg_loss 7.385530
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:43:33
run time  0:01:41.104743
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_32/forward_32_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553365
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:43:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd59ce4a450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2180, '_step_count': 2181, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.037562 valid_loss:0.039046 each epoch time:20.00589
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.037145  valid_dp 0.038616 reg_loss 7.196458
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:45:15
run time  0:01:40.685557
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_32/forward_32_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553381
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:45:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2d5248d050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2185, '_step_count': 2186, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.064522 valid_loss:0.063736 each epoch time:19.61717
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000073  train_dp 0.063862  valid_dp 0.063081 reg_loss 19.191226
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:46:56
run time  0:01:39.991315
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_32/forward_32_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553398
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:47:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb915094590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2190, '_step_count': 2191, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.037487 valid_loss:0.038974 each epoch time:20.47515
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.037070  valid_dp 0.038545 reg_loss 7.193671
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:48:41
run time  0:01:40.417530
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_32/forward_32_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553415
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:48:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fef5b1ec810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2195, '_step_count': 2196, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.050819 valid_loss:0.049693 each epoch time:20.04903
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000049  train_dp 0.050279  valid_dp 0.049167 reg_loss 7.383315
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:50:22
run time  0:01:40.451962
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_32/forward_32_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553432
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:50:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f26b1531c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2200, '_step_count': 2201, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.078577 valid_loss:0.078034 each epoch time:20.12885
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000101  valid_dq/boxsize 0.000101  train_dp 0.077796  valid_dp 0.077254 reg_loss 24.770029
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:52:05
run time  0:01:41.461272
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_32/forward_32_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553450
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:52:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc0b54eb950>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2205, '_step_count': 2206, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.099819 valid_loss:0.097496 each epoch time:20.63567
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000147  valid_dq/boxsize 0.000146  train_dp 0.098863  valid_dp 0.096546 reg_loss 25.864861
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:53:51
run time  0:01:42.254317
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_32/forward_32_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553467
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:53:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f00b297c650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2210, '_step_count': 2211, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.078279 valid_loss:0.077764 each epoch time:20.29092
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000101  valid_dq/boxsize 0.000101  train_dp 0.077499  valid_dp 0.076986 reg_loss 24.631700
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:55:33
run time  0:01:41.061615
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_32/backward_32_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553483
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:55:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f054aea0250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2215, '_step_count': 2216, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.050582 valid_loss:0.049455 each epoch time:19.70585
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.050044  valid_dp 0.048931 reg_loss 7.339488
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:57:15
run time  0:01:40.896534
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_32/backward_32_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553501
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:57:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6f0b1da290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2220, '_step_count': 2221, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.037273 valid_loss:0.038730 each epoch time:20.86059
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.036857  valid_dp 0.038303 reg_loss 7.166930
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:59:00
run time  0:01:43.589472
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_32/backward_32_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553519
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:59:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f12921073d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2225, '_step_count': 2226, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.063974 valid_loss:0.063192 each epoch time:20.53473
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000073  train_dp 0.063316  valid_dp 0.062540 reg_loss 19.114844
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:00:42
run time  0:01:40.149092
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_32/backward_32_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553536
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:00:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f985ca5c210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2230, '_step_count': 2231, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.037189 valid_loss:0.038656 each epoch time:20.31904
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.036774  valid_dp 0.038229 reg_loss 7.167234
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:02:24
run time  0:01:41.132572
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_32/backward_32_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553553
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:02:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1560b22050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2235, '_step_count': 2236, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.050395 valid_loss:0.049280 each epoch time:20.07505
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.049857  valid_dp 0.048756 reg_loss 7.350785
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:04:08
run time  0:01:40.848960
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_32/backward_32_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553571
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:04:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb55655e8d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2240, '_step_count': 2241, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.037112 valid_loss:0.038591 each epoch time:19.70572
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.036697  valid_dp 0.038164 reg_loss 7.162825
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:05:50
run time  0:01:40.071467
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_32/backward_32_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553587
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:05:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f107addd390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2245, '_step_count': 2246, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.050306 valid_loss:0.049205 each epoch time:19.86440
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.049768  valid_dp 0.048681 reg_loss 7.346566
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:07:30
run time  0:01:38.844557
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_33/forward_33_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553603
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:07:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbca0a13410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2250, '_step_count': 2251, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.037041 valid_loss:0.038529 each epoch time:20.62711
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.036626  valid_dp 0.038102 reg_loss 7.157531
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:09:15
run time  0:01:41.682878
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_33/forward_33_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553620
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:09:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2b403abd90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2255, '_step_count': 2256, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.063683 valid_loss:0.062911 each epoch time:20.15016
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000073  valid_dq/boxsize 0.000073  train_dp 0.063026  valid_dp 0.062259 reg_loss 19.113856
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:10:57
run time  0:01:40.522753
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_33/forward_33_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553637
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:10:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6f257d6710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2260, '_step_count': 2261, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.036969 valid_loss:0.038461 each epoch time:19.82059
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.036555  valid_dp 0.038035 reg_loss 7.153625
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:12:38
run time  0:01:39.995517
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_33/forward_33_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553655
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:12:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff44e5fba10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2265, '_step_count': 2266, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.050140 valid_loss:0.049047 each epoch time:19.88260
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.049603  valid_dp 0.048524 reg_loss 7.343933
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:14:20
run time  0:01:40.204509
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_33/forward_33_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553671
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:14:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faef8ef0c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2270, '_step_count': 2271, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.077576 valid_loss:0.077067 each epoch time:20.36325
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000101  valid_dq/boxsize 0.000101  train_dp 0.076798  valid_dp 0.076291 reg_loss 24.564265
memory usage : 3.6  at e= 5
end date/time : 20211025, 13:16:02
run time  0:01:41.377270
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_33/forward_33_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553688
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:16:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb7edf95650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2275, '_step_count': 2276, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.098610 valid_loss:0.096341 each epoch time:20.92185
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000147  valid_dq/boxsize 0.000146  train_dp 0.097657  valid_dp 0.095395 reg_loss 25.739490
memory usage : 3.6  at e= 5
end date/time : 20211025, 13:17:48
run time  0:01:44.179103
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_33/forward_33_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553708
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:17:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6e7bff8110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2280, '_step_count': 2281, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.077291 valid_loss:0.076813 each epoch time:20.07399
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000101  valid_dq/boxsize 0.000101  train_dp 0.076515  valid_dp 0.076038 reg_loss 24.440872
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:19:32
run time  0:01:42.535804
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_33/backward_33_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553725
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:19:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efcdeb9b750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2285, '_step_count': 2286, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.049916 valid_loss:0.048824 each epoch time:20.35314
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.049381  valid_dp 0.048302 reg_loss 7.306783
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:21:16
run time  0:01:42.176118
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_33/backward_33_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553742
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:21:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9d1fde02d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2290, '_step_count': 2291, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.036768 valid_loss:0.038231 each epoch time:19.73937
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.036355  valid_dp 0.037806 reg_loss 7.130179
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:22:56
run time  0:01:39.102808
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_33/backward_33_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553759
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:22:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feb6b13e890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2295, '_step_count': 2296, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.063164 valid_loss:0.062392 each epoch time:19.68936
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000073  valid_dq/boxsize 0.000073  train_dp 0.062509  valid_dp 0.061742 reg_loss 19.043608
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:24:38
run time  0:01:40.605466
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_33/backward_33_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553776
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:24:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f24d60f8490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2300, '_step_count': 2301, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.036689 valid_loss:0.038162 each epoch time:19.88507
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.036276  valid_dp 0.037737 reg_loss 7.129345
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:26:19
run time  0:01:40.026141
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_33/backward_33_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553794
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:26:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4437da4410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2305, '_step_count': 2306, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.049740 valid_loss:0.048659 each epoch time:19.88855
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.049204  valid_dp 0.048138 reg_loss 7.317271
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:28:02
run time  0:01:40.102695
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_33/backward_33_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553810
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:28:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbafe032c50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2310, '_step_count': 2311, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.036616 valid_loss:0.038100 each epoch time:19.83989
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.036203  valid_dp 0.037675 reg_loss 7.124639
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:29:47
run time  0:01:40.444812
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_33/backward_33_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553826
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:29:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f483afe0450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2315, '_step_count': 2316, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.049654 valid_loss:0.048588 each epoch time:20.40185
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.049119  valid_dp 0.048067 reg_loss 7.313823
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:31:28
run time  0:01:39.863246
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_34/forward_34_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553846
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:31:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f33b41a4bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2320, '_step_count': 2321, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.036548 valid_loss:0.038042 each epoch time:20.36642
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.036135  valid_dp 0.037617 reg_loss 7.119332
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:33:11
run time  0:01:41.718472
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_34/forward_34_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553865
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:33:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f86394fc190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2325, '_step_count': 2326, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.062889 valid_loss:0.062128 each epoch time:20.40501
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000073  valid_dq/boxsize 0.000073  train_dp 0.062235  valid_dp 0.061479 reg_loss 19.044479
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:34:53
run time  0:01:40.642810
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_34/forward_34_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553882
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:34:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb1738752d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2330, '_step_count': 2331, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.036480 valid_loss:0.037978 each epoch time:20.00835
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.036068  valid_dp 0.037554 reg_loss 7.115316
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:36:35
run time  0:01:40.924513
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_34/forward_34_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553899
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:36:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7b0bf57310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2335, '_step_count': 2336, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.049498 valid_loss:0.048439 each epoch time:20.42404
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.048963  valid_dp 0.047919 reg_loss 7.312812
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:38:17
run time  0:01:41.081626
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_34/forward_34_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553915
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:38:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f880b3bd390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2340, '_step_count': 2341, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.076626 valid_loss:0.076152 each epoch time:19.72712
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000101  valid_dq/boxsize 0.000100  train_dp 0.075852  valid_dp 0.075378 reg_loss 24.378197
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:40:00
run time  0:01:41.475348
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_34/forward_34_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553933
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:40:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa3a78c4610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2345, '_step_count': 2346, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.097464 valid_loss:0.095246 each epoch time:21.23177
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000146  valid_dq/boxsize 0.000145  train_dp 0.096515  valid_dp 0.094303 reg_loss 25.635006
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:41:47
run time  0:01:45.056714
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_34/forward_34_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553950
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:41:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0732797450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2350, '_step_count': 2351, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.076355 valid_loss:0.075912 each epoch time:19.89524
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000100  train_dp 0.075582  valid_dp 0.075140 reg_loss 24.268087
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:43:29
run time  0:01:40.793228
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_34/backward_34_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553967
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:43:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2d894e0690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2355, '_step_count': 2356, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.049286 valid_loss:0.048230 each epoch time:20.19280
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.048753  valid_dp 0.047711 reg_loss 7.281043
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:45:12
run time  0:01:39.463221
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_34/backward_34_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  553985
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:45:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f99ada3e150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2360, '_step_count': 2361, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.036289 valid_loss:0.037762 each epoch time:19.82183
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.035879  valid_dp 0.037339 reg_loss 7.098161
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:46:54
run time  0:01:40.613974
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_34/backward_34_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554001
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:46:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f23fea92710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2365, '_step_count': 2366, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.062398 valid_loss:0.061640 each epoch time:20.20409
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000073  valid_dq/boxsize 0.000072  train_dp 0.061746  valid_dp 0.060993 reg_loss 18.985565
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:48:35
run time  0:01:39.932755
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_34/backward_34_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554017
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:48:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa882dcc250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2370, '_step_count': 2371, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.036214 valid_loss:0.037696 each epoch time:20.16740
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.035803  valid_dp 0.037273 reg_loss 7.097210
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:50:17
run time  0:01:41.096639
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_34/backward_34_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554034
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:50:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7732d86210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2375, '_step_count': 2376, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.049119 valid_loss:0.048073 each epoch time:19.87143
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.048586  valid_dp 0.047555 reg_loss 7.292661
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:52:00
run time  0:01:41.191491
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_34/backward_34_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554052
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:52:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbc3bd21cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2380, '_step_count': 2381, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.036144 valid_loss:0.037638 each epoch time:19.72955
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.035733  valid_dp 0.037215 reg_loss 7.093478
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:53:43
run time  0:01:40.700161
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_34/backward_34_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554069
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:53:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5e92ccd0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2385, '_step_count': 2386, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.049037 valid_loss:0.048006 each epoch time:20.28558
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.048504  valid_dp 0.047488 reg_loss 7.290262
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:55:25
run time  0:01:41.590993
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_35/forward_35_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554086
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:55:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa322247450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2390, '_step_count': 2391, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.036080 valid_loss:0.037583 each epoch time:20.50098
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.035669  valid_dp 0.037160 reg_loss 7.089014
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:57:09
run time  0:01:41.850876
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_35/forward_35_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554103
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:57:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f505adb2050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2395, '_step_count': 2396, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.062137 valid_loss:0.061391 each epoch time:19.67999
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000073  valid_dq/boxsize 0.000072  train_dp 0.061486  valid_dp 0.060745 reg_loss 18.990870
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:58:51
run time  0:01:39.118027
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_35/forward_35_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554121
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:58:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fafb01fc990>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2400, '_step_count': 2401, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.036015 valid_loss:0.037523 each epoch time:20.01550
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.035605  valid_dp 0.037101 reg_loss 7.084927
memory usage : 3.5  at e= 5
end date/time : 20211025, 14:00:33
run time  0:01:40.765482
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_35/forward_35_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554137
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:00:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6aa0696d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2405, '_step_count': 2406, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.048889 valid_loss:0.047865 each epoch time:20.44248
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000048  train_dp 0.048357  valid_dp 0.047347 reg_loss 7.288242
memory usage : 3.5  at e= 5
end date/time : 20211025, 14:02:17
run time  0:01:41.009078
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_35/forward_35_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554156
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:02:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f585a9d9190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2410, '_step_count': 2411, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.075727 valid_loss:0.075282 each epoch time:19.87343
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000100  train_dp 0.074955  valid_dp 0.074511 reg_loss 24.204685
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:04:01
run time  0:01:40.701756
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_35/forward_35_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554172
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:04:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd2ffdbed10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2415, '_step_count': 2416, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.096378 valid_loss:0.094207 each epoch time:20.49993
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000146  valid_dq/boxsize 0.000145  train_dp 0.095432  valid_dp 0.093267 reg_loss 25.544218
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:05:45
run time  0:01:42.473364
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_35/forward_35_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554189
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:05:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc5dbb39fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2420, '_step_count': 2421, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.075467 valid_loss:0.075054 each epoch time:20.11040
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000100  train_dp 0.074697  valid_dp 0.074285 reg_loss 24.099061
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:07:28
run time  0:01:41.452109
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_35/backward_35_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554207
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:07:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbd4af63d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2425, '_step_count': 2426, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.048688 valid_loss:0.047666 each epoch time:20.03344
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000048  train_dp 0.048158  valid_dp 0.047149 reg_loss 7.258045
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:09:10
run time  0:01:40.659289
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_35/backward_35_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554226
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:09:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcafe558550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2430, '_step_count': 2431, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.035836 valid_loss:0.037319 each epoch time:20.17227
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.035427  valid_dp 0.036898 reg_loss 7.068882
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:10:52
run time  0:01:40.291976
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_35/backward_35_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554243
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:10:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f32dddb4d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2435, '_step_count': 2436, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.061671 valid_loss:0.060927 each epoch time:19.75673
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000073  valid_dq/boxsize 0.000072  train_dp 0.061022  valid_dp 0.060283 reg_loss 18.934545
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:12:34
run time  0:01:40.654473
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_35/backward_35_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554260
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:12:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f679eb92610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2440, '_step_count': 2441, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.035764 valid_loss:0.037257 each epoch time:19.62369
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.035355  valid_dp 0.036836 reg_loss 7.067420
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:14:16
run time  0:01:40.525557
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_35/backward_35_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554276
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:14:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcbe7d38fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2445, '_step_count': 2446, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.048529 valid_loss:0.047517 each epoch time:20.22608
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000048  train_dp 0.047999  valid_dp 0.047001 reg_loss 7.266425
memory usage : 3.5  at e= 5
end date/time : 20211025, 14:15:58
run time  0:01:40.690602
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_35/backward_35_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554294
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:16:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7554e58a50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2450, '_step_count': 2451, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.035698 valid_loss:0.037202 each epoch time:20.44673
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.035289  valid_dp 0.036781 reg_loss 7.063963
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:17:44
run time  0:01:42.379539
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_35/backward_35_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554315
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:17:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2fd30965d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2455, '_step_count': 2456, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.048451 valid_loss:0.047453 each epoch time:19.99212
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000048  train_dp 0.047921  valid_dp 0.046937 reg_loss 7.263531
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:19:29
run time  0:01:41.623882
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_36/forward_36_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554333
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:19:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff31e00c2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2460, '_step_count': 2461, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.035636 valid_loss:0.037149 each epoch time:20.03823
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.035228  valid_dp 0.036729 reg_loss 7.059968
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:21:12
run time  0:01:39.255609
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_36/forward_36_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554351
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:21:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6f85407190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2465, '_step_count': 2466, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.061424 valid_loss:0.060692 each epoch time:19.78051
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000072  train_dp 0.060775  valid_dp 0.060049 reg_loss 18.936299
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:22:55
run time  0:01:41.205325
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_36/forward_36_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554368
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:22:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f419378a110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2470, '_step_count': 2471, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.035574 valid_loss:0.037093 each epoch time:19.96049
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.035166  valid_dp 0.036673 reg_loss 7.055619
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:24:37
run time  0:01:39.970838
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_36/forward_36_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554385
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:24:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9b8282b650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2475, '_step_count': 2476, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.048310 valid_loss:0.047319 each epoch time:19.92376
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000048  train_dp 0.047781  valid_dp 0.046803 reg_loss 7.261159
memory usage : 3.5  at e= 5
end date/time : 20211025, 14:26:19
run time  0:01:40.752550
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_36/forward_36_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554403
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:26:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd144c2da10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2480, '_step_count': 2481, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.074872 valid_loss:0.074453 each epoch time:20.34910
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000100  train_dp 0.074103  valid_dp 0.073685 reg_loss 24.033039
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:28:03
run time  0:01:40.097264
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_36/forward_36_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554420
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:28:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe729978210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2485, '_step_count': 2486, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.095345 valid_loss:0.093223 each epoch time:21.17436
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000145  valid_dq/boxsize 0.000144  train_dp 0.094402  valid_dp 0.092286 reg_loss 25.448472
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:29:51
run time  0:01:44.227281
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_36/forward_36_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554436
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:29:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fec8169f150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2490, '_step_count': 2491, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.074624 valid_loss:0.074238 each epoch time:19.91471
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000100  train_dp 0.073856  valid_dp 0.073471 reg_loss 23.928112
memory usage : 3.5  at e= 5
end date/time : 20211025, 14:31:35
run time  0:01:41.873796
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_36/backward_36_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554454
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:31:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7c48c97ad0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2495, '_step_count': 2496, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.048120 valid_loss:0.047127 each epoch time:20.25722
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.047592  valid_dp 0.046613 reg_loss 7.229586
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:33:16
run time  0:01:40.432947
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_36/backward_36_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554472
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:33:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc1e01a1950>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2500, '_step_count': 2501, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.035405 valid_loss:0.036900 each epoch time:19.99368
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034999  valid_dp 0.036482 reg_loss 7.040284
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:34:58
run time  0:01:39.776290
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_36/backward_36_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554488
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:34:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f815c3ec450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2505, '_step_count': 2506, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.060983 valid_loss:0.060253 each epoch time:20.03057
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000072  train_dp 0.060336  valid_dp 0.059612 reg_loss 18.880966
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:36:39
run time  0:01:40.224506
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_36/backward_36_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554506
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:36:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1b9e48b7d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2510, '_step_count': 2511, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.035338 valid_loss:0.036843 each epoch time:20.03061
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034931  valid_dp 0.036424 reg_loss 7.040825
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:38:22
run time  0:01:41.205513
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_36/backward_36_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554523
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:38:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdb75349390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2515, '_step_count': 2516, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.047971 valid_loss:0.046988 each epoch time:19.61902
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.047443  valid_dp 0.046474 reg_loss 7.240790
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:40:02
run time  0:01:39.050718
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_36/backward_36_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554539
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:40:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9b0be2d610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2520, '_step_count': 2521, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.035275 valid_loss:0.036791 each epoch time:19.80480
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034869  valid_dp 0.036372 reg_loss 7.037824
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:41:44
run time  0:01:40.724860
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_36/backward_36_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554556
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:41:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbf16396510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2525, '_step_count': 2526, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.047898 valid_loss:0.046928 each epoch time:19.53739
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.047370  valid_dp 0.046414 reg_loss 7.237834
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:43:25
run time  0:01:40.248754
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_37/forward_37_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554574
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:43:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa12251e490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2530, '_step_count': 2531, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.035217 valid_loss:0.036742 each epoch time:20.34962
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034811  valid_dp 0.036324 reg_loss 7.034158
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:45:08
run time  0:01:41.086728
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_37/forward_37_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554591
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:45:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2c72f6e210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2535, '_step_count': 2536, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.060752 valid_loss:0.060034 each epoch time:20.19392
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000072  train_dp 0.060106  valid_dp 0.059393 reg_loss 18.883928
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:46:50
run time  0:01:40.834896
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_37/forward_37_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554608
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:46:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbccda83f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2540, '_step_count': 2541, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.035159 valid_loss:0.036690 each epoch time:20.60733
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034753  valid_dp 0.036271 reg_loss 7.031055
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:48:32
run time  0:01:40.986172
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_37/forward_37_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554626
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:48:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fecccc6cf10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2545, '_step_count': 2546, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.047766 valid_loss:0.046802 each epoch time:19.71890
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.047239  valid_dp 0.046288 reg_loss 7.236926
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:50:16
run time  0:01:40.204725
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_37/forward_37_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554643
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:50:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa1cb6dc390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2550, '_step_count': 2551, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.074069 valid_loss:0.073676 each epoch time:20.34169
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000099  train_dp 0.073303  valid_dp 0.072911 reg_loss 23.873513
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:51:59
run time  0:01:41.158092
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_37/forward_37_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554659
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:52:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd9ddc1a050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2555, '_step_count': 2556, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.094377 valid_loss:0.092302 each epoch time:20.31621
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000145  valid_dq/boxsize 0.000144  train_dp 0.093436  valid_dp 0.091368 reg_loss 25.360427
memory usage : 3.5  at e= 5
end date/time : 20211025, 14:53:44
run time  0:01:44.453640
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_37/forward_37_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554675
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:53:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe134103750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2560, '_step_count': 2561, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.073836 valid_loss:0.073475 each epoch time:19.81938
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000099  valid_dq/boxsize 0.000099  train_dp 0.073071  valid_dp 0.072711 reg_loss 23.772491
memory usage : 3.5  at e= 5
end date/time : 20211025, 14:55:28
run time  0:01:40.581850
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_37/backward_37_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554692
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:55:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff67fcde150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2565, '_step_count': 2566, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.047589 valid_loss:0.046624 each epoch time:20.11687
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.047063  valid_dp 0.046112 reg_loss 7.204169
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:57:11
run time  0:01:39.919917
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_37/backward_37_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554710
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:57:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f996f93c450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2570, '_step_count': 2571, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.035002 valid_loss:0.036509 each epoch time:20.33085
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034597  valid_dp 0.036092 reg_loss 7.015904
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:58:54
run time  0:01:41.755830
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_37/backward_37_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554726
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:58:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdd9ad95390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2575, '_step_count': 2576, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.060337 valid_loss:0.059626 each epoch time:20.16278
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000071  train_dp 0.059693  valid_dp 0.058987 reg_loss 18.827741
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:00:37
run time  0:01:41.424969
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_37/backward_37_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554743
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:00:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2fd9d68410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2580, '_step_count': 2581, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034937 valid_loss:0.036454 each epoch time:20.37037
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034532  valid_dp 0.036038 reg_loss 7.016330
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:02:20
run time  0:01:40.912595
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_37/backward_37_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554760
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:02:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f84e63906d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2585, '_step_count': 2586, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.047447 valid_loss:0.046492 each epoch time:20.29400
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.046921  valid_dp 0.045980 reg_loss 7.215373
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:04:02
run time  0:01:40.724263
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_37/backward_37_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554777
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:04:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6a8d7e1550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2590, '_step_count': 2591, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034877 valid_loss:0.036405 each epoch time:19.61431
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034472  valid_dp 0.035988 reg_loss 7.012615
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:05:45
run time  0:01:40.228694
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_37/backward_37_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554794
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:05:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0fe4996290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2595, '_step_count': 2596, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.047376 valid_loss:0.046434 each epoch time:19.79899
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.046850  valid_dp 0.045922 reg_loss 7.211831
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:07:26
run time  0:01:40.621980
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_38/forward_38_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554821
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:07:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbabce20b90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2600, '_step_count': 2601, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034821 valid_loss:0.036358 each epoch time:20.15502
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034417  valid_dp 0.035942 reg_loss 7.008540
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:09:10
run time  0:01:41.984746
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_38/forward_38_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554838
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:09:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff721f0df10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2605, '_step_count': 2606, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.060116 valid_loss:0.059419 each epoch time:19.59373
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000071  train_dp 0.059473  valid_dp 0.058781 reg_loss 18.827615
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:10:50
run time  0:01:39.056859
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_38/forward_38_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554855
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:10:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2f5890f5d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2610, '_step_count': 2611, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034765 valid_loss:0.036308 each epoch time:20.18397
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034361  valid_dp 0.035892 reg_loss 7.005958
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:12:33
run time  0:01:41.515361
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_38/forward_38_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554871
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:12:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2fa301bd50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2615, '_step_count': 2616, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.047250 valid_loss:0.046314 each epoch time:19.68973
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.046725  valid_dp 0.045803 reg_loss 7.211143
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:14:17
run time  0:01:40.286855
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_38/forward_38_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554887
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:14:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f844a62a290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2620, '_step_count': 2621, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.073309 valid_loss:0.072938 each epoch time:20.26431
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000099  valid_dq/boxsize 0.000099  train_dp 0.072545  valid_dp 0.072176 reg_loss 23.719064
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:16:03
run time  0:01:41.784140
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_38/forward_38_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554904
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:16:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6cca993250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2625, '_step_count': 2626, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.093455 valid_loss:0.091426 each epoch time:20.89019
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000145  valid_dq/boxsize 0.000144  train_dp 0.092517  valid_dp 0.090494 reg_loss 25.274223
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:17:49
run time  0:01:44.600036
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_38/forward_38_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554924
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:17:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f41a7b943d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2630, '_step_count': 2631, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.073085 valid_loss:0.072746 each epoch time:20.09946
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000099  valid_dq/boxsize 0.000099  train_dp 0.072322  valid_dp 0.071985 reg_loss 23.616527
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:19:31
run time  0:01:40.359949
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_38/backward_38_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554941
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:19:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fde90609710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2635, '_step_count': 2636, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.047081 valid_loss:0.046143 each epoch time:19.88021
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.046557  valid_dp 0.045633 reg_loss 7.178488
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:21:13
run time  0:01:40.835815
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_38/backward_38_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554958
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:21:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fac0b44a190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2640, '_step_count': 2641, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034616 valid_loss:0.036136 each epoch time:20.15438
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034212  valid_dp 0.035721 reg_loss 6.990988
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:22:55
run time  0:01:40.286571
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_38/backward_38_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554975
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:22:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd9327bfa90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2645, '_step_count': 2646, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.059722 valid_loss:0.059031 each epoch time:20.11836
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000071  train_dp 0.059080  valid_dp 0.058394 reg_loss 18.772997
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:24:37
run time  0:01:40.042065
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_38/backward_38_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  554993
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:24:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f33e330d310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2650, '_step_count': 2651, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034554 valid_loss:0.036084 each epoch time:19.54603
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034150  valid_dp 0.035669 reg_loss 6.992873
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:26:18
run time  0:01:39.824498
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_38/backward_38_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555010
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:26:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5a2b0f1550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2655, '_step_count': 2656, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046946 valid_loss:0.046016 each epoch time:19.79902
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.046421  valid_dp 0.045506 reg_loss 7.191278
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:28:00
run time  0:01:40.754806
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_38/backward_38_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555027
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:28:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5359fbb390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2660, '_step_count': 2661, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034496 valid_loss:0.036037 each epoch time:20.32280
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034093  valid_dp 0.035622 reg_loss 6.989841
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:29:42
run time  0:01:40.348573
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_38/backward_38_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555044
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:29:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb7e3dfb950>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2665, '_step_count': 2666, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046878 valid_loss:0.045962 each epoch time:19.99370
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.046354  valid_dp 0.045452 reg_loss 7.188092
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:31:24
run time  0:01:41.008068
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_39/forward_39_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555064
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:31:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0cd70ddd10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2670, '_step_count': 2671, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034443 valid_loss:0.035992 each epoch time:20.08903
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.034040  valid_dp 0.035578 reg_loss 6.986228
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:33:08
run time  0:01:40.488917
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_39/forward_39_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555084
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:33:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff5e16170d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2675, '_step_count': 2676, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.059511 valid_loss:0.058836 each epoch time:19.72268
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000071  train_dp 0.058870  valid_dp 0.058200 reg_loss 18.774532
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:34:50
run time  0:01:39.410142
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_39/forward_39_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555101
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:34:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f097fc4e850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2680, '_step_count': 2681, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034390 valid_loss:0.035945 each epoch time:20.27041
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.033987  valid_dp 0.035530 reg_loss 6.984772
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:36:33
run time  0:01:41.511443
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_39/forward_39_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555118
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:36:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f130ef6e850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2685, '_step_count': 2686, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046758 valid_loss:0.045848 each epoch time:19.60384
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.046234  valid_dp 0.045338 reg_loss 7.188584
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:38:13
run time  0:01:38.731289
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_39/forward_39_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555136
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:38:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5a7fc9d450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2690, '_step_count': 2691, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.072585 valid_loss:0.072239 each epoch time:19.89795
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000099  valid_dq/boxsize 0.000099  train_dp 0.071824  valid_dp 0.071479 reg_loss 23.571394
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:39:54
run time  0:01:39.971270
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_39/forward_39_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555153
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:39:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa58f0d7e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2695, '_step_count': 2696, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.092575 valid_loss:0.090590 each epoch time:20.61482
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000144  valid_dq/boxsize 0.000143  train_dp 0.091639  valid_dp 0.089660 reg_loss 25.197577
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:41:38
run time  0:01:42.935565
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_39/forward_39_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555169
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:41:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f06b2be7d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2700, '_step_count': 2701, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.072369 valid_loss:0.072055 each epoch time:20.32629
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000099  valid_dq/boxsize 0.000099  train_dp 0.071609  valid_dp 0.071295 reg_loss 23.469897
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:43:20
run time  0:01:40.876979
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_39/backward_39_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555186
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:43:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f64d7e1f250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2705, '_step_count': 2706, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046597 valid_loss:0.045683 each epoch time:20.26719
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.046075  valid_dp 0.045175 reg_loss 7.156923
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:45:02
run time  0:01:40.694396
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_39/backward_39_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555202
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:45:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9e2df96550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2710, '_step_count': 2711, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034248 valid_loss:0.035781 each epoch time:20.01022
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.033847  valid_dp 0.035368 reg_loss 6.969863
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:46:44
run time  0:01:40.570599
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_39/backward_39_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555219
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:46:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb4765c0850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2715, '_step_count': 2716, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.059136 valid_loss:0.058467 each epoch time:20.38089
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000071  train_dp 0.058496  valid_dp 0.057832 reg_loss 18.717791
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:48:27
run time  0:01:41.608097
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_39/backward_39_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555237
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:48:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe0341d4090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2720, '_step_count': 2721, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034189 valid_loss:0.035732 each epoch time:19.97341
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.033787  valid_dp 0.035318 reg_loss 6.970915
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:50:10
run time  0:01:41.593596
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_39/backward_39_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555254
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:50:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffa91c251d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2725, '_step_count': 2726, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046468 valid_loss:0.045563 each epoch time:20.20430
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.045945  valid_dp 0.045055 reg_loss 7.166604
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:51:54
run time  0:01:40.538213
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_39/backward_39_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555270
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:51:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f670edbc590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2730, '_step_count': 2731, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034133 valid_loss:0.035687 each epoch time:19.66843
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.033732  valid_dp 0.035273 reg_loss 6.966903
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:53:39
run time  0:01:40.567984
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_39/backward_39_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555287
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:53:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f33c122d5d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2735, '_step_count': 2736, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046403 valid_loss:0.045511 each epoch time:20.25637
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.045880  valid_dp 0.045003 reg_loss 7.162793
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:55:22
run time  0:01:41.629762
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_40/forward_40_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555304
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:55:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f373bb58a50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2740, '_step_count': 2741, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034083 valid_loss:0.035644 each epoch time:20.21760
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.033681  valid_dp 0.035231 reg_loss 6.962654
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:57:04
run time  0:01:40.845025
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_40/forward_40_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555321
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:57:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7a81432f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2745, '_step_count': 2746, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.058935 valid_loss:0.058283 each epoch time:19.73201
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000071  valid_dq/boxsize 0.000071  train_dp 0.058296  valid_dp 0.057649 reg_loss 18.713830
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:58:44
run time  0:01:39.210668
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_40/forward_40_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555339
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:58:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efbe1cbd590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2750, '_step_count': 2751, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.034032 valid_loss:0.035599 each epoch time:20.50224
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.033631  valid_dp 0.035186 reg_loss 6.960389
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:00:28
run time  0:01:42.233733
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_40/forward_40_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555355
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:00:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f947c164210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2755, '_step_count': 2756, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046289 valid_loss:0.045402 each epoch time:19.54859
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000047  train_dp 0.045767  valid_dp 0.044895 reg_loss 7.161847
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:02:10
run time  0:01:40.442101
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_40/forward_40_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555372
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:02:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fad96a625d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2760, '_step_count': 2761, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.071895 valid_loss:0.071570 each epoch time:19.82608
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000099  valid_dq/boxsize 0.000098  train_dp 0.071136  valid_dp 0.070812 reg_loss 23.422367
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:03:51
run time  0:01:40.549324
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_40/forward_40_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555391
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:03:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4b7e769bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2765, '_step_count': 2766, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.091736 valid_loss:0.089793 each epoch time:20.42098
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000144  valid_dq/boxsize 0.000143  train_dp 0.090803  valid_dp 0.088865 reg_loss 25.119626
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:05:35
run time  0:01:42.613422
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_40/forward_40_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555408
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:05:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4d1f0f2e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2770, '_step_count': 2771, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.071686 valid_loss:0.071371 each epoch time:19.91540
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000098  valid_dq/boxsize 0.000098  train_dp 0.070929  valid_dp 0.070614 reg_loss 23.325835
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:07:16
run time  0:01:39.834532
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_40/backward_40_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555424
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:07:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2b64fff250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2775, '_step_count': 2776, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046136 valid_loss:0.045245 each epoch time:19.70981
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000047  train_dp 0.045615  valid_dp 0.044738 reg_loss 7.133092
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:08:57
run time  0:01:39.643536
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_40/backward_40_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555441
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:08:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa12535c910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2780, '_step_count': 2781, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033898 valid_loss:0.035444 each epoch time:20.54108
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.033498  valid_dp 0.035032 reg_loss 6.949171
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:10:38
run time  0:01:40.351232
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_40/backward_40_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555458
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:10:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5de0aeed10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2785, '_step_count': 2786, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.058578 valid_loss:0.057932 each epoch time:20.12420
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000071  valid_dq/boxsize 0.000071  train_dp 0.057940  valid_dp 0.057299 reg_loss 18.657604
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:12:21
run time  0:01:41.345427
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_40/backward_40_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555474
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:12:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f32cecf1350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2790, '_step_count': 2791, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033841 valid_loss:0.035397 each epoch time:20.07970
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.033441  valid_dp 0.034985 reg_loss 6.949754
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:14:02
run time  0:01:39.473969
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_40/backward_40_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555491
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:14:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb7aa0e0610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2795, '_step_count': 2796, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.046012 valid_loss:0.045130 each epoch time:19.67730
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000047  train_dp 0.045492  valid_dp 0.044624 reg_loss 7.142186
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:15:42
run time  0:01:38.489389
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_40/backward_40_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555507
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:15:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7469f8a1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2800, '_step_count': 2801, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033788 valid_loss:0.035354 each epoch time:20.02338
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.033388  valid_dp 0.034942 reg_loss 6.945375
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:17:25
run time  0:01:41.536004
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_40/backward_40_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555527
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:17:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4aec455d90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2805, '_step_count': 2806, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045950 valid_loss:0.045081 each epoch time:20.28491
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000047  train_dp 0.045429  valid_dp 0.044574 reg_loss 7.137912
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:19:09
run time  0:01:42.012339
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_41/forward_41_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555545
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:19:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f71e9206790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2810, '_step_count': 2811, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033739 valid_loss:0.035314 each epoch time:19.27493
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.033340  valid_dp 0.034902 reg_loss 6.941030
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:20:48
run time  0:01:38.307521
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_41/forward_41_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555562
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:20:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0838c17890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2815, '_step_count': 2816, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.058386 valid_loss:0.057758 each epoch time:19.69946
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000071  valid_dq/boxsize 0.000071  train_dp 0.057749  valid_dp 0.057125 reg_loss 18.650672
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:22:28
run time  0:01:38.971996
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_41/forward_41_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555579
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:22:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3e1b1ef0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2820, '_step_count': 2821, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033690 valid_loss:0.035271 each epoch time:20.50616
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.033291  valid_dp 0.034859 reg_loss 6.938541
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:24:11
run time  0:01:41.779560
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_41/forward_41_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555596
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:24:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f645761b710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2825, '_step_count': 2826, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045841 valid_loss:0.044977 each epoch time:20.10924
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000047  train_dp 0.045321  valid_dp 0.044471 reg_loss 7.137674
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:25:55
run time  0:01:40.115870
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_41/forward_41_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555612
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:25:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f87fe7ec350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2830, '_step_count': 2831, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.071236 valid_loss:0.070909 each epoch time:19.95839
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000098  valid_dq/boxsize 0.000098  train_dp 0.070479  valid_dp 0.070153 reg_loss 23.272771
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:27:36
run time  0:01:40.338880
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_41/forward_41_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555629
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:27:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2069b59390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2835, '_step_count': 2836, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.090937 valid_loss:0.089034 each epoch time:19.96979
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000143  valid_dq/boxsize 0.000143  train_dp 0.090006  valid_dp 0.088108 reg_loss 25.045601
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:29:20
run time  0:01:42.611569
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_41/forward_41_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555646
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:29:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f52df59e190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2840, '_step_count': 2841, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.071035 valid_loss:0.070730 each epoch time:19.86329
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000098  valid_dq/boxsize 0.000098  train_dp 0.070280  valid_dp 0.069975 reg_loss 23.180782
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:31:01
run time  0:01:39.306054
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_41/backward_41_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555666
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:31:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f86764dd890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2845, '_step_count': 2846, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045696 valid_loss:0.044827 each epoch time:20.27304
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000047  train_dp 0.045177  valid_dp 0.044322 reg_loss 7.108827
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:32:44
run time  0:01:40.331788
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_41/backward_41_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555682
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:32:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcfc87f66d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2850, '_step_count': 2851, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033564 valid_loss:0.035123 each epoch time:20.24204
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000032  train_dp 0.033166  valid_dp 0.034713 reg_loss 6.928010
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:34:26
run time  0:01:40.959091
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_41/backward_41_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555702
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:34:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f624ae80950>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2855, '_step_count': 2856, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.058046 valid_loss:0.057422 each epoch time:20.94218
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000071  valid_dq/boxsize 0.000071  train_dp 0.057410  valid_dp 0.056792 reg_loss 18.596004
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:36:09
run time  0:01:40.670224
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_41/backward_41_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555718
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:36:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc433c18610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2860, '_step_count': 2861, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033509 valid_loss:0.035079 each epoch time:20.16187
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.033111  valid_dp 0.034668 reg_loss 6.928087
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:37:51
run time  0:01:41.030174
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_41/backward_41_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555735
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:37:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f39c5125f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2865, '_step_count': 2866, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045578 valid_loss:0.044717 each epoch time:20.47142
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000047  train_dp 0.045059  valid_dp 0.044213 reg_loss 7.118027
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:39:35
run time  0:01:42.527085
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_41/backward_41_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555752
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:39:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f090d645190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2870, '_step_count': 2871, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033458 valid_loss:0.035038 each epoch time:19.88798
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.033060  valid_dp 0.034627 reg_loss 6.923685
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:41:16
run time  0:01:39.684827
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_41/backward_41_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555769
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:41:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fea841d7110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2875, '_step_count': 2876, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045518 valid_loss:0.044670 each epoch time:20.23305
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000047  train_dp 0.044999  valid_dp 0.044166 reg_loss 7.113594
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:43:01
run time  0:01:42.001718
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_42/forward_42_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555785
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:43:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbd37138510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2880, '_step_count': 2881, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033411 valid_loss:0.034999 each epoch time:20.31300
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.033013  valid_dp 0.034589 reg_loss 6.918981
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:44:46
run time  0:01:41.168295
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_42/forward_42_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555802
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:44:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f171fe33bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2885, '_step_count': 2886, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.057863 valid_loss:0.057257 each epoch time:19.61730
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000071  valid_dq/boxsize 0.000070  train_dp 0.057228  valid_dp 0.056627 reg_loss 18.590816
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:46:27
run time  0:01:38.846533
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_42/forward_42_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555819
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:46:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f38c0882810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2890, '_step_count': 2891, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033365 valid_loss:0.034959 each epoch time:20.14980
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032966  valid_dp 0.034549 reg_loss 6.916879
memory usage : 3.6  at e= 5
end date/time : 20211025, 16:48:11
run time  0:01:39.611415
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_42/forward_42_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555835
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:48:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd256243fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2895, '_step_count': 2896, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045414 valid_loss:0.044572 each epoch time:19.92880
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.044895  valid_dp 0.044068 reg_loss 7.114240
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:49:53
run time  0:01:39.843581
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_42/forward_42_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555851
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:49:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f941d58c110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2900, '_step_count': 2901, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.070607 valid_loss:0.070290 each epoch time:19.87641
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000098  valid_dq/boxsize 0.000098  train_dp 0.069853  valid_dp 0.069536 reg_loss 23.131074
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:51:35
run time  0:01:40.737372
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_42/forward_42_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555868
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:51:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb3df43b150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2905, '_step_count': 2906, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.090174 valid_loss:0.088309 each epoch time:20.76107
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000143  valid_dq/boxsize 0.000142  train_dp 0.089245  valid_dp 0.087386 reg_loss 24.979716
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:53:20
run time  0:01:43.415004
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_42/forward_42_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555887
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:53:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffa3e7a4250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2910, '_step_count': 2911, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.070414 valid_loss:0.070137 each epoch time:20.20932
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000098  valid_dq/boxsize 0.000098  train_dp 0.069661  valid_dp 0.069384 reg_loss 23.043769
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:55:03
run time  0:01:41.414090
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_42/backward_42_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555904
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:55:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9ff40c5c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2915, '_step_count': 2916, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045275 valid_loss:0.044427 each epoch time:20.36620
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.044758  valid_dp 0.043924 reg_loss 7.086970
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:56:44
run time  0:01:39.922855
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_42/backward_42_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555921
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:56:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8032da8610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2920, '_step_count': 2921, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033245 valid_loss:0.034819 each epoch time:19.37740
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032848  valid_dp 0.034410 reg_loss 6.907938
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:58:24
run time  0:01:38.567502
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_42/backward_42_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555937
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:58:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6c6b128390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2925, '_step_count': 2926, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.057537 valid_loss:0.056936 each epoch time:19.86921
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000071  valid_dq/boxsize 0.000070  train_dp 0.056903  valid_dp 0.056307 reg_loss 18.537463
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:00:05
run time  0:01:39.999351
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_42/backward_42_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555953
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:00:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0ebd375990>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2930, '_step_count': 2931, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033192 valid_loss:0.034777 each epoch time:19.95988
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032795  valid_dp 0.034368 reg_loss 6.907499
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:01:48
run time  0:01:39.622438
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_42/backward_42_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555969
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:01:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fabcd146150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2935, '_step_count': 2936, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045162 valid_loss:0.044324 each epoch time:20.14082
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.044645  valid_dp 0.043820 reg_loss 7.095773
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:03:30
run time  0:01:40.445578
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_42/backward_42_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  555986
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:03:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f73e7cd56d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2940, '_step_count': 2941, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033143 valid_loss:0.034737 each epoch time:20.22183
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032746  valid_dp 0.034328 reg_loss 6.902951
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:05:13
run time  0:01:41.846985
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_42/backward_42_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556004
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:05:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc84ea16650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2945, '_step_count': 2946, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045104 valid_loss:0.044279 each epoch time:20.14312
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.044587  valid_dp 0.043776 reg_loss 7.091424
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:06:56
run time  0:01:41.734353
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_43/forward_43_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556021
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:06:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f74267d7610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2950, '_step_count': 2951, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033098 valid_loss:0.034701 each epoch time:20.29288
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032701  valid_dp 0.034292 reg_loss 6.898157
memory usage : 3.6  at e= 5
end date/time : 20211025, 17:08:37
run time  0:01:40.198071
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_43/forward_43_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556038
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:08:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5182221590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2955, '_step_count': 2956, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.057362 valid_loss:0.056778 each epoch time:20.25273
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000071  valid_dq/boxsize 0.000070  train_dp 0.056729  valid_dp 0.056149 reg_loss 18.530946
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:10:19
run time  0:01:40.549281
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_43/forward_43_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556054
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:10:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4bc46a0cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2960, '_step_count': 2961, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.033053 valid_loss:0.034662 each epoch time:19.70704
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032656  valid_dp 0.034254 reg_loss 6.895760
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:12:02
run time  0:01:41.443074
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_43/forward_43_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556072
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:12:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd07de39e10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2965, '_step_count': 2966, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.045005 valid_loss:0.044185 each epoch time:20.71088
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.044489  valid_dp 0.043683 reg_loss 7.091927
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:13:47
run time  0:01:42.079589
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_43/forward_43_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556089
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:13:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc49d406390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2970, '_step_count': 2971, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.070007 valid_loss:0.069717 each epoch time:19.61708
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000098  valid_dq/boxsize 0.000098  train_dp 0.069254  valid_dp 0.068965 reg_loss 22.992129
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:15:27
run time  0:01:39.586430
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_43/forward_43_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556106
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:15:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdaaa8fef50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2975, '_step_count': 2976, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.089444 valid_loss:0.087616 each epoch time:20.81820
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000143  valid_dq/boxsize 0.000142  train_dp 0.088517  valid_dp 0.086695 reg_loss 24.912285
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:17:13
run time  0:01:43.341690
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_43/forward_43_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556127
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:17:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2ea1caf850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2980, '_step_count': 2981, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.069821 valid_loss:0.069561 each epoch time:20.20726
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000098  valid_dq/boxsize 0.000098  train_dp 0.069069  valid_dp 0.068810 reg_loss 22.907351
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:18:55
run time  0:01:41.306344
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_43/backward_43_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556144
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:18:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff98cc4af90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2985, '_step_count': 2986, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044873 valid_loss:0.044046 each epoch time:19.85024
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.044357  valid_dp 0.043545 reg_loss 7.063701
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:20:38
run time  0:01:41.873184
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_43/backward_43_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556161
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:20:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f26c812b410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2990, '_step_count': 2991, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032940 valid_loss:0.034529 each epoch time:20.02288
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032544  valid_dp 0.034122 reg_loss 6.885660
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:22:20
run time  0:01:40.318268
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_43/backward_43_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556177
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:22:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f94d611e3d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2995, '_step_count': 2996, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.057051 valid_loss:0.056470 each epoch time:19.73792
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000071  valid_dq/boxsize 0.000070  train_dp 0.056419  valid_dp 0.055843 reg_loss 18.476200
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:24:01
run time  0:01:39.703916
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_43/backward_43_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556194
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:24:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd3a670d050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3000, '_step_count': 3001, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032890 valid_loss:0.034489 each epoch time:19.93640
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032494  valid_dp 0.034081 reg_loss 6.884867
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:25:43
run time  0:01:40.099596
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_43/backward_43_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556211
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:25:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa8ea63b550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3005, '_step_count': 3006, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044766 valid_loss:0.043949 each epoch time:19.95957
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.044250  valid_dp 0.043448 reg_loss 7.071478
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:27:23
run time  0:01:39.319641
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_43/backward_43_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556228
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:27:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f82ebbc3090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3010, '_step_count': 3011, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032843 valid_loss:0.034452 each epoch time:20.08529
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032448  valid_dp 0.034045 reg_loss 6.880507
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:29:04
run time  0:01:39.025262
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_43/backward_43_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556247
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:29:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1605014290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3015, '_step_count': 3016, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044711 valid_loss:0.043908 each epoch time:20.41975
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.044196  valid_dp 0.043406 reg_loss 7.066912
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:30:45
run time  0:01:40.183688
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_44/forward_44_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556265
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:30:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8f6d035050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3020, '_step_count': 3021, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032801 valid_loss:0.034418 each epoch time:19.81001
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032406  valid_dp 0.034011 reg_loss 6.875932
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:32:28
run time  0:01:41.039351
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_44/forward_44_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556282
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:32:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fef3d9b7450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3025, '_step_count': 3026, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.056887 valid_loss:0.056323 each epoch time:20.59838
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000071  valid_dq/boxsize 0.000070  train_dp 0.056255  valid_dp 0.055696 reg_loss 18.466183
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:34:12
run time  0:01:39.878063
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_44/forward_44_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556303
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:34:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff7fa2e6710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3030, '_step_count': 3031, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032758 valid_loss:0.034382 each epoch time:19.89457
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032363  valid_dp 0.033974 reg_loss 6.872841
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:35:54
run time  0:01:40.204996
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_44/forward_44_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556319
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:35:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0f52881ed0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3035, '_step_count': 3036, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044618 valid_loss:0.043821 each epoch time:19.78509
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.044103  valid_dp 0.043320 reg_loss 7.066610
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:37:39
run time  0:01:41.859792
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_44/forward_44_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556336
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:37:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fee675bd7d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3040, '_step_count': 3041, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.069438 valid_loss:0.069165 each epoch time:20.82748
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000098  valid_dq/boxsize 0.000097  train_dp 0.068687  valid_dp 0.068414 reg_loss 22.851799
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:39:23
run time  0:01:42.914278
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_44/forward_44_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556352
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:39:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f73a42491d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3045, '_step_count': 3046, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.088757 valid_loss:0.086967 each epoch time:21.31320
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000143  valid_dq/boxsize 0.000142  train_dp 0.087831  valid_dp 0.086047 reg_loss 24.847163
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:41:09
run time  0:01:44.137185
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_44/forward_44_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556370
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:41:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f44b0c6a190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3050, '_step_count': 3051, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.069262 valid_loss:0.069023 each epoch time:20.74234
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000097  train_dp 0.068512  valid_dp 0.068273 reg_loss 22.775303
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:42:51
run time  0:01:41.349066
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_44/backward_44_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556387
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:42:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f848402a090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3055, '_step_count': 3056, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044494 valid_loss:0.043691 each epoch time:20.27113
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.043980  valid_dp 0.043190 reg_loss 7.040740
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:44:34
run time  0:01:40.944492
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_44/backward_44_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556404
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:44:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6f7ae3b090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3060, '_step_count': 3061, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032653 valid_loss:0.034257 each epoch time:19.74724
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032259  valid_dp 0.033850 reg_loss 6.864690
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:46:15
run time  0:01:40.131242
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_44/backward_44_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556420
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:46:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7e9de02a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3065, '_step_count': 3066, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.056594 valid_loss:0.056033 each epoch time:20.37207
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000070  train_dp 0.055964  valid_dp 0.055407 reg_loss 18.414131
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:47:59
run time  0:01:42.484022
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_44/backward_44_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556437
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:48:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7756b85090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3070, '_step_count': 3071, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032605 valid_loss:0.034218 each epoch time:19.88252
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032211  valid_dp 0.033812 reg_loss 6.862828
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:49:41
run time  0:01:40.668965
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_44/backward_44_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556454
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:49:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbc5c0c79d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3075, '_step_count': 3076, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044392 valid_loss:0.043599 each epoch time:20.55247
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.043878  valid_dp 0.043099 reg_loss 7.047322
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:51:23
run time  0:01:41.109103
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_44/backward_44_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556471
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:51:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd3e23d7610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3080, '_step_count': 3081, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032561 valid_loss:0.034183 each epoch time:19.99867
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032166  valid_dp 0.033777 reg_loss 6.858964
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:53:04
run time  0:01:39.188394
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_44/backward_44_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556487
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:53:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb1ae23e3d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3085, '_step_count': 3086, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044339 valid_loss:0.043560 each epoch time:19.51983
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.043825  valid_dp 0.043060 reg_loss 7.042724
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:54:45
run time  0:01:39.642574
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_45/forward_45_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556504
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:54:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f130de4d550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3090, '_step_count': 3091, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032520 valid_loss:0.034151 each epoch time:20.01713
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032125  valid_dp 0.033745 reg_loss 6.854786
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:56:29
run time  0:01:39.768673
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_45/forward_45_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556522
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:56:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f676b1bc090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3095, '_step_count': 3096, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.056437 valid_loss:0.055892 each epoch time:20.09238
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000070  train_dp 0.055807  valid_dp 0.055267 reg_loss 18.401003
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:58:10
run time  0:01:40.727523
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_45/forward_45_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556539
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:58:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe141f5b150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3100, '_step_count': 3101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032479 valid_loss:0.034116 each epoch time:20.39279
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.032084  valid_dp 0.033709 reg_loss 6.850804
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:59:54
run time  0:01:42.810276
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_45/forward_45_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556556
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:59:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1463d61d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3105, '_step_count': 3106, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044250 valid_loss:0.043477 each epoch time:19.88773
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.043736  valid_dp 0.042978 reg_loss 7.041595
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:01:39
run time  0:01:41.647604
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_45/forward_45_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556572
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:01:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8fac705190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3110, '_step_count': 3111, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.068899 valid_loss:0.068644 each epoch time:20.38269
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000097  train_dp 0.068149  valid_dp 0.067895 reg_loss 22.722895
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:03:21
run time  0:01:40.900375
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_45/forward_45_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556588
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:03:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbb67f43410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3115, '_step_count': 3116, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.088101 valid_loss:0.086343 each epoch time:20.84189
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000142  valid_dq/boxsize 0.000141  train_dp 0.087178  valid_dp 0.085425 reg_loss 24.786543
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:05:09
run time  0:01:44.507496
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_45/forward_45_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556605
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:05:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f91e763f690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3120, '_step_count': 3121, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.068728 valid_loss:0.068511 each epoch time:20.13385
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000097  train_dp 0.067980  valid_dp 0.067763 reg_loss 22.656511
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:06:52
run time  0:01:41.537309
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_45/backward_45_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556622
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:06:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4a32ca3510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3125, '_step_count': 3126, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044131 valid_loss:0.043352 each epoch time:20.18874
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.043619  valid_dp 0.042853 reg_loss 7.022383
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:08:35
run time  0:01:41.399788
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_45/backward_45_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556640
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:08:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9494413f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3130, '_step_count': 3131, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032379 valid_loss:0.033997 each epoch time:19.84523
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031986  valid_dp 0.033591 reg_loss 6.847065
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:10:16
run time  0:01:39.933904
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_45/backward_45_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556657
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:10:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efd6aeae250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3135, '_step_count': 3136, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.056156 valid_loss:0.055614 each epoch time:20.89045
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000070  train_dp 0.055527  valid_dp 0.054990 reg_loss 18.356517
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:12:01
run time  0:01:43.421026
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_45/backward_45_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556673
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:12:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe742776d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3140, '_step_count': 3141, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032332 valid_loss:0.033960 each epoch time:20.27268
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031939  valid_dp 0.033554 reg_loss 6.844061
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:13:44
run time  0:01:41.593179
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_45/backward_45_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556690
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:13:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9690280c50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3145, '_step_count': 3146, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.044033 valid_loss:0.043265 each epoch time:20.07857
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.043521  valid_dp 0.042766 reg_loss 7.025223
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:15:26
run time  0:01:39.275415
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_45/backward_45_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556708
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:15:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc4d681b790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3150, '_step_count': 3151, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032289 valid_loss:0.033926 each epoch time:20.41775
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031896  valid_dp 0.033521 reg_loss 6.839873
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:17:08
run time  0:01:41.177554
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_45/backward_45_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556728
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:17:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0834525890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3155, '_step_count': 3156, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043982 valid_loss:0.043228 each epoch time:19.64072
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.043469  valid_dp 0.042729 reg_loss 7.019603
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:18:50
run time  0:01:41.203636
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_46/forward_46_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556745
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:18:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa57d10d450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3160, '_step_count': 3161, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032250 valid_loss:0.033895 each epoch time:19.56055
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031857  valid_dp 0.033490 reg_loss 6.835773
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:20:34
run time  0:01:41.244753
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_46/forward_46_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556761
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:20:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f60ccc3b910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3165, '_step_count': 3166, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.056004 valid_loss:0.055479 each epoch time:20.00290
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000070  train_dp 0.055376  valid_dp 0.054855 reg_loss 18.338434
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:22:16
run time  0:01:39.346717
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_46/forward_46_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556779
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:22:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7e490bd610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3170, '_step_count': 3171, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032210 valid_loss:0.033861 each epoch time:20.13777
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031817  valid_dp 0.033456 reg_loss 6.830871
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:23:56
run time  0:01:39.220949
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_46/forward_46_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556796
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:23:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f37e292f5d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3175, '_step_count': 3176, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043896 valid_loss:0.043149 each epoch time:20.44250
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.043384  valid_dp 0.042650 reg_loss 7.016630
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:25:39
run time  0:01:41.312115
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_46/forward_46_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556812
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:25:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7eff49732450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3180, '_step_count': 3181, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.068381 valid_loss:0.068156 each epoch time:19.77997
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000097  train_dp 0.067633  valid_dp 0.067409 reg_loss 22.596564
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:27:22
run time  0:01:41.430442
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_46/forward_46_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556829
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:27:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5fb82fa690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3185, '_step_count': 3186, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.087472 valid_loss:0.085746 each epoch time:19.95809
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000142  valid_dq/boxsize 0.000141  train_dp 0.086550  valid_dp 0.084831 reg_loss 24.721138
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:29:07
run time  0:01:42.700070
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_46/forward_46_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556847
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:29:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5884ba7a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3190, '_step_count': 3191, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.068216 valid_loss:0.068029 each epoch time:20.05487
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000097  train_dp 0.067469  valid_dp 0.067282 reg_loss 22.536549
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:30:49
run time  0:01:40.200800
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_46/backward_46_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556865
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:30:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa62093f250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3195, '_step_count': 3196, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043782 valid_loss:0.043028 each epoch time:19.92483
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.043271  valid_dp 0.042530 reg_loss 7.001379
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:32:32
run time  0:01:40.514094
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_46/backward_46_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556885
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:32:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb8224fb090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3200, '_step_count': 3201, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032115 valid_loss:0.033747 each epoch time:20.91777
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031723  valid_dp 0.033343 reg_loss 6.830097
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:34:15
run time  0:01:41.254707
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_46/backward_46_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556902
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:34:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f44a4cce2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3205, '_step_count': 3206, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.055734 valid_loss:0.055211 each epoch time:20.97712
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000070  train_dp 0.055107  valid_dp 0.054588 reg_loss 18.299342
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:36:00
run time  0:01:43.623724
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_46/backward_46_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556919
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:36:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f80b0d7da10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3210, '_step_count': 3211, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032070 valid_loss:0.033711 each epoch time:20.34023
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031678  valid_dp 0.033307 reg_loss 6.826891
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:37:43
run time  0:01:40.096327
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_46/backward_46_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556935
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:37:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f508c8e8910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3215, '_step_count': 3216, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043688 valid_loss:0.042945 each epoch time:20.58734
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.043177  valid_dp 0.042447 reg_loss 7.003560
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:39:28
run time  0:01:42.787585
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_46/backward_46_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556951
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:39:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f42fd561550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3220, '_step_count': 3221, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.032028 valid_loss:0.033679 each epoch time:19.61759
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031636  valid_dp 0.033275 reg_loss 6.822853
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:41:11
run time  0:01:40.219111
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_46/backward_46_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556968
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:41:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc9d39ca950>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3225, '_step_count': 3226, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043638 valid_loss:0.042909 each epoch time:20.59676
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.043127  valid_dp 0.042412 reg_loss 6.997809
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:42:53
run time  0:01:41.405261
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_47/forward_47_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  556986
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:42:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd52660ae50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3230, '_step_count': 3231, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031990 valid_loss:0.033649 each epoch time:19.67596
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031598  valid_dp 0.033246 reg_loss 6.818838
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:44:36
run time  0:01:41.569205
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_47/forward_47_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557007
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:44:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f399490e090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3235, '_step_count': 3236, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.055589 valid_loss:0.055081 each epoch time:19.96145
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000070  train_dp 0.054962  valid_dp 0.054459 reg_loss 18.280654
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:46:18
run time  0:01:40.687841
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_47/forward_47_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557024
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:46:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff986619a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3240, '_step_count': 3241, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031952 valid_loss:0.033617 each epoch time:20.23880
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031560  valid_dp 0.033213 reg_loss 6.813980
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:48:02
run time  0:01:40.384467
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_47/forward_47_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557041
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:48:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3ec310d310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3245, '_step_count': 3246, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043556 valid_loss:0.042833 each epoch time:20.45981
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.043045  valid_dp 0.042336 reg_loss 6.995424
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:49:44
run time  0:01:40.861974
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_47/forward_47_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557059
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:49:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8c2640a310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3250, '_step_count': 3251, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.067883 valid_loss:0.067681 each epoch time:20.62269
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000097  train_dp 0.067137  valid_dp 0.066935 reg_loss 22.479572
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:51:28
run time  0:01:42.277747
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_47/forward_47_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557075
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:51:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8fb817d9d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3255, '_step_count': 3256, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.086868 valid_loss:0.085168 each epoch time:20.72558
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000142  valid_dq/boxsize 0.000141  train_dp 0.085948  valid_dp 0.084254 reg_loss 24.666441
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:53:14
run time  0:01:44.007088
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_47/forward_47_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557093
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:53:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7eff244df350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3260, '_step_count': 3261, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.067722 valid_loss:0.067558 each epoch time:19.89054
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000097  train_dp 0.066977  valid_dp 0.066813 reg_loss 22.424467
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:54:56
run time  0:01:40.607690
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_47/backward_47_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557111
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:54:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2c5667f890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3265, '_step_count': 3266, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043447 valid_loss:0.042717 each epoch time:20.09750
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000046  train_dp 0.042936  valid_dp 0.042220 reg_loss 6.983485
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:56:37
run time  0:01:40.193249
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_47/backward_47_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557128
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:56:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f92cb8e6f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3270, '_step_count': 3271, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031862 valid_loss:0.033507 each epoch time:20.42463
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031471  valid_dp 0.033104 reg_loss 6.815529
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:58:21
run time  0:01:42.669954
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_47/backward_47_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557145
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:58:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fadd594c250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3275, '_step_count': 3276, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.055330 valid_loss:0.054821 each epoch time:20.16881
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000069  train_dp 0.054704  valid_dp 0.054200 reg_loss 18.246381
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:00:04
run time  0:01:41.347278
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_47/backward_47_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557162
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:00:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fab917f5650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3280, '_step_count': 3281, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031818 valid_loss:0.033473 each epoch time:19.54584
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031427  valid_dp 0.033070 reg_loss 6.811730
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:01:46
run time  0:01:40.494477
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_47/backward_47_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557179
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:01:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd1899122d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3285, '_step_count': 3286, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043356 valid_loss:0.042637 each epoch time:20.48884
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000046  train_dp 0.042846  valid_dp 0.042140 reg_loss 6.984940
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:03:32
run time  0:01:42.073658
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_47/backward_47_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557196
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:03:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0d1866a210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3290, '_step_count': 3291, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031778 valid_loss:0.033441 each epoch time:20.10275
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031387  valid_dp 0.033038 reg_loss 6.807489
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:05:14
run time  0:01:40.869627
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_47/backward_47_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557213
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:05:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f97e5859310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3295, '_step_count': 3296, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043307 valid_loss:0.042603 each epoch time:20.39637
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000046  train_dp 0.042797  valid_dp 0.042106 reg_loss 6.978577
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:06:57
run time  0:01:41.240913
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_48/forward_48_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557230
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:06:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc3bbf901d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3300, '_step_count': 3301, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031741 valid_loss:0.033414 each epoch time:20.47349
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031350  valid_dp 0.033011 reg_loss 6.803284
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:08:41
run time  0:01:42.816502
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_48/forward_48_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557247
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:08:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f16d282a350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3305, '_step_count': 3306, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.055188 valid_loss:0.054696 each epoch time:19.94857
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000069  train_dp 0.054563  valid_dp 0.054075 reg_loss 18.228745
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:10:24
run time  0:01:41.168328
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_48/forward_48_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557264
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:10:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f82dcf684d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3310, '_step_count': 3311, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031704 valid_loss:0.033380 each epoch time:20.61688
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031313  valid_dp 0.032977 reg_loss 6.799020
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:12:07
run time  0:01:42.398625
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_48/forward_48_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557280
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:12:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd9fa2cdad0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3315, '_step_count': 3316, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043228 valid_loss:0.042529 each epoch time:19.92875
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000046  train_dp 0.042718  valid_dp 0.042033 reg_loss 6.977064
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:13:49
run time  0:01:40.120544
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_48/forward_48_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557297
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:13:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5dd5336090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3320, '_step_count': 3321, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.067404 valid_loss:0.067223 each epoch time:20.21212
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000097  train_dp 0.066659  valid_dp 0.066479 reg_loss 22.371439
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:15:32
run time  0:01:42.157090
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_48/forward_48_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557314
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:15:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2e7d939410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3325, '_step_count': 3326, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.086287 valid_loss:0.084610 each epoch time:21.14255
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000142  valid_dq/boxsize 0.000141  train_dp 0.085368  valid_dp 0.083697 reg_loss 24.615386
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:17:19
run time  0:01:45.687807
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_48/forward_48_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557333
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:17:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f78a618af90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3330, '_step_count': 3331, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.067248 valid_loss:0.067105 each epoch time:20.19047
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000097  train_dp 0.066504  valid_dp 0.066362 reg_loss 22.322677
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:19:04
run time  0:01:42.980639
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_48/backward_48_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557349
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:19:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f10de7e7a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3335, '_step_count': 3336, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043123 valid_loss:0.042417 each epoch time:20.10798
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000046  train_dp 0.042614  valid_dp 0.041921 reg_loss 6.966816
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:20:47
run time  0:01:41.976741
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_48/backward_48_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557365
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:20:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0a628d0310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3340, '_step_count': 3341, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031619 valid_loss:0.033244 each epoch time:20.05907
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031229  valid_dp 0.032842 reg_loss 6.802293
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:22:28
run time  0:01:40.233971
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_48/backward_48_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557382
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:22:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f347d68b5d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3345, '_step_count': 3346, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054939 valid_loss:0.054445 each epoch time:20.67309
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000069  train_dp 0.054314  valid_dp 0.053826 reg_loss 18.199518
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:24:12
run time  0:01:42.788247
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_48/backward_48_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557400
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:24:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f04495eabd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3350, '_step_count': 3351, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031576 valid_loss:0.033210 each epoch time:20.32931
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031186  valid_dp 0.032808 reg_loss 6.797297
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:25:57
run time  0:01:41.494430
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_48/backward_48_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557417
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:25:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb0e7e1a450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3355, '_step_count': 3356, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.043035 valid_loss:0.042340 each epoch time:20.31293
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000046  train_dp 0.042526  valid_dp 0.041845 reg_loss 6.966664
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:27:39
run time  0:01:40.955317
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_48/backward_48_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557433
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:27:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2f01aaf3d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3360, '_step_count': 3361, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031537 valid_loss:0.033180 each epoch time:19.78356
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031147  valid_dp 0.032778 reg_loss 6.792832
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:29:23
run time  0:01:41.191702
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_48/backward_48_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557449
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:29:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe575e6b9d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3365, '_step_count': 3366, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042988 valid_loss:0.042307 each epoch time:19.98219
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000046  train_dp 0.042480  valid_dp 0.041812 reg_loss 6.959971
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:31:05
run time  0:01:41.172795
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_49/forward_49_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557472
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:31:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd5facdf110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3370, '_step_count': 3371, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031501 valid_loss:0.033153 each epoch time:20.30867
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031112  valid_dp 0.032751 reg_loss 6.788492
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:32:47
run time  0:01:40.219854
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_49/forward_49_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557488
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:32:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6ac616dfd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3375, '_step_count': 3376, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054802 valid_loss:0.054326 each epoch time:19.88115
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000069  train_dp 0.054178  valid_dp 0.053707 reg_loss 18.184772
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:34:29
run time  0:01:40.287702
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_49/forward_49_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557505
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:34:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb22cc88fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3380, '_step_count': 3381, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031465 valid_loss:0.033123 each epoch time:20.06442
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.031076  valid_dp 0.032721 reg_loss 6.785576
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:36:12
run time  0:01:41.110350
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_49/forward_49_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557522
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:36:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0dabab6310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3385, '_step_count': 3386, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042912 valid_loss:0.042237 each epoch time:20.60420
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000046  train_dp 0.042404  valid_dp 0.041742 reg_loss 6.959951
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:37:54
run time  0:01:41.193961
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_49/forward_49_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557540
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:37:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6ebe86be90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3390, '_step_count': 3391, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.066943 valid_loss:0.066783 each epoch time:20.36177
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000096  train_dp 0.066199  valid_dp 0.066040 reg_loss 22.267791
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:39:38
run time  0:01:42.482328
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_49/forward_49_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557557
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:39:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f654f88a190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3395, '_step_count': 3396, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.085728 valid_loss:0.084074 each epoch time:20.24780
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000141  valid_dq/boxsize 0.000140  train_dp 0.084811  valid_dp 0.083163 reg_loss 24.571104
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:41:22
run time  0:01:42.335833
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_49/forward_49_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557574
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:41:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4e17fb2d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3400, '_step_count': 3401, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.066790 valid_loss:0.066669 each epoch time:20.63404
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000096  valid_dq/boxsize 0.000096  train_dp 0.066048  valid_dp 0.065927 reg_loss 22.223003
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:43:05
run time  0:01:42.406106
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_49/backward_49_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557590
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:43:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f179ae9b290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3405, '_step_count': 3406, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042812 valid_loss:0.042128 each epoch time:19.85253
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000046  train_dp 0.042304  valid_dp 0.041634 reg_loss 6.950970
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:44:49
run time  0:01:41.058379
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_49/backward_49_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557607
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:44:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7df5e2b0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3410, '_step_count': 3411, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031384 valid_loss:0.033021 each epoch time:20.00364
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030995  valid_dp 0.032620 reg_loss 6.788953
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:46:32
run time  0:01:41.408250
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_49/backward_49_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557624
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:46:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6e7b1eafd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3415, '_step_count': 3416, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054560 valid_loss:0.054084 each epoch time:19.91375
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000069  train_dp 0.053937  valid_dp 0.053465 reg_loss 18.159400
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:48:13
run time  0:01:40.180902
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_49/backward_49_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557642
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:48:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fabdf3d8090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3420, '_step_count': 3421, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031343 valid_loss:0.032989 each epoch time:19.77932
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030954  valid_dp 0.032588 reg_loss 6.785301
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:49:55
run time  0:01:40.928820
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_49/backward_49_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557659
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:49:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f513b4f6410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3425, '_step_count': 3426, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042727 valid_loss:0.042055 each epoch time:20.37192
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000046  train_dp 0.042219  valid_dp 0.041561 reg_loss 6.951587
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:51:38
run time  0:01:40.205729
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_49/backward_49_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557675
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:51:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f76d203ee50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3430, '_step_count': 3431, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031305 valid_loss:0.032960 each epoch time:19.52018
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030916  valid_dp 0.032559 reg_loss 6.780040
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:53:20
run time  0:01:40.441888
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_49/backward_49_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557691
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:53:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc148d2e350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3435, '_step_count': 3436, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042681 valid_loss:0.042024 each epoch time:20.13559
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000046  train_dp 0.042173  valid_dp 0.041530 reg_loss 6.943627
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:55:03
run time  0:01:41.173900
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_50/forward_50_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557709
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:55:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f11b05b3210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3440, '_step_count': 3441, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031271 valid_loss:0.032933 each epoch time:20.34911
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030882  valid_dp 0.032532 reg_loss 6.775186
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:56:46
run time  0:01:42.183195
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_50/forward_50_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557726
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:56:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8e427ce490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3445, '_step_count': 3446, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054429 valid_loss:0.053969 each epoch time:20.41777
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000069  train_dp 0.053806  valid_dp 0.053350 reg_loss 18.141309
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:58:29
run time  0:01:41.726135
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_50/forward_50_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557744
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:58:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1e44dda090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3450, '_step_count': 3451, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031236 valid_loss:0.032904 each epoch time:19.93507
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030847  valid_dp 0.032503 reg_loss 6.771140
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:00:13
run time  0:01:41.763062
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_50/forward_50_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557761
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:00:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbde130d1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3455, '_step_count': 3456, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042608 valid_loss:0.041956 each epoch time:20.55252
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.042100  valid_dp 0.041463 reg_loss 6.941826
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:01:56
run time  0:01:41.723432
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_50/forward_50_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557778
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:01:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc320098110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3460, '_step_count': 3461, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.066497 valid_loss:0.066356 each epoch time:20.30561
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000096  valid_dq/boxsize 0.000096  train_dp 0.065755  valid_dp 0.065615 reg_loss 22.166267
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:03:39
run time  0:01:41.590574
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_50/forward_50_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557794
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:03:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7f14e3f110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3465, '_step_count': 3466, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.085188 valid_loss:0.083560 each epoch time:20.53819
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000141  valid_dq/boxsize 0.000140  train_dp 0.084272  valid_dp 0.082650 reg_loss 24.525280
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:05:24
run time  0:01:44.485673
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_50/forward_50_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557811
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:05:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f729820da10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3470, '_step_count': 3471, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.066348 valid_loss:0.066247 each epoch time:20.57425
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000096  valid_dq/boxsize 0.000096  train_dp 0.065607  valid_dp 0.065507 reg_loss 22.123515
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:07:08
run time  0:01:42.522115
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_50/backward_50_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557828
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:07:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1df9ca8f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3475, '_step_count': 3476, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042511 valid_loss:0.041850 each epoch time:20.38756
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.042004  valid_dp 0.041357 reg_loss 6.935131
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:08:51
run time  0:01:41.093173
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_50/backward_50_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557844
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:08:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb1e17a72d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3480, '_step_count': 3481, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031159 valid_loss:0.032806 each epoch time:19.87104
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030771  valid_dp 0.032406 reg_loss 6.777265
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:10:35
run time  0:01:41.160883
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_50/backward_50_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557861
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:10:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faf9027f2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3485, '_step_count': 3486, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054196 valid_loss:0.053734 each epoch time:20.23315
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000069  train_dp 0.053574  valid_dp 0.053117 reg_loss 18.118688
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:12:18
run time  0:01:41.134806
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_50/backward_50_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557878
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:12:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fef9840b7d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3490, '_step_count': 3491, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031118 valid_loss:0.032774 each epoch time:20.03660
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030730  valid_dp 0.032374 reg_loss 6.771657
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:14:00
run time  0:01:41.213659
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_50/backward_50_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557895
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:14:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f76ec869090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3495, '_step_count': 3496, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042429 valid_loss:0.041780 each epoch time:20.66459
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041922  valid_dp 0.041287 reg_loss 6.933565
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:15:44
run time  0:01:42.450141
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_50/backward_50_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557911
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:15:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f195eb89a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3500, '_step_count': 3501, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031082 valid_loss:0.032746 each epoch time:20.11422
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030694  valid_dp 0.032346 reg_loss 6.767496
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:17:27
run time  0:01:41.380474
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_50/backward_50_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557931
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:17:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbfdad4b210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3505, '_step_count': 3506, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042385 valid_loss:0.041751 each epoch time:20.15228
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041878  valid_dp 0.041258 reg_loss 6.926330
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:19:09
run time  0:01:40.911197
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_51/forward_51_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557949
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:19:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8e4c089290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3510, '_step_count': 3511, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031049 valid_loss:0.032721 each epoch time:20.11403
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030661  valid_dp 0.032321 reg_loss 6.763316
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:20:54
run time  0:01:40.663682
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_51/forward_51_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557966
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:20:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fea32db1790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3515, '_step_count': 3516, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.054071 valid_loss:0.053625 each epoch time:20.36638
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000069  train_dp 0.053449  valid_dp 0.053008 reg_loss 18.103526
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:22:39
run time  0:01:42.554117
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_51/forward_51_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  557983
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:22:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f80ba93ca50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3520, '_step_count': 3521, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.031016 valid_loss:0.032694 each epoch time:19.95845
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030628  valid_dp 0.032294 reg_loss 6.759521
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:24:23
run time  0:01:40.987891
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_51/forward_51_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558000
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:24:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fad691a6650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3525, '_step_count': 3526, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042316 valid_loss:0.041687 each epoch time:20.27673
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041809  valid_dp 0.041194 reg_loss 6.924769
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:26:07
run time  0:01:41.281760
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_51/forward_51_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558017
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:26:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fba8a1e6ed0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3530, '_step_count': 3531, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.066070 valid_loss:0.065951 each epoch time:19.61151
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000096  valid_dq/boxsize 0.000096  train_dp 0.065330  valid_dp 0.065211 reg_loss 22.069371
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:27:52
run time  0:01:41.014483
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_51/forward_51_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558036
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:27:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9747d77450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3535, '_step_count': 3536, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.084673 valid_loss:0.083073 each epoch time:20.78642
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000141  valid_dq/boxsize 0.000140  train_dp 0.083759  valid_dp 0.082164 reg_loss 24.482710
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:29:39
run time  0:01:44.904030
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_51/forward_51_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558052
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:29:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb13fa875d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3540, '_step_count': 3541, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.065928 valid_loss:0.065847 each epoch time:19.94486
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000096  valid_dq/boxsize 0.000096  train_dp 0.065188  valid_dp 0.065107 reg_loss 22.030712
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:31:22
run time  0:01:40.995615
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_51/backward_51_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558072
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:31:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0f3bea4650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3545, '_step_count': 3546, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042224 valid_loss:0.041587 each epoch time:19.99192
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041718  valid_dp 0.041095 reg_loss 6.917732
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:33:06
run time  0:01:40.867660
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_51/backward_51_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558092
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:33:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3033c16690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3550, '_step_count': 3551, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030943 valid_loss:0.032601 each epoch time:19.67269
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030556  valid_dp 0.032202 reg_loss 6.765481
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:34:48
run time  0:01:39.519683
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_51/backward_51_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558108
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:34:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff550928ad0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3555, '_step_count': 3556, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.053850 valid_loss:0.053401 each epoch time:19.60527
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000069  valid_dq/boxsize 0.000069  train_dp 0.053229  valid_dp 0.052785 reg_loss 18.078869
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:36:29
run time  0:01:39.703942
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_51/backward_51_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558125
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:36:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fec6dff3310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3560, '_step_count': 3561, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030905 valid_loss:0.032571 each epoch time:20.00902
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030518  valid_dp 0.032171 reg_loss 6.759338
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:38:13
run time  0:01:39.463600
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_51/backward_51_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558143
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:38:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7facaff93b90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3565, '_step_count': 3566, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042146 valid_loss:0.041521 each epoch time:19.85212
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041640  valid_dp 0.041029 reg_loss 6.915146
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:39:54
run time  0:01:40.454803
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_51/backward_51_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558159
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:39:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f47ce90e0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3570, '_step_count': 3571, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030870 valid_loss:0.032545 each epoch time:20.50426
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030483  valid_dp 0.032145 reg_loss 6.754914
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:41:37
run time  0:01:40.741793
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_51/backward_51_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558176
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:41:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9dca072790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3575, '_step_count': 3576, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042104 valid_loss:0.041493 each epoch time:19.99499
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041598  valid_dp 0.041001 reg_loss 6.907597
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:43:20
run time  0:01:40.852964
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_52/forward_52_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558192
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:43:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1b534c6e90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3580, '_step_count': 3581, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030838 valid_loss:0.032520 each epoch time:20.21131
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030451  valid_dp 0.032121 reg_loss 6.750680
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:45:03
run time  0:01:39.418020
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_52/forward_52_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558208
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:45:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9959b1cfd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3585, '_step_count': 3586, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.053730 valid_loss:0.053296 each epoch time:20.09762
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000069  valid_dq/boxsize 0.000069  train_dp 0.053109  valid_dp 0.052680 reg_loss 18.059804
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:46:46
run time  0:01:40.296117
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_52/forward_52_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558225
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:46:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f17b8adb290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3590, '_step_count': 3591, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030805 valid_loss:0.032493 each epoch time:20.07350
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.030418  valid_dp 0.032094 reg_loss 6.745540
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:48:28
run time  0:01:41.019997
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_52/forward_52_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558241
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:48:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9e1fcaacd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3595, '_step_count': 3596, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.042037 valid_loss:0.041432 each epoch time:20.00395
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041531  valid_dp 0.040940 reg_loss 6.904345
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:50:10
run time  0:01:40.172294
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_52/forward_52_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558260
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:50:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f37a2d87690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3600, '_step_count': 3601, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.065662 valid_loss:0.065563 each epoch time:20.33319
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000096  valid_dq/boxsize 0.000096  train_dp 0.064922  valid_dp 0.064824 reg_loss 21.970986
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:51:52
run time  0:01:41.012731
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_52/forward_52_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558280
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:51:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd9599a9650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3605, '_step_count': 3606, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.084179 valid_loss:0.082603 each epoch time:20.43986
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000141  valid_dq/boxsize 0.000140  train_dp 0.083266  valid_dp 0.081696 reg_loss 24.439080
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:53:36
run time  0:01:43.174060
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_52/forward_52_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558297
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:53:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efdaeedf390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3610, '_step_count': 3611, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.065522 valid_loss:0.065462 each epoch time:20.90522
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000096  valid_dq/boxsize 0.000096  train_dp 0.064783  valid_dp 0.064724 reg_loss 21.935114
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:55:21
run time  0:01:43.026100
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_52/backward_52_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558321
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:55:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1c1b870510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3615, '_step_count': 3616, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041948 valid_loss:0.041334 each epoch time:19.77690
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041443  valid_dp 0.040843 reg_loss 6.898025
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:57:00
run time  0:01:38.197904
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_52/backward_52_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558337
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:57:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f819ded0810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3620, '_step_count': 3621, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030737 valid_loss:0.032404 each epoch time:20.64885
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000031  train_dp 0.030351  valid_dp 0.032005 reg_loss 6.752558
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:58:43
run time  0:01:41.613562
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_52/backward_52_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558355
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:58:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb22e6842d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3625, '_step_count': 3626, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.053515 valid_loss:0.053079 each epoch time:20.09560
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000069  valid_dq/boxsize 0.000069  train_dp 0.052895  valid_dp 0.052464 reg_loss 18.041932
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:00:29
run time  0:01:42.382947
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_52/backward_52_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558372
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:00:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f36eca1dd90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3630, '_step_count': 3631, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030699 valid_loss:0.032374 each epoch time:20.22023
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000031  train_dp 0.030313  valid_dp 0.031976 reg_loss 6.746299
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:02:12
run time  0:01:41.803314
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_52/backward_52_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558390
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:02:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f17ee95b210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3635, '_step_count': 3636, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041873 valid_loss:0.041271 each epoch time:20.21697
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041368  valid_dp 0.040780 reg_loss 6.895861
memory usage : 3.6  at e= 5
end date/time : 20211025, 21:03:54
run time  0:01:40.897134
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_52/backward_52_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558407
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:03:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f13a53c1350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3640, '_step_count': 3641, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030665 valid_loss:0.032349 each epoch time:19.49609
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000031  train_dp 0.030279  valid_dp 0.031951 reg_loss 6.741287
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:05:36
run time  0:01:39.788691
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_52/backward_52_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558424
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:05:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3b472614d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3645, '_step_count': 3646, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041831 valid_loss:0.041244 each epoch time:20.18970
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041326  valid_dp 0.040753 reg_loss 6.887964
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:07:18
run time  0:01:39.904770
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_53/forward_53_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558440
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:07:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdf94095fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3650, '_step_count': 3651, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030634 valid_loss:0.032325 each epoch time:20.42519
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000031  train_dp 0.030248  valid_dp 0.031927 reg_loss 6.736575
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:09:01
run time  0:01:42.361749
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_53/forward_53_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558457
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:09:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa0b45d8350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3655, '_step_count': 3656, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.053399 valid_loss:0.052978 each epoch time:19.85461
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000069  valid_dq/boxsize 0.000069  train_dp 0.052779  valid_dp 0.052363 reg_loss 18.022009
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:10:45
run time  0:01:41.471371
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_53/forward_53_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558475
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:10:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f32940b76d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3660, '_step_count': 3661, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030602 valid_loss:0.032299 each epoch time:20.45938
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000031  train_dp 0.030216  valid_dp 0.031901 reg_loss 6.730595
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:12:30
run time  0:01:40.924178
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/forward_53/forward_53_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558492
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:12:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6840c67e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3665, '_step_count': 3666, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041766 valid_loss:0.041185 each epoch time:19.63922
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041262  valid_dp 0.040694 reg_loss 6.883606
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:14:12
run time  0:01:39.544858
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/forward_53/forward_53_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558509
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:14:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8e24fe0e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3670, '_step_count': 3671, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.065266 valid_loss:0.065187 each epoch time:20.50104
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000096  valid_dq/boxsize 0.000096  train_dp 0.064528  valid_dp 0.064449 reg_loss 21.870871
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:15:54
run time  0:01:40.532037
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/forward_53/forward_53_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558526
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:15:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f56d6c6cdd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3675, '_step_count': 3676, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.083700 valid_loss:0.082146 each epoch time:20.91387
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000141  valid_dq/boxsize 0.000140  train_dp 0.082788  valid_dp 0.081240 reg_loss 24.395318
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:17:39
run time  0:01:43.905139
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/forward_53/forward_53_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558545
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:17:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc4d3f5dfd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3680, '_step_count': 3681, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.065129 valid_loss:0.065090 each epoch time:20.35929
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000096  valid_dq/boxsize 0.000096  train_dp 0.064391  valid_dp 0.064353 reg_loss 21.834882
memory usage : 3.5  at e= 5
end date/time : 20211025, 21:19:22
run time  0:01:41.180652
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/backward_53/backward_53_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558562
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:19:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff5d5d94390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3685, '_step_count': 3686, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041681 valid_loss:0.041091 each epoch time:20.10154
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041177  valid_dp 0.040601 reg_loss 6.876873
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:21:06
run time  0:01:39.961632
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/backward_53/backward_53_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558578
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:21:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8dc4c55410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3690, '_step_count': 3691, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030537 valid_loss:0.032213 each epoch time:20.25105
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.030152  valid_dp 0.031815 reg_loss 6.737989
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:22:51
run time  0:01:40.924373
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/backward_53/backward_53_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558596
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:22:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2ab9c2d850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3695, '_step_count': 3696, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.053190 valid_loss:0.052767 each epoch time:19.87082
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000069  valid_dq/boxsize 0.000069  train_dp 0.052572  valid_dp 0.052153 reg_loss 18.005576
memory usage : 3.5  at e= 5
end date/time : 20211025, 21:24:32
run time  0:01:40.280919
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/backward_53/backward_53_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558613
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:24:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7effa4d4e650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3700, '_step_count': 3701, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030500 valid_loss:0.032184 each epoch time:20.68868
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.030115  valid_dp 0.031786 reg_loss 6.731783
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:26:17
run time  0:01:42.284247
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/backward_53/backward_53_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558630
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:26:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6529d49350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3705, '_step_count': 3706, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041608 valid_loss:0.041029 each epoch time:20.84700
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041104  valid_dp 0.040539 reg_loss 6.874330
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:28:00
run time  0:01:41.494209
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/backward_53/backward_53_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558648
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:28:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fea68d18510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3710, '_step_count': 3711, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030467 valid_loss:0.032159 each epoch time:19.95262
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.030082  valid_dp 0.031762 reg_loss 6.726768
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:29:43
run time  0:01:41.414363
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/backward_53/backward_53_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558665
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:29:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc407973b10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3715, '_step_count': 3716, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.041567 valid_loss:0.041003 each epoch time:19.89028
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.041063  valid_dp 0.040513 reg_loss 6.866671
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:31:24
run time  0:01:38.657224
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_54/forward_54_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/forward_54/forward_54_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558688
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:31:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb256dafcd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3720, '_step_count': 3721, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.030437 valid_loss:0.032136 each epoch time:20.27912
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.030051  valid_dp 0.031739 reg_loss 6.722393
memory usage : 3.5  at e= 5
end date/time : 20211025, 21:33:07
run time  0:01:41.391642
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_54/forward_54_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/forward_54/forward_54_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  558704
uname :  posix.uname_result(sysname='Linux', nodename='jae4', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:33:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcd57ee59d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.0l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3725, '_step_count': 3726, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.053077 valid_loss:0.052668 each epoch time:20.07058
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000069  valid_dq/boxsize 0.000069  train_dp 0.052459  valid_dp 0.052055 reg_loss 17.986564
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:34:48
run time  0:01:39.238269
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_54/forward_54_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.0l2reg/4rho0.20/forward_54/forward_54_loss.txt
forward 5rho0.10
