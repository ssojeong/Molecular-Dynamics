forward 1rho0.10, first run no save model .....
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  836006
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:48:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f48d4659e50>
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.422835 valid_loss:0.424768 each epoch time:11.66763
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.002358  valid_dq/boxsize 0.002216  train_dp 0.393014  valid_dp 0.396736 reg_loss 49.616803
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:49:43
run time  0:00:58.701912
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/rho0/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/forward_1/forward_1_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  845021
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:49:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f182e74b5d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 5, '_step_count': 6, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.476552 valid_loss:0.471509 each epoch time:11.60006
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002398  valid_dq/boxsize 0.002363  train_dp 0.450919  valid_dp 0.446252 reg_loss 25.636744
memory usage : 3.2  at e= 5
end date/time : 20211025, 14:50:43
run time  0:00:58.588678
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_1/forward_1_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  854038
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:50:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa8490e84d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 10, '_step_count': 11, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.397904 valid_loss:0.404191 each epoch time:11.56273
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001704  valid_dq/boxsize 0.001727  train_dp 0.376355  valid_dp 0.382345 reg_loss 18.902473
memory usage : 3.2  at e= 5
end date/time : 20211025, 14:51:42
run time  0:00:58.330870
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_1/forward_1_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  863054
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:51:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa753d1af90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 15, '_step_count': 16, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.539946 valid_loss:0.537193 each epoch time:11.74064
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.003125  valid_dq/boxsize 0.003111  train_dp 0.511994  valid_dp 0.509365 reg_loss 31.560791
memory usage : 3.2  at e= 5
end date/time : 20211025, 14:52:43
run time  0:00:58.907710
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_1/forward_1_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  872070
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:52:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5bb8fa5fd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 20, '_step_count': 21, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.392959 valid_loss:0.399526 each epoch time:11.66581
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001658  valid_dq/boxsize 0.001684  train_dp 0.371990  valid_dp 0.378220 reg_loss 18.932902
memory usage : 3.2  at e= 5
end date/time : 20211025, 14:53:42
run time  0:00:57.982205
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_1/forward_1_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  881086
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:53:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f85a0227050>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 25, '_step_count': 26, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.465738 valid_loss:0.461528 each epoch time:11.82616
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002270  valid_dq/boxsize 0.002247  train_dp 0.441472  valid_dp 0.437502 reg_loss 22.904543
memory usage : 3.2  at e= 5
end date/time : 20211025, 14:54:42
run time  0:00:58.470100
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_1/forward_1_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  890102
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:54:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3d58da5f90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 30, '_step_count': 31, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.600831 valid_loss:0.599707 each epoch time:11.88544
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003974  valid_dq/boxsize 0.003969  train_dp 0.570238  valid_dp 0.569151 reg_loss 43.619200
memory usage : 3.2  at e= 5
end date/time : 20211025, 14:55:42
run time  0:00:59.152896
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_1/forward_1_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  899118
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:55:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7c24205d90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 35, '_step_count': 36, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.685076 valid_loss:0.684185 each epoch time:11.40426
optimizer lr 0.00100  boxsize 6.48886  train_dq/boxsize 0.005351  valid_dq/boxsize 0.005354  train_dp 0.650353  valid_dp 0.649442 reg_loss 41.300611
memory usage : 3.2  at e= 5
end date/time : 20211025, 14:56:41
run time  0:00:57.294671
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_1/forward_1_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  908133
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:56:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe5be735d50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 40, '_step_count': 41, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.598943 valid_loss:0.597840 each epoch time:11.44025
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003959  valid_dq/boxsize 0.003956  train_dp 0.568470  valid_dp 0.567390 reg_loss 42.320828
memory usage : 3.2  at e= 5
end date/time : 20211025, 14:57:40
run time  0:00:58.435770
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_1/backward_1_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  917149
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:57:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8600cc2610>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 45, '_step_count': 46, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.462948 valid_loss:0.458991 each epoch time:11.62312
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002245  valid_dq/boxsize 0.002224  train_dp 0.438951  valid_dp 0.435212 reg_loss 23.106914
memory usage : 3.2  at e= 5
end date/time : 20211025, 14:58:40
run time  0:00:57.981566
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_1/backward_1_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  926164
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:58:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcc80930d50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 50, '_step_count': 51, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.387822 valid_loss:0.394527 each epoch time:11.33371
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001617  valid_dq/boxsize 0.001645  train_dp 0.367371  valid_dp 0.373722 reg_loss 19.848463
memory usage : 3.2  at e= 5
end date/time : 20211025, 14:59:40
run time  0:00:57.290029
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_1/backward_1_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  935179
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:59:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f20f014cd50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 55, '_step_count': 56, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.532740 valid_loss:0.530208 each epoch time:11.88877
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.003052  valid_dq/boxsize 0.003041  train_dp 0.505446  valid_dp 0.503009 reg_loss 33.039423
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:00:41
run time  0:00:59.017595
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_1/backward_1_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  944195
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:00:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd4ce8aaad0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 60, '_step_count': 61, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.386306 valid_loss:0.393068 each epoch time:11.48191
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001605  valid_dq/boxsize 0.001634  train_dp 0.366001  valid_dp 0.372405 reg_loss 19.969370
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:01:40
run time  0:00:57.695356
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_1/backward_1_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  953209
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:01:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9c591e1f90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 65, '_step_count': 66, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.460385 valid_loss:0.456406 each epoch time:11.38751
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002222  valid_dq/boxsize 0.002202  train_dp 0.436627  valid_dp 0.432862 reg_loss 24.540163
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:02:38
run time  0:00:56.413776
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_1/backward_1_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  962225
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:02:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0d953661d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 70, '_step_count': 71, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.384907 valid_loss:0.391732 each epoch time:11.19379
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001595  valid_dq/boxsize 0.001623  train_dp 0.364734  valid_dp 0.371198 reg_loss 20.101069
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:03:35
run time  0:00:56.266046
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_1/backward_1_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  971240
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:03:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe482083050>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 75, '_step_count': 76, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.459463 valid_loss:0.455489 each epoch time:11.21747
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002213  valid_dq/boxsize 0.002194  train_dp 0.435803  valid_dp 0.432040 reg_loss 24.577694
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:04:31
run time  0:00:55.705616
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_2/forward_2_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  980256
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:04:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f085c8f7bd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 80, '_step_count': 81, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.383793 valid_loss:0.390655 each epoch time:12.00286
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001586  valid_dq/boxsize 0.001615  train_dp 0.363732  valid_dp 0.370232 reg_loss 20.093315
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:05:33
run time  0:00:59.212310
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_2/forward_2_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  989282
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:05:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4a0c808950>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 85, '_step_count': 86, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.530618 valid_loss:0.528086 each epoch time:11.55468
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.003026  valid_dq/boxsize 0.003016  train_dp 0.503556  valid_dp 0.501114 reg_loss 33.400001
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:06:32
run time  0:00:58.033113
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_2/forward_2_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  998297
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:06:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc1648bac90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 90, '_step_count': 91, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.382987 valid_loss:0.389859 each epoch time:11.61168
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001579  valid_dq/boxsize 0.001608  train_dp 0.363011  valid_dp 0.369522 reg_loss 19.961163
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:07:31
run time  0:00:58.584715
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_2/forward_2_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1007312
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:07:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd3e1ada590>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 95, '_step_count': 96, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.457972 valid_loss:0.454046 each epoch time:11.17031
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002198  valid_dq/boxsize 0.002179  train_dp 0.434471  valid_dp 0.430749 reg_loss 24.403935
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:08:30
run time  0:00:58.305411
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_2/forward_2_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1016327
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:08:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0cdd250c10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 100, '_step_count': 101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.595319 valid_loss:0.594205 each epoch time:11.60920
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003914  valid_dq/boxsize 0.003910  train_dp 0.565188  valid_dp 0.564104 reg_loss 44.296397
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:09:30
run time  0:00:58.222410
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_2/forward_2_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1025342
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:09:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f20a307fe90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 105, '_step_count': 106, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.680636 valid_loss:0.679752 each epoch time:11.66121
optimizer lr 0.00100  boxsize 6.48886  train_dq/boxsize 0.005304  valid_dq/boxsize 0.005306  train_dp 0.646221  valid_dp 0.645319 reg_loss 42.705252
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:10:30
run time  0:00:58.976488
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_2/forward_2_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1034358
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:10:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb6177e0990>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 110, '_step_count': 111, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.594300 valid_loss:0.593149 each epoch time:11.30826
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003907  valid_dq/boxsize 0.003904  train_dp 0.564223  valid_dp 0.563097 reg_loss 41.981860
memory usage : 3.1  at e= 5
end date/time : 20211025, 15:11:27
run time  0:00:56.289437
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_2/backward_2_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1043373
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:11:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2110868a90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 115, '_step_count': 116, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.457109 valid_loss:0.453332 each epoch time:11.91926
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002192  valid_dq/boxsize 0.002174  train_dp 0.433674  valid_dp 0.430095 reg_loss 23.438888
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:12:27
run time  0:00:57.939877
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_2/backward_2_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1052388
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:12:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f753a2f2690>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 120, '_step_count': 121, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.381646 valid_loss:0.388500 each epoch time:11.62826
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001569  valid_dq/boxsize 0.001598  train_dp 0.361793  valid_dp 0.368289 reg_loss 19.829648
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:13:26
run time  0:00:58.546108
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_2/backward_2_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1061404
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:13:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f649040e7d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 125, '_step_count': 126, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.528369 valid_loss:0.525835 each epoch time:11.36576
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.003006  valid_dq/boxsize 0.002996  train_dp 0.501486  valid_dp 0.499039 reg_loss 33.931144
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:14:25
run time  0:00:57.934686
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_2/backward_2_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1070419
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:14:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe7ba6e8990>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 130, '_step_count': 131, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.380938 valid_loss:0.387829 each epoch time:11.57050
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001563  valid_dq/boxsize 0.001592  train_dp 0.361162  valid_dp 0.367692 reg_loss 19.779404
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:15:24
run time  0:00:57.595929
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_2/backward_2_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1079434
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:15:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0e087f33d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 135, '_step_count': 136, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.455962 valid_loss:0.452131 each epoch time:11.21492
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002181  valid_dq/boxsize 0.002163  train_dp 0.432641  valid_dp 0.429008 reg_loss 24.323365
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:16:21
run time  0:00:56.555865
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_2/backward_2_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1088449
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:16:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8ba32123d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 140, '_step_count': 141, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.380218 valid_loss:0.387149 each epoch time:11.41736
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001557  valid_dq/boxsize 0.001586  train_dp 0.360518  valid_dp 0.367087 reg_loss 19.792235
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:17:19
run time  0:00:57.081645
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_2/backward_2_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1097468
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:17:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f49c2507dd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 145, '_step_count': 146, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.455505 valid_loss:0.451672 each epoch time:11.67088
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002177  valid_dq/boxsize 0.002158  train_dp 0.432236  valid_dp 0.428600 reg_loss 24.213903
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:18:18
run time  0:00:58.310333
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_3/forward_3_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1106483
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:18:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faecd0b8d50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 150, '_step_count': 151, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.379624 valid_loss:0.386580 each epoch time:11.66701
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001552  valid_dq/boxsize 0.001581  train_dp 0.359990  valid_dp 0.366583 reg_loss 19.685358
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:19:18
run time  0:00:58.683870
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_3/forward_3_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1115498
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:19:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f701008ab10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 155, '_step_count': 156, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.527419 valid_loss:0.524872 each epoch time:11.70779
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.002993  valid_dq/boxsize 0.002983  train_dp 0.500649  valid_dp 0.498188 reg_loss 33.849808
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:20:17
run time  0:00:58.788592
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_3/forward_3_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1124513
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:20:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6ae3292b10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 160, '_step_count': 161, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.379190 valid_loss:0.386145 each epoch time:11.62893
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001548  valid_dq/boxsize 0.001577  train_dp 0.359605  valid_dp 0.366200 reg_loss 19.465138
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:21:16
run time  0:00:57.767773
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_3/forward_3_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1133528
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:21:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f04a8f12d90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 165, '_step_count': 166, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.454695 valid_loss:0.450884 each epoch time:11.71628
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002168  valid_dq/boxsize 0.002150  train_dp 0.431515  valid_dp 0.427900 reg_loss 23.861723
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:22:16
run time  0:00:58.826770
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_3/forward_3_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1142543
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:22:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbf6ca22ad0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 170, '_step_count': 171, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.592751 valid_loss:0.591595 each epoch time:11.31509
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003888  valid_dq/boxsize 0.003884  train_dp 0.562821  valid_dp 0.561695 reg_loss 43.017590
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:23:14
run time  0:00:57.614971
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_3/forward_3_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1151558
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:23:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff12c648390>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 175, '_step_count': 176, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.678336 valid_loss:0.677452 each epoch time:11.75028
optimizer lr 0.00100  boxsize 6.48886  train_dq/boxsize 0.005282  valid_dq/boxsize 0.005284  train_dp 0.644063  valid_dp 0.643164 reg_loss 42.103172
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:24:14
run time  0:00:58.883248
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_3/forward_3_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1160573
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:24:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa30b62bd90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 180, '_step_count': 181, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.591962 valid_loss:0.590771 each epoch time:11.25886
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003884  valid_dq/boxsize 0.003880  train_dp 0.562066  valid_dp 0.560902 reg_loss 40.560161
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:25:11
run time  0:00:56.370053
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_3/backward_3_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1169588
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:25:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe198a7c350>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 185, '_step_count': 186, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.454174 valid_loss:0.450481 each epoch time:11.29690
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002166  valid_dq/boxsize 0.002148  train_dp 0.431020  valid_dp 0.427521 reg_loss 22.687116
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:26:08
run time  0:00:56.560760
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_3/backward_3_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1178604
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:26:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbcf477fc90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 190, '_step_count': 191, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.378472 valid_loss:0.385404 each epoch time:11.95180
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001543  valid_dq/boxsize 0.001572  train_dp 0.358949  valid_dp 0.365523 reg_loss 19.084778
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:27:09
run time  0:00:59.996417
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_3/backward_3_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1187619
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:27:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efc2163bf90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 195, '_step_count': 196, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.525967 valid_loss:0.523408 each epoch time:11.65112
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.002982  valid_dq/boxsize 0.002972  train_dp 0.499296  valid_dp 0.496822 reg_loss 33.823013
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:28:08
run time  0:00:57.943262
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_3/backward_3_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1196634
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:28:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7effe15c5d90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 200, '_step_count': 201, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.378011 valid_loss:0.384974 each epoch time:12.04089
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001539  valid_dq/boxsize 0.001568  train_dp 0.358538  valid_dp 0.365142 reg_loss 19.053251
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:29:09
run time  0:00:59.961540
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_3/backward_3_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1205652
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:29:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f87962bb050>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 205, '_step_count': 206, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.453418 valid_loss:0.449683 each epoch time:11.99303
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002159  valid_dq/boxsize 0.002140  train_dp 0.430342  valid_dp 0.426802 reg_loss 23.464509
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:30:11
run time  0:00:59.635476
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_3/backward_3_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1214673
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:30:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7aaae621d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 210, '_step_count': 211, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.377530 valid_loss:0.384523 each epoch time:11.46131
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001535  valid_dq/boxsize 0.001564  train_dp 0.358110  valid_dp 0.364743 reg_loss 19.075360
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:31:10
run time  0:00:57.617366
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_3/backward_3_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1223690
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:31:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb8aa961250>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 215, '_step_count': 216, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.453114 valid_loss:0.449373 each epoch time:11.95782
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002156  valid_dq/boxsize 0.002137  train_dp 0.430070  valid_dp 0.426525 reg_loss 23.390253
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:32:10
run time  0:00:59.308269
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_4/forward_4_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1232706
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:32:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f86d4aa0e50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 220, '_step_count': 221, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.377129 valid_loss:0.384136 each epoch time:11.95858
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001532  valid_dq/boxsize 0.001560  train_dp 0.357753  valid_dp 0.364402 reg_loss 18.989749
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:33:09
run time  0:00:58.583844
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_4/forward_4_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1241721
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:33:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2c1ac9bf50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 225, '_step_count': 226, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.525341 valid_loss:0.522772 each epoch time:11.65449
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.002974  valid_dq/boxsize 0.002965  train_dp 0.498739  valid_dp 0.496255 reg_loss 33.784148
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:34:09
run time  0:00:58.533111
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_4/forward_4_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1250736
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:34:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f49e122e150>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 230, '_step_count': 231, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.376834 valid_loss:0.383843 each epoch time:11.78195
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001529  valid_dq/boxsize 0.001558  train_dp 0.357491  valid_dp 0.364142 reg_loss 18.809200
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:35:10
run time  0:00:58.566894
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_4/forward_4_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1259752
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:35:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f485bb19e90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 235, '_step_count': 236, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.452557 valid_loss:0.448826 each epoch time:11.61924
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002150  valid_dq/boxsize 0.002132  train_dp 0.429571  valid_dp 0.426034 reg_loss 23.089122
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:36:09
run time  0:00:57.472397
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_4/forward_4_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1268767
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:36:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f47dbe17f90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 240, '_step_count': 241, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.590926 valid_loss:0.589725 each epoch time:11.44559
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003873  valid_dq/boxsize 0.003869  train_dp 0.561115  valid_dp 0.559944 reg_loss 41.759132
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:37:07
run time  0:00:57.524244
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_4/forward_4_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1277782
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:37:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4260051290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 245, '_step_count': 246, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.676590 valid_loss:0.675700 each epoch time:11.77867
optimizer lr 0.00100  boxsize 6.48886  train_dq/boxsize 0.005269  valid_dq/boxsize 0.005271  train_dp 0.642404  valid_dp 0.641498 reg_loss 41.248494
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:38:07
run time  0:00:59.110610
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_4/forward_4_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1286798
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:38:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f42b6426dd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 250, '_step_count': 251, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.590246 valid_loss:0.589023 each epoch time:11.08654
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003869  valid_dq/boxsize 0.003866  train_dp 0.560460  valid_dp 0.559266 reg_loss 39.297428
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:39:06
run time  0:00:56.742360
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_4/backward_4_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1295813
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:39:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb2b1c9d510>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 255, '_step_count': 256, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.452173 valid_loss:0.448527 each epoch time:11.81660
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002149  valid_dq/boxsize 0.002131  train_dp 0.429197  valid_dp 0.425744 reg_loss 21.883959
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:40:05
run time  0:00:58.109740
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_4/backward_4_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1304828
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:40:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6cd7576cd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 260, '_step_count': 261, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.376363 valid_loss:0.383338 each epoch time:11.89142
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001527  valid_dq/boxsize 0.001555  train_dp 0.357052  valid_dp 0.363669 reg_loss 18.355136
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:41:05
run time  0:00:59.026610
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_4/backward_4_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1313843
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:41:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f27a2b468d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 265, '_step_count': 266, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.524210 valid_loss:0.521641 each epoch time:11.49639
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.002967  valid_dq/boxsize 0.002958  train_dp 0.497671  valid_dp 0.495187 reg_loss 33.531261
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:42:05
run time  0:00:57.978430
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_4/backward_4_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1322865
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:42:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdebe2f0a90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 270, '_step_count': 271, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.376017 valid_loss:0.383017 each epoch time:11.38498
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001524  valid_dq/boxsize 0.001552  train_dp 0.356743  valid_dp 0.363384 reg_loss 18.355554
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:43:04
run time  0:00:57.505973
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_4/backward_4_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1331880
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:43:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff9c3361e90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 275, '_step_count': 276, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.451594 valid_loss:0.447916 each epoch time:11.66785
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002144  valid_dq/boxsize 0.002126  train_dp 0.428672  valid_dp 0.425189 reg_loss 22.584404
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:44:03
run time  0:00:58.467496
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_4/backward_4_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1340896
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:44:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9428930c90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 280, '_step_count': 281, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.375651 valid_loss:0.382673 each epoch time:11.40061
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001521  valid_dq/boxsize 0.001549  train_dp 0.356415  valid_dp 0.363078 reg_loss 18.392779
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:45:00
run time  0:00:56.484789
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_4/backward_4_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1349911
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:45:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9e923daf90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 285, '_step_count': 286, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.451359 valid_loss:0.447679 each epoch time:10.85337
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002142  valid_dq/boxsize 0.002124  train_dp 0.428461  valid_dp 0.424975 reg_loss 22.532279
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:45:56
run time  0:00:54.991318
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_5/forward_5_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1358926
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:45:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9efb3bcf50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 290, '_step_count': 291, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.375341 valid_loss:0.382376 each epoch time:11.60706
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001518  valid_dq/boxsize 0.001547  train_dp 0.356138  valid_dp 0.362814 reg_loss 18.335139
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:46:55
run time  0:00:57.707345
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_5/forward_5_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1367941
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:46:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe0fa4dff50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 295, '_step_count': 296, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.523727 valid_loss:0.521149 each epoch time:11.56534
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.002962  valid_dq/boxsize 0.002952  train_dp 0.497234  valid_dp 0.494742 reg_loss 33.539487
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:47:54
run time  0:00:58.387303
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_5/forward_5_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1376956
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:47:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f940a193fd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 300, '_step_count': 301, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.375112 valid_loss:0.382143 each epoch time:11.92245
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001516  valid_dq/boxsize 0.001545  train_dp 0.355932  valid_dp 0.362605 reg_loss 18.181795
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:48:54
run time  0:00:58.699043
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_5/forward_5_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1385971
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:48:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f46fa472d90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 305, '_step_count': 306, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.450922 valid_loss:0.447248 each epoch time:11.41957
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002138  valid_dq/boxsize 0.002120  train_dp 0.428065  valid_dp 0.424585 reg_loss 22.285627
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:49:55
run time  0:00:57.610952
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_5/forward_5_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1394995
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:49:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f07107cead0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 310, '_step_count': 311, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.589418 valid_loss:0.588189 each epoch time:11.68784
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003862  valid_dq/boxsize 0.003858  train_dp 0.559686  valid_dp 0.558490 reg_loss 40.659745
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:50:55
run time  0:00:58.743568
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_5/forward_5_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1404010
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:50:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc7d3125e10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 315, '_step_count': 316, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.675082 valid_loss:0.674185 each epoch time:11.67516
optimizer lr 0.00100  boxsize 6.48886  train_dq/boxsize 0.005259  valid_dq/boxsize 0.005262  train_dp 0.640955  valid_dp 0.640043 reg_loss 40.358867
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:51:54
run time  0:00:57.716533
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_5/forward_5_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1413025
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:51:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f84d93f25d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 320, '_step_count': 321, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.588806 valid_loss:0.587558 each epoch time:11.52932
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003859  valid_dq/boxsize 0.003856  train_dp 0.559096  valid_dp 0.557878 reg_loss 38.256886
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:52:53
run time  0:00:57.782560
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_5/backward_5_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1422040
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:52:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9768045ad0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 325, '_step_count': 326, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.450604 valid_loss:0.447018 each epoch time:11.78495
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002138  valid_dq/boxsize 0.002120  train_dp 0.427750  valid_dp 0.424355 reg_loss 21.093869
memory usage : 3.1  at e= 5
end date/time : 20211025, 15:53:52
run time  0:00:58.585363
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_5/backward_5_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1431055
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:53:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4dd3bf2790>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 330, '_step_count': 331, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.374755 valid_loss:0.381747 each epoch time:11.31332
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001515  valid_dq/boxsize 0.001543  train_dp 0.355589  valid_dp 0.362224 reg_loss 17.695169
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:54:51
run time  0:00:56.909623
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_5/backward_5_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1440070
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:54:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efba82c3650>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 335, '_step_count': 336, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.522765 valid_loss:0.520198 each epoch time:11.94798
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.002957  valid_dq/boxsize 0.002948  train_dp 0.496317  valid_dp 0.493834 reg_loss 33.136966
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:55:50
run time  0:00:58.987782
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_5/backward_5_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1449086
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:55:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc517954410>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 340, '_step_count': 341, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.374469 valid_loss:0.381485 each epoch time:11.19600
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001513  valid_dq/boxsize 0.001541  train_dp 0.355331  valid_dp 0.361988 reg_loss 17.722827
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:56:50
run time  0:00:55.510350
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_5/backward_5_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1458107
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:56:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8eb73e4410>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 345, '_step_count': 346, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.450117 valid_loss:0.446495 each epoch time:11.83969
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002134  valid_dq/boxsize 0.002116  train_dp 0.427303  valid_dp 0.423874 reg_loss 21.740532
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:57:52
run time  0:00:59.142350
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_5/backward_5_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1467122
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:57:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fde0aebdf50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 350, '_step_count': 351, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.374164 valid_loss:0.381193 each epoch time:11.42076
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001511  valid_dq/boxsize 0.001539  train_dp 0.355056  valid_dp 0.361725 reg_loss 17.764012
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:58:50
run time  0:00:56.915266
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_5/backward_5_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1476137
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:58:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efd7f2b5e90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 355, '_step_count': 356, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.449917 valid_loss:0.446294 each epoch time:11.41725
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002132  valid_dq/boxsize 0.002114  train_dp 0.427122  valid_dp 0.423691 reg_loss 21.710398
memory usage : 3.2  at e= 5
end date/time : 20211025, 15:59:50
run time  0:00:57.005059
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_6/forward_6_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1485152
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:59:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1f601fe090>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 360, '_step_count': 361, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.373902 valid_loss:0.380940 each epoch time:11.91918
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001509  valid_dq/boxsize 0.001537  train_dp 0.354819  valid_dp 0.361497 reg_loss 17.728581
memory usage : 3.1  at e= 5
end date/time : 20211025, 16:00:50
run time  0:00:59.677369
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_6/forward_6_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1494167
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:00:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc750956050>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 365, '_step_count': 366, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.522351 valid_loss:0.519779 each epoch time:11.35490
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.002953  valid_dq/boxsize 0.002944  train_dp 0.495938  valid_dp 0.493451 reg_loss 33.214625
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:01:49
run time  0:00:58.146382
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_6/forward_6_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1503183
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:01:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9b7be65f50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 370, '_step_count': 371, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.373706 valid_loss:0.380740 each epoch time:11.73252
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001507  valid_dq/boxsize 0.001536  train_dp 0.354641  valid_dp 0.361315 reg_loss 17.594759
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:02:49
run time  0:00:58.560112
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_6/forward_6_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1512198
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:02:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f500dc38310>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 375, '_step_count': 376, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.449544 valid_loss:0.445926 each epoch time:11.26327
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002129  valid_dq/boxsize 0.002111  train_dp 0.426780  valid_dp 0.423354 reg_loss 21.520423
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:03:47
run time  0:00:56.484260
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_6/forward_6_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1521214
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:03:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbafa759e10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 380, '_step_count': 381, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.588079 valid_loss:0.586832 each epoch time:11.71662
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003855  valid_dq/boxsize 0.003850  train_dp 0.558407  valid_dp 0.557193 reg_loss 39.785664
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:04:47
run time  0:00:58.765072
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_6/forward_6_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1530229
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:04:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4618a0ac50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 385, '_step_count': 386, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.673704 valid_loss:0.672795 each epoch time:11.74043
optimizer lr 0.00100  boxsize 6.48886  train_dq/boxsize 0.005252  valid_dq/boxsize 0.005255  train_dp 0.639622  valid_dp 0.638699 reg_loss 39.585713
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:05:47
run time  0:00:58.903428
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_6/forward_6_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1539244
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:05:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2b25451bd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 390, '_step_count': 391, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.587516 valid_loss:0.586258 each epoch time:11.97514
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003852  valid_dq/boxsize 0.003848  train_dp 0.557862  valid_dp 0.556636 reg_loss 37.450623
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:06:47
run time  0:00:59.296562
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_6/backward_6_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1548262
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:06:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f812c359390>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 395, '_step_count': 396, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.449263 valid_loss:0.445725 each epoch time:11.47440
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002129  valid_dq/boxsize 0.002112  train_dp 0.426498  valid_dp 0.423150 reg_loss 20.375374
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:07:46
run time  0:00:58.014477
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_6/backward_6_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1557277
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:07:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f572361b350>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 400, '_step_count': 401, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.373407 valid_loss:0.380404 each epoch time:11.39526
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001507  valid_dq/boxsize 0.001535  train_dp 0.354348  valid_dp 0.360985 reg_loss 17.092693
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:08:45
run time  0:00:57.720863
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_6/backward_6_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1566292
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:08:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faf1d63c790>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 405, '_step_count': 406, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.521491 valid_loss:0.518934 each epoch time:11.60234
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.002949  valid_dq/boxsize 0.002940  train_dp 0.495110  valid_dp 0.492638 reg_loss 32.760810
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:09:45
run time  0:00:58.942563
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_6/backward_6_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1575307
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:09:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7cbe048850>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 410, '_step_count': 411, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.373158 valid_loss:0.380170 each epoch time:11.40473
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001505  valid_dq/boxsize 0.001534  train_dp 0.354121  valid_dp 0.360772 reg_loss 17.130323
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:10:43
run time  0:00:57.673280
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_6/backward_6_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1584322
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:10:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8df9686e90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 415, '_step_count': 416, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.448832 valid_loss:0.445266 each epoch time:11.77615
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002126  valid_dq/boxsize 0.002109  train_dp 0.426099  valid_dp 0.422724 reg_loss 20.985212
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:11:44
run time  0:00:58.945887
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_6/backward_6_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1593338
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:11:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f866886d650>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 420, '_step_count': 421, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.372890 valid_loss:0.379914 each epoch time:11.43418
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001503  valid_dq/boxsize 0.001532  train_dp 0.353877  valid_dp 0.360540 reg_loss 17.190841
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:12:44
run time  0:00:56.988409
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_6/backward_6_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1602360
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:12:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f85503d8390>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 425, '_step_count': 426, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.448655 valid_loss:0.445081 each epoch time:11.67728
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002125  valid_dq/boxsize 0.002107  train_dp 0.425937  valid_dp 0.422554 reg_loss 20.987621
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:13:43
run time  0:00:58.180987
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_7/forward_7_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1611375
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:13:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa908fbb290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 430, '_step_count': 431, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.372659 valid_loss:0.379689 each epoch time:11.75789
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001502  valid_dq/boxsize 0.001530  train_dp 0.353667  valid_dp 0.360336 reg_loss 17.177717
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:14:42
run time  0:00:58.012130
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_7/forward_7_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1620390
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:14:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f807ed763d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 435, '_step_count': 436, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.521120 valid_loss:0.518558 each epoch time:11.78571
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.002946  valid_dq/boxsize 0.002937  train_dp 0.494767  valid_dp 0.492289 reg_loss 32.853869
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:15:42
run time  0:00:59.063339
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_7/forward_7_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1629405
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:15:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0882e8b910>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 440, '_step_count': 441, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.372487 valid_loss:0.379511 each epoch time:11.75762
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001500  valid_dq/boxsize 0.001529  train_dp 0.353508  valid_dp 0.360172 reg_loss 17.059169
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:16:41
run time  0:00:58.505651
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_7/forward_7_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1638420
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:16:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb45cefae90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 445, '_step_count': 446, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.448324 valid_loss:0.444752 each epoch time:11.06876
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002123  valid_dq/boxsize 0.002105  train_dp 0.425631  valid_dp 0.422250 reg_loss 20.827183
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:17:37
run time  0:00:55.225670
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_7/forward_7_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1647439
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:17:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8ed2252950>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 450, '_step_count': 451, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.586848 valid_loss:0.585598 each epoch time:11.66064
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003849  valid_dq/boxsize 0.003844  train_dp 0.557222  valid_dp 0.556005 reg_loss 39.088268
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:18:37
run time  0:00:58.151077
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_7/forward_7_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1656454
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:18:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f95f245fb90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 455, '_step_count': 456, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.672410 valid_loss:0.671495 each epoch time:11.62334
optimizer lr 0.00100  boxsize 6.48886  train_dq/boxsize 0.005247  valid_dq/boxsize 0.005249  train_dp 0.638362  valid_dp 0.637435 reg_loss 38.987778
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:19:36
run time  0:00:58.220057
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_7/forward_7_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1665469
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:19:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0e8e25b290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 460, '_step_count': 461, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.586322 valid_loss:0.585060 each epoch time:11.64441
optimizer lr 0.00100  boxsize 7.69800  train_dq/boxsize 0.003846  valid_dq/boxsize 0.003842  train_dp 0.556713  valid_dp 0.555483 reg_loss 36.813908
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:20:35
run time  0:00:58.191332
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_7/backward_7_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1674484
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:20:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb26cc235d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 465, '_step_count': 466, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.448068 valid_loss:0.444571 each epoch time:11.34479
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002123  valid_dq/boxsize 0.002105  train_dp 0.425371  valid_dp 0.422065 reg_loss 19.721774
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:21:33
run time  0:00:56.961387
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_7/backward_7_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1683499
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:21:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe38f50b950>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 470, '_step_count': 471, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.372227 valid_loss:0.379209 each epoch time:11.25203
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001500  valid_dq/boxsize 0.001529  train_dp 0.353250  valid_dp 0.359871 reg_loss 16.572272
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:22:30
run time  0:00:55.716303
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_7/backward_7_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1692514
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:22:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f84ca1e10d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 475, '_step_count': 476, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.520333 valid_loss:0.517784 each epoch time:11.76301
optimizer lr 0.00100  boxsize 8.94427  train_dq/boxsize 0.002944  valid_dq/boxsize 0.002934  train_dp 0.494004  valid_dp 0.491540 reg_loss 32.340640
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:23:30
run time  0:00:59.165469
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_7/backward_7_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1701529
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:23:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd54cc5ef10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 480, '_step_count': 481, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.372004 valid_loss:0.379000 each epoch time:11.63879
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001499  valid_dq/boxsize 0.001527  train_dp 0.353045  valid_dp 0.359680 reg_loss 16.614398
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:24:29
run time  0:00:58.042904
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_7/backward_7_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1710545
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:24:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fca5625a350>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 485, '_step_count': 486, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.447680 valid_loss:0.444154 each epoch time:11.64905
optimizer lr 0.00100  boxsize 10.69045  train_dq/boxsize 0.002121  valid_dq/boxsize 0.002103  train_dp 0.425010  valid_dp 0.421674 reg_loss 20.324531
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:25:30
run time  0:00:59.164808
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_7/backward_7_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1719560
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:25:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9ea9476850>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 490, '_step_count': 491, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.371766 valid_loss:0.378771 each epoch time:11.87485
optimizer lr 0.00100  boxsize 12.64911  train_dq/boxsize 0.001497  valid_dq/boxsize 0.001526  train_dp 0.352827  valid_dp 0.359471 reg_loss 16.683534
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:26:29
run time  0:00:57.818345
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_7/backward_7_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1728575
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:26:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3489e9b250>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 495, '_step_count': 496, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.447519 valid_loss:0.443992 each epoch time:11.22343
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002119  valid_dq/boxsize 0.002102  train_dp 0.424862  valid_dp 0.421526 reg_loss 20.325768
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:27:26
run time  0:00:56.709406
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_8/forward_8_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1737590
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:27:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f703c4608d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 500, '_step_count': 501, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.371562 valid_loss:0.378576 each epoch time:11.62953
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001496  valid_dq/boxsize 0.001524  train_dp 0.352641  valid_dp 0.359294 reg_loss 16.673569
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:28:26
run time  0:00:58.263697
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_8/forward_8_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1746605
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:28:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe4b021f790>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 505, '_step_count': 506, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.519996 valid_loss:0.517444 each epoch time:11.70908
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002941  valid_dq/boxsize 0.002932  train_dp 0.493690  valid_dp 0.491222 reg_loss 32.453664
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:29:25
run time  0:00:59.014389
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_8/forward_8_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1755620
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:29:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0dda288310>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 510, '_step_count': 511, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.371411 valid_loss:0.378420 each epoch time:11.48572
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001495  valid_dq/boxsize 0.001524  train_dp 0.352501  valid_dp 0.359148 reg_loss 16.564504
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:30:25
run time  0:00:57.698030
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_8/forward_8_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1764637
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:30:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f46b5d37e90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 515, '_step_count': 516, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.447227 valid_loss:0.443701 each epoch time:12.17802
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002117  valid_dq/boxsize 0.002100  train_dp 0.424591  valid_dp 0.421255 reg_loss 20.200978
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:31:26
run time  0:00:59.986370
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_8/forward_8_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1773653
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:31:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffa16a1b150>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 520, '_step_count': 521, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.585706 valid_loss:0.584443 each epoch time:11.90205
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003844  valid_dq/boxsize 0.003839  train_dp 0.556117  valid_dp 0.554888 reg_loss 38.499690
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:32:27
run time  0:00:59.644491
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_8/forward_8_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1782673
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:32:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbe8fc9ce50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 525, '_step_count': 526, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.671195 valid_loss:0.670283 each epoch time:11.85186
optimizer lr 0.00098  boxsize 6.48886  train_dq/boxsize 0.005243  valid_dq/boxsize 0.005245  train_dp 0.637174  valid_dp 0.636250 reg_loss 38.577713
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:33:27
run time  0:00:59.071712
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_8/forward_8_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1791689
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:33:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f222c397410>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 530, '_step_count': 531, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.585215 valid_loss:0.583951 each epoch time:11.56606
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003842  valid_dq/boxsize 0.003837  train_dp 0.555642  valid_dp 0.554410 reg_loss 36.333220
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:34:25
run time  0:00:57.862894
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_8/backward_8_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1800707
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:34:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd12cf24110>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 535, '_step_count': 536, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.446993 valid_loss:0.443534 each epoch time:11.49879
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002118  valid_dq/boxsize 0.002100  train_dp 0.424351  valid_dp 0.421082 reg_loss 19.167507
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:35:24
run time  0:00:57.459939
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_8/backward_8_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1809722
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:35:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7499b26dd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 540, '_step_count': 541, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.371187 valid_loss:0.378148 each epoch time:11.07929
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001495  valid_dq/boxsize 0.001524  train_dp 0.352275  valid_dp 0.358875 reg_loss 16.114080
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:36:20
run time  0:00:55.037647
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_8/backward_8_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1818737
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:36:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f17e8e83dd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 545, '_step_count': 546, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.519277 valid_loss:0.516736 each epoch time:11.58152
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002939  valid_dq/boxsize 0.002930  train_dp 0.492989  valid_dp 0.490532 reg_loss 31.902988
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:37:21
run time  0:00:58.280922
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_8/backward_8_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1827753
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:37:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f25f5f01f10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 550, '_step_count': 551, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.370990 valid_loss:0.377969 each epoch time:10.93819
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001494  valid_dq/boxsize 0.001523  train_dp 0.352092  valid_dp 0.358709 reg_loss 16.163499
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:38:17
run time  0:00:55.233864
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_8/backward_8_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1836768
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:38:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7720f0d150>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 555, '_step_count': 556, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.446643 valid_loss:0.443163 each epoch time:11.70315
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002116  valid_dq/boxsize 0.002098  train_dp 0.424024  valid_dp 0.420733 reg_loss 19.753448
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:39:18
run time  0:00:59.651734
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_8/backward_8_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1845783
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:39:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4f43679e10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 560, '_step_count': 561, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.370778 valid_loss:0.377774 each epoch time:11.54373
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001493  valid_dq/boxsize 0.001521  train_dp 0.351898  valid_dp 0.358531 reg_loss 16.233173
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:40:16
run time  0:00:56.990114
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_8/backward_8_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1854805
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:40:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9c22b8c690>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 565, '_step_count': 566, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.446498 valid_loss:0.443015 each epoch time:11.82378
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002115  valid_dq/boxsize 0.002097  train_dp 0.423890  valid_dp 0.420597 reg_loss 19.764952
memory usage : 3.1  at e= 5
end date/time : 20211025, 16:41:17
run time  0:00:59.828050
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_9/forward_9_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1863820
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:41:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe5ce67d850>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 570, '_step_count': 571, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.370595 valid_loss:0.377596 each epoch time:11.73353
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001491  valid_dq/boxsize 0.001520  train_dp 0.351730  valid_dp 0.358368 reg_loss 16.230707
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:42:17
run time  0:00:58.406568
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_9/forward_9_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1872835
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:42:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7519313b50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 575, '_step_count': 576, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.518967 valid_loss:0.516424 each epoch time:11.94360
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002937  valid_dq/boxsize 0.002928  train_dp 0.492698  valid_dp 0.490239 reg_loss 32.040727
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:43:17
run time  0:00:59.906088
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_9/forward_9_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1881851
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:43:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efe2df83290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 580, '_step_count': 581, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.370457 valid_loss:0.377453 each epoch time:11.43536
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001491  valid_dq/boxsize 0.001519  train_dp 0.351601  valid_dp 0.358235 reg_loss 16.142589
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:44:15
run time  0:00:57.127706
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_9/forward_9_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1890866
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:44:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd5a8047890>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 585, '_step_count': 586, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.446230 valid_loss:0.442747 each epoch time:11.98756
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002113  valid_dq/boxsize 0.002096  train_dp 0.423638  valid_dp 0.420345 reg_loss 19.669999
memory usage : 3.1  at e= 5
end date/time : 20211025, 16:45:16
run time  0:00:59.925947
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_9/forward_9_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1899881
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:45:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1f2ed26310>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 590, '_step_count': 591, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.584633 valid_loss:0.583365 each epoch time:11.23261
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003840  valid_dq/boxsize 0.003835  train_dp 0.555073  valid_dp 0.553840 reg_loss 38.018404
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:46:14
run time  0:00:56.365159
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_9/forward_9_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1908896
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:46:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f35da1a8bd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 595, '_step_count': 596, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.670028 valid_loss:0.669114 each epoch time:11.75815
optimizer lr 0.00098  boxsize 6.48886  train_dq/boxsize 0.005240  valid_dq/boxsize 0.005242  train_dp 0.636028  valid_dp 0.635102 reg_loss 38.271354
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:47:12
run time  0:00:57.717509
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_9/forward_9_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1917911
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:47:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffb60237e10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 600, '_step_count': 601, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.584162 valid_loss:0.582894 each epoch time:11.96084
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003838  valid_dq/boxsize 0.003834  train_dp 0.554617  valid_dp 0.553382 reg_loss 35.936997
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:48:13
run time  0:00:59.774819
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_9/backward_9_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1926926
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:48:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f52903ef490>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 605, '_step_count': 606, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.446011 valid_loss:0.442594 each epoch time:11.55565
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002114  valid_dq/boxsize 0.002096  train_dp 0.423413  valid_dp 0.420185 reg_loss 18.689663
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:49:13
run time  0:00:58.159112
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_9/backward_9_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1935942
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:49:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9564394590>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 610, '_step_count': 611, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.370255 valid_loss:0.377206 each epoch time:11.72813
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001491  valid_dq/boxsize 0.001520  train_dp 0.351395  valid_dp 0.357984 reg_loss 15.721053
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:50:12
run time  0:00:58.949871
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_9/backward_9_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1944957
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:50:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbe8f980610>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 615, '_step_count': 616, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.518286 valid_loss:0.515754 each epoch time:11.82601
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002935  valid_dq/boxsize 0.002926  train_dp 0.492031  valid_dp 0.489584 reg_loss 31.490539
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:51:13
run time  0:00:59.033362
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_9/backward_9_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1953972
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:51:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f17c56db7d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 620, '_step_count': 621, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.370072 valid_loss:0.377037 each epoch time:11.37141
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001490  valid_dq/boxsize 0.001519  train_dp 0.351224  valid_dp 0.357826 reg_loss 15.771146
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:52:11
run time  0:00:56.943479
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_9/backward_9_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1962987
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:52:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd57e54dad0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 625, '_step_count': 626, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.445685 valid_loss:0.442245 each epoch time:11.63653
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002112  valid_dq/boxsize 0.002094  train_dp 0.423106  valid_dp 0.419855 reg_loss 19.266967
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:53:10
run time  0:00:57.501093
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_9/backward_9_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1972002
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:53:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efee344bad0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 630, '_step_count': 631, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.369878 valid_loss:0.376857 each epoch time:11.35046
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001489  valid_dq/boxsize 0.001518  train_dp 0.351045  valid_dp 0.357661 reg_loss 15.838983
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:54:08
run time  0:00:57.268633
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_9/backward_9_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1981017
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:54:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4af428e350>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 635, '_step_count': 636, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.445550 valid_loss:0.442107 each epoch time:11.64357
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002111  valid_dq/boxsize 0.002094  train_dp 0.422980  valid_dp 0.419727 reg_loss 19.284154
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:55:07
run time  0:00:58.465406
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_10/forward_10_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1990033
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:55:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f058a7b58d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 640, '_step_count': 641, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.369709 valid_loss:0.376695 each epoch time:11.93378
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001488  valid_dq/boxsize 0.001517  train_dp 0.350889  valid_dp 0.357512 reg_loss 15.846287
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:56:07
run time  0:00:58.780516
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_10/forward_10_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  1999048
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:56:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faf7d019510>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 645, '_step_count': 646, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.517994 valid_loss:0.515459 each epoch time:11.75662
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002934  valid_dq/boxsize 0.002924  train_dp 0.491756  valid_dp 0.489305 reg_loss 31.619451
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:57:06
run time  0:00:58.647799
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_10/forward_10_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2008063
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:57:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fea85148150>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 650, '_step_count': 651, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.369581 valid_loss:0.376565 each epoch time:11.64240
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001487  valid_dq/boxsize 0.001516  train_dp 0.350770  valid_dp 0.357389 reg_loss 15.764867
memory usage : 3.2  at e= 5
end date/time : 20211025, 16:58:06
run time  0:00:58.894195
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_10/forward_10_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2017078
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:58:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0660330490>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 655, '_step_count': 656, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.445300 valid_loss:0.441859 each epoch time:11.95274
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002110  valid_dq/boxsize 0.002092  train_dp 0.422745  valid_dp 0.419492 reg_loss 19.208629
memory usage : 3.1  at e= 5
end date/time : 20211025, 16:59:07
run time  0:01:00.006196
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_10/forward_10_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2026093
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:59:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8f3ee13d50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 660, '_step_count': 661, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.583604 valid_loss:0.582334 each epoch time:11.74590
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003837  valid_dq/boxsize 0.003832  train_dp 0.554068  valid_dp 0.552833 reg_loss 37.593428
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:00:07
run time  0:00:59.061924
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_10/forward_10_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2035108
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:00:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6022eaf210>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 665, '_step_count': 666, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.668899 valid_loss:0.667987 each epoch time:11.62877
optimizer lr 0.00098  boxsize 6.48886  train_dq/boxsize 0.005237  valid_dq/boxsize 0.005239  train_dp 0.634915  valid_dp 0.633990 reg_loss 38.001750
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:01:06
run time  0:00:58.080235
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_10/forward_10_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2044124
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:01:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8566433210>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 670, '_step_count': 671, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.583151 valid_loss:0.581882 each epoch time:11.84029
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003835  valid_dq/boxsize 0.003831  train_dp 0.553629  valid_dp 0.552393 reg_loss 35.575458
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:02:05
run time  0:00:58.822576
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_10/backward_10_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2053139
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:02:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f992b3ebbd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 675, '_step_count': 676, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.445091 valid_loss:0.441713 each epoch time:11.66870
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002110  valid_dq/boxsize 0.002093  train_dp 0.422530  valid_dp 0.419340 reg_loss 18.271482
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:03:04
run time  0:00:57.925407
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_10/backward_10_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2062155
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:03:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe950b85290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 680, '_step_count': 681, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.369396 valid_loss:0.376337 each epoch time:11.38327
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001488  valid_dq/boxsize 0.001516  train_dp 0.350579  valid_dp 0.357157 reg_loss 15.361731
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:04:03
run time  0:00:57.980880
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_10/backward_10_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2071170
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:04:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9c7fa17050>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 685, '_step_count': 686, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.517346 valid_loss:0.514822 each epoch time:11.91573
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002932  valid_dq/boxsize 0.002923  train_dp 0.491119  valid_dp 0.488678 reg_loss 31.066531
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:05:04
run time  0:01:00.061276
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_10/backward_10_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2080185
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:05:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1f93f04290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 690, '_step_count': 691, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.369226 valid_loss:0.376183 each epoch time:11.61605
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001487  valid_dq/boxsize 0.001516  train_dp 0.350418  valid_dp 0.357011 reg_loss 15.416835
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:06:05
run time  0:00:57.397242
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_10/backward_10_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2089206
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:06:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4871a864d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 695, '_step_count': 696, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.444785 valid_loss:0.441381 each epoch time:11.85409
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002109  valid_dq/boxsize 0.002091  train_dp 0.422238  valid_dp 0.419023 reg_loss 18.835152
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:07:04
run time  0:00:58.136659
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_10/backward_10_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2098222
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:07:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe9625b9350>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 700, '_step_count': 701, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.369044 valid_loss:0.376012 each epoch time:11.26370
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001486  valid_dq/boxsize 0.001515  train_dp 0.350251  valid_dp 0.356854 reg_loss 15.483975
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:08:02
run time  0:00:56.450839
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_10/backward_10_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2107237
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:08:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5e80cd4950>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 705, '_step_count': 706, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.444657 valid_loss:0.441251 each epoch time:12.03759
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002108  valid_dq/boxsize 0.002091  train_dp 0.422120  valid_dp 0.418901 reg_loss 18.854485
memory usage : 3.1  at e= 5
end date/time : 20211025, 17:09:03
run time  0:01:00.242853
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_11/forward_11_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2116252
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:09:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc086e4e990>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 710, '_step_count': 711, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.368887 valid_loss:0.375855 each epoch time:11.72714
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001485  valid_dq/boxsize 0.001514  train_dp 0.350104  valid_dp 0.356708 reg_loss 15.492681
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:10:03
run time  0:00:58.427114
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_11/forward_11_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2125267
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:10:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6128233f50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 715, '_step_count': 716, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.517066 valid_loss:0.514543 each epoch time:11.75352
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002931  valid_dq/boxsize 0.002922  train_dp 0.490851  valid_dp 0.488412 reg_loss 31.213785
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:11:02
run time  0:00:58.368840
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_11/forward_11_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2134282
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:11:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcb4cacfcd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 720, '_step_count': 721, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.368767 valid_loss:0.375734 each epoch time:11.38198
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001484  valid_dq/boxsize 0.001513  train_dp 0.349990  valid_dp 0.356593 reg_loss 15.416090
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:12:01
run time  0:00:58.497786
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_11/forward_11_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2143297
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:12:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0deca36990>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 725, '_step_count': 726, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.444422 valid_loss:0.441016 each epoch time:11.67664
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002107  valid_dq/boxsize 0.002089  train_dp 0.421897  valid_dp 0.418679 reg_loss 18.793563
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:13:01
run time  0:00:58.817805
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_11/forward_11_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2152313
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:13:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc2f0f6e2d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 730, '_step_count': 731, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.582609 valid_loss:0.581342 each epoch time:11.57589
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003834  valid_dq/boxsize 0.003830  train_dp 0.553092  valid_dp 0.551859 reg_loss 37.261809
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:14:01
run time  0:00:58.963400
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_11/forward_11_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2161329
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:14:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f26e7268b50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 735, '_step_count': 736, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.667796 valid_loss:0.666883 each epoch time:11.47663
optimizer lr 0.00098  boxsize 6.48886  train_dq/boxsize 0.005236  valid_dq/boxsize 0.005238  train_dp 0.633823  valid_dp 0.632897 reg_loss 37.807909
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:15:00
run time  0:00:57.932879
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_11/forward_11_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2170344
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:15:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc3c3a16c50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 740, '_step_count': 741, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.582170 valid_loss:0.580905 each epoch time:11.99517
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003833  valid_dq/boxsize 0.003828  train_dp 0.552667  valid_dp 0.551436 reg_loss 35.283440
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:16:01
run time  0:00:59.502979
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_11/backward_11_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2179360
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:16:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f40292668d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 745, '_step_count': 746, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.444221 valid_loss:0.440879 each epoch time:11.62513
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002108  valid_dq/boxsize 0.002090  train_dp 0.421689  valid_dp 0.418532 reg_loss 17.905440
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:17:00
run time  0:00:58.094732
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_11/backward_11_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2188377
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:17:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe47c1d4a90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 750, '_step_count': 751, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.368594 valid_loss:0.375528 each epoch time:11.40542
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001485  valid_dq/boxsize 0.001514  train_dp 0.349810  valid_dp 0.356379 reg_loss 15.035729
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:17:58
run time  0:00:56.876901
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_11/backward_11_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2197395
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:17:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa4c0334e50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 755, '_step_count': 756, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.516441 valid_loss:0.513932 each epoch time:12.22924
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002930  valid_dq/boxsize 0.002921  train_dp 0.490234  valid_dp 0.487809 reg_loss 30.687412
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:18:58
run time  0:00:59.837290
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_11/backward_11_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2206411
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:19:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f104f56a190>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 760, '_step_count': 761, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.368433 valid_loss:0.375379 each epoch time:11.77349
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001484  valid_dq/boxsize 0.001513  train_dp 0.349658  valid_dp 0.356238 reg_loss 15.088468
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:20:00
run time  0:00:58.782285
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_11/backward_11_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2215427
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:20:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7388b78510>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 765, '_step_count': 766, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.443930 valid_loss:0.440560 each epoch time:11.53637
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002107  valid_dq/boxsize 0.002089  train_dp 0.421411  valid_dp 0.418227 reg_loss 18.451991
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:20:59
run time  0:00:58.308115
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_11/backward_11_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2224442
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:21:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc47bc63310>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 770, '_step_count': 771, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.368263 valid_loss:0.375217 each epoch time:11.33436
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001483  valid_dq/boxsize 0.001512  train_dp 0.349500  valid_dp 0.356088 reg_loss 15.157803
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:21:57
run time  0:00:56.622652
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_11/backward_11_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2233457
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:21:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff113beab50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 775, '_step_count': 776, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.443808 valid_loss:0.440434 each epoch time:11.76861
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002106  valid_dq/boxsize 0.002088  train_dp 0.421296  valid_dp 0.418109 reg_loss 18.478883
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:22:56
run time  0:00:58.521577
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_12/forward_12_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2242472
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:22:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f38683f9f10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 780, '_step_count': 781, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.368114 valid_loss:0.375074 each epoch time:11.91787
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001483  valid_dq/boxsize 0.001512  train_dp 0.349361  valid_dp 0.355955 reg_loss 15.169671
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:23:57
run time  0:00:59.666165
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_12/forward_12_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2251487
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:23:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7e7667bbd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 785, '_step_count': 786, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.516171 valid_loss:0.513657 each epoch time:11.93152
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002929  valid_dq/boxsize 0.002919  train_dp 0.489975  valid_dp 0.487544 reg_loss 30.836884
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:24:59
run time  0:00:59.376863
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_12/forward_12_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2260502
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:24:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f020f60d290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 790, '_step_count': 791, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.368001 valid_loss:0.374957 each epoch time:11.68233
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001482  valid_dq/boxsize 0.001511  train_dp 0.349253  valid_dp 0.355843 reg_loss 15.104664
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:25:57
run time  0:00:58.000262
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_12/forward_12_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2269518
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:26:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3a77fc0cd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 795, '_step_count': 796, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.443583 valid_loss:0.440209 each epoch time:11.83363
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002105  valid_dq/boxsize 0.002087  train_dp 0.421082  valid_dp 0.417893 reg_loss 18.433970
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:26:59
run time  0:00:59.383275
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_12/forward_12_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2278535
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:27:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f25c2fcc210>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 800, '_step_count': 801, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.581641 valid_loss:0.580376 each epoch time:11.93047
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003832  valid_dq/boxsize 0.003828  train_dp 0.552138  valid_dp 0.550908 reg_loss 36.992810
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:28:00
run time  0:00:59.241651
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_12/forward_12_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2287550
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:28:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb98daf2e50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 805, '_step_count': 806, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.666713 valid_loss:0.665805 each epoch time:11.15643
optimizer lr 0.00098  boxsize 6.48886  train_dq/boxsize 0.005234  valid_dq/boxsize 0.005237  train_dp 0.632748  valid_dp 0.631825 reg_loss 37.700702
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:28:58
run time  0:00:55.372213
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_12/forward_12_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2296565
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:28:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f42a15ea210>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 810, '_step_count': 811, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.581213 valid_loss:0.579953 each epoch time:11.68806
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003831  valid_dq/boxsize 0.003826  train_dp 0.551724  valid_dp 0.550498 reg_loss 35.092478
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:29:57
run time  0:00:58.363599
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_12/backward_12_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2305580
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:29:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f60d73695d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 815, '_step_count': 816, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.443389 valid_loss:0.440078 each epoch time:11.71718
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002105  valid_dq/boxsize 0.002088  train_dp 0.420881  valid_dp 0.417754 reg_loss 17.586564
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:30:57
run time  0:00:58.699205
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_12/backward_12_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2314599
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:30:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f307aa710d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 820, '_step_count': 821, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.367839 valid_loss:0.374758 each epoch time:11.65630
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001483  valid_dq/boxsize 0.001512  train_dp 0.349082  valid_dp 0.355635 reg_loss 14.739023
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:31:56
run time  0:00:58.299339
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_12/backward_12_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2323615
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:31:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faf5d93a950>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 825, '_step_count': 826, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.515565 valid_loss:0.513065 each epoch time:11.81710
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002928  valid_dq/boxsize 0.002919  train_dp 0.489374  valid_dp 0.486958 reg_loss 30.339090
memory usage : 3.1  at e= 5
end date/time : 20211025, 17:32:57
run time  0:01:00.003308
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_12/backward_12_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2332630
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:32:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc4c91e8f10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 830, '_step_count': 831, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.367686 valid_loss:0.374618 each epoch time:11.59027
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001482  valid_dq/boxsize 0.001511  train_dp 0.348936  valid_dp 0.355501 reg_loss 14.798515
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:33:56
run time  0:00:57.229972
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_12/backward_12_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2341645
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:33:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffa26484f50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 835, '_step_count': 836, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.443110 valid_loss:0.439774 each epoch time:11.72985
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002105  valid_dq/boxsize 0.002087  train_dp 0.420610  valid_dp 0.417460 reg_loss 18.124830
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:34:55
run time  0:00:58.732709
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_12/backward_12_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2350660
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:34:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6326ceddd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 840, '_step_count': 841, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.367524 valid_loss:0.374462 each epoch time:11.58629
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001481  valid_dq/boxsize 0.001510  train_dp 0.348785  valid_dp 0.355356 reg_loss 14.865934
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:35:54
run time  0:00:58.295675
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_12/backward_12_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2359675
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:35:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa88178b390>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 845, '_step_count': 846, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.442992 valid_loss:0.439654 each epoch time:11.89905
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002104  valid_dq/boxsize 0.002087  train_dp 0.420500  valid_dp 0.417347 reg_loss 18.148541
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:36:55
run time  0:00:59.406404
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_13/forward_13_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2368690
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:36:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa933eab1d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 850, '_step_count': 851, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.367383 valid_loss:0.374323 each epoch time:11.69218
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001481  valid_dq/boxsize 0.001510  train_dp 0.348652  valid_dp 0.355225 reg_loss 14.884908
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:37:55
run time  0:00:58.197317
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_13/forward_13_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2377706
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:37:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f13568a4690>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 855, '_step_count': 856, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.515303 valid_loss:0.512796 each epoch time:12.11744
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002927  valid_dq/boxsize 0.002918  train_dp 0.489120  valid_dp 0.486698 reg_loss 30.497229
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:38:55
run time  0:00:59.742510
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_13/forward_13_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2386721
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:38:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe62ae1b110>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 860, '_step_count': 861, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.367274 valid_loss:0.374216 each epoch time:11.82984
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001480  valid_dq/boxsize 0.001509  train_dp 0.348548  valid_dp 0.355123 reg_loss 14.826450
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:39:54
run time  0:00:58.343012
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_13/forward_13_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2395737
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:39:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3ca0bfa990>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 865, '_step_count': 866, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.442777 valid_loss:0.439434 each epoch time:11.67572
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002103  valid_dq/boxsize 0.002086  train_dp 0.420293  valid_dp 0.417136 reg_loss 18.116621
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:40:54
run time  0:00:58.515046
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_13/forward_13_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2404752
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:40:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f92996d8a10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 870, '_step_count': 871, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.580693 valid_loss:0.579436 each epoch time:12.10718
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003831  valid_dq/boxsize 0.003827  train_dp 0.551201  valid_dp 0.549978 reg_loss 36.804716
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:41:54
run time  0:00:59.665514
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_13/forward_13_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2413767
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:41:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f66b30bf490>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 875, '_step_count': 876, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.665646 valid_loss:0.664740 each epoch time:11.69324
optimizer lr 0.00098  boxsize 6.48886  train_dq/boxsize 0.005234  valid_dq/boxsize 0.005236  train_dp 0.631683  valid_dp 0.630763 reg_loss 37.622426
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:42:53
run time  0:00:58.161546
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_13/forward_13_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2422782
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:42:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9e3b46ff90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 880, '_step_count': 881, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.580271 valid_loss:0.579018 each epoch time:11.60242
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003829  valid_dq/boxsize 0.003825  train_dp 0.550792  valid_dp 0.549572 reg_loss 34.937402
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:43:53
run time  0:00:58.663968
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_13/backward_13_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2431797
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:43:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0a607f8dd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 885, '_step_count': 886, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.442588 valid_loss:0.439309 each epoch time:12.00056
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002104  valid_dq/boxsize 0.002087  train_dp 0.420097  valid_dp 0.417001 reg_loss 17.296268
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:44:55
run time  0:00:59.348192
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_13/backward_13_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2440814
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:44:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6af52f07d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 890, '_step_count': 891, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.367121 valid_loss:0.374031 each epoch time:11.80962
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001481  valid_dq/boxsize 0.001510  train_dp 0.348385  valid_dp 0.354927 reg_loss 14.473169
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:45:55
run time  0:00:59.332452
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_13/backward_13_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2449829
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:45:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0eb9ea6810>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 895, '_step_count': 896, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.514710 valid_loss:0.512217 each epoch time:11.69837
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002927  valid_dq/boxsize 0.002917  train_dp 0.488530  valid_dp 0.486123 reg_loss 30.005081
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:46:56
run time  0:00:59.671248
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_13/backward_13_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2458845
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:46:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff6fa58bcd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 900, '_step_count': 901, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.366975 valid_loss:0.373894 each epoch time:11.70562
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001481  valid_dq/boxsize 0.001510  train_dp 0.348244  valid_dp 0.354796 reg_loss 14.532094
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:47:55
run time  0:00:58.901231
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_13/backward_13_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2467860
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:47:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff204865590>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 905, '_step_count': 906, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.442317 valid_loss:0.439016 each epoch time:11.60595
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002103  valid_dq/boxsize 0.002086  train_dp 0.419834  valid_dp 0.416718 reg_loss 17.830492
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:48:55
run time  0:00:58.298729
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_13/backward_13_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2476877
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:48:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd0b188ca50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 910, '_step_count': 911, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.366819 valid_loss:0.373746 each epoch time:11.61210
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001480  valid_dq/boxsize 0.001509  train_dp 0.348098  valid_dp 0.354657 reg_loss 14.600045
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:49:55
run time  0:00:58.997377
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_13/backward_13_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2485892
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:49:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1157cc5fd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 915, '_step_count': 916, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.442203 valid_loss:0.438897 each epoch time:11.49872
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002103  valid_dq/boxsize 0.002085  train_dp 0.419726  valid_dp 0.416604 reg_loss 17.857195
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:50:55
run time  0:00:58.550890
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_14/forward_14_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2494907
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:50:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1b540faad0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 920, '_step_count': 921, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.366682 valid_loss:0.373614 each epoch time:11.75912
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001509  train_dp 0.347969  valid_dp 0.354533 reg_loss 14.617389
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:51:56
run time  0:00:59.262813
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_14/forward_14_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2503923
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:51:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f685a940e90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 925, '_step_count': 926, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.514453 valid_loss:0.511956 each epoch time:11.53988
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002926  valid_dq/boxsize 0.002917  train_dp 0.488281  valid_dp 0.485870 reg_loss 30.182907
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:52:57
run time  0:00:58.260138
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_14/forward_14_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2512938
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:52:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fed53feee10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 930, '_step_count': 931, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.366578 valid_loss:0.373508 each epoch time:11.63567
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001508  train_dp 0.347868  valid_dp 0.354431 reg_loss 14.564460
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:53:57
run time  0:00:58.760867
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_14/forward_14_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2521953
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:53:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f80d3ad1290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 935, '_step_count': 936, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.441994 valid_loss:0.438685 each epoch time:11.76681
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002102  valid_dq/boxsize 0.002085  train_dp 0.419524  valid_dp 0.416400 reg_loss 17.834623
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:54:57
run time  0:00:59.066743
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_14/forward_14_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2530968
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:54:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3afb207fd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 940, '_step_count': 941, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.579757 valid_loss:0.578512 each epoch time:11.50147
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003830  valid_dq/boxsize 0.003826  train_dp 0.550272  valid_dp 0.549061 reg_loss 36.644331
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:55:56
run time  0:00:57.943850
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_14/forward_14_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2539983
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:55:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fea1f63edd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 945, '_step_count': 946, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.664586 valid_loss:0.663683 each epoch time:11.65691
optimizer lr 0.00098  boxsize 6.48886  train_dq/boxsize 0.005234  valid_dq/boxsize 0.005236  train_dp 0.630623  valid_dp 0.629705 reg_loss 37.575848
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:56:56
run time  0:00:58.596895
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_14/forward_14_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2548998
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:56:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff34d608c50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 950, '_step_count': 951, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.579340 valid_loss:0.578096 each epoch time:11.59238
optimizer lr 0.00098  boxsize 7.69800  train_dq/boxsize 0.003829  valid_dq/boxsize 0.003824  train_dp 0.549868  valid_dp 0.548657 reg_loss 34.822433
memory usage : 3.2  at e= 5
end date/time : 20211025, 17:57:59
run time  0:00:59.552067
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_14/backward_14_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2558021
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:58:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5227236390>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 955, '_step_count': 956, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.441807 valid_loss:0.438555 each epoch time:12.24607
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002103  valid_dq/boxsize 0.002086  train_dp 0.419330  valid_dp 0.416259 reg_loss 17.036828
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:59:00
run time  0:00:59.911016
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_14/backward_14_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2567061
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:59:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fef32026310>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 960, '_step_count': 961, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.366431 valid_loss:0.373324 each epoch time:11.86144
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001480  valid_dq/boxsize 0.001509  train_dp 0.347711  valid_dp 0.354236 reg_loss 14.226668
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:00:01
run time  0:00:58.678906
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_14/backward_14_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2576078
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:00:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4049aa89d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 965, '_step_count': 966, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.513868 valid_loss:0.511386 each epoch time:11.86308
optimizer lr 0.00098  boxsize 8.94427  train_dq/boxsize 0.002926  valid_dq/boxsize 0.002916  train_dp 0.487697  valid_dp 0.485301 reg_loss 29.695881
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:01:03
run time  0:00:59.035758
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_14/backward_14_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2585093
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:01:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9d5f3bed50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 970, '_step_count': 971, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.366290 valid_loss:0.373190 each epoch time:11.37036
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001480  valid_dq/boxsize 0.001509  train_dp 0.347575  valid_dp 0.354107 reg_loss 14.284167
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:02:02
run time  0:00:57.473972
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_14/backward_14_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2594107
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:02:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fead6373c10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 975, '_step_count': 976, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.441544 valid_loss:0.438271 each epoch time:11.65257
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002102  valid_dq/boxsize 0.002085  train_dp 0.419074  valid_dp 0.415983 reg_loss 17.552154
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:03:01
run time  0:00:58.159713
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_14/backward_14_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2603123
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:03:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f78d526ef50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 980, '_step_count': 981, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.366139 valid_loss:0.373048 each epoch time:11.89666
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001508  train_dp 0.347432  valid_dp 0.353974 reg_loss 14.350297
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:04:00
run time  0:00:58.821453
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_14/backward_14_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2612139
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:04:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc66aa55790>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 985, '_step_count': 986, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.441434 valid_loss:0.438158 each epoch time:11.83536
optimizer lr 0.00098  boxsize 10.69045  train_dq/boxsize 0.002101  valid_dq/boxsize 0.002084  train_dp 0.418968  valid_dp 0.415876 reg_loss 17.588107
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:05:00
run time  0:00:58.627604
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_15/forward_15_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2621154
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:05:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f47328332d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 990, '_step_count': 991, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.366007 valid_loss:0.372921 each epoch time:11.65737
optimizer lr 0.00098  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.347307  valid_dp 0.353853 reg_loss 14.370337
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:06:01
run time  0:00:59.224963
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_15/forward_15_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2630169
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:06:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fada5f78e50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00098, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 995, '_step_count': 996, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.00098]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.513614 valid_loss:0.511125 each epoch time:11.91075
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002925  valid_dq/boxsize 0.002916  train_dp 0.487449  valid_dp 0.485047 reg_loss 29.883248
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:07:04
run time  0:00:59.641670
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_15/forward_15_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2639191
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:07:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f19340153d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1000, '_step_count': 1001, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.365907 valid_loss:0.372819 each epoch time:11.49383
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.347211  valid_dp 0.353755 reg_loss 14.320490
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:08:04
run time  0:00:58.022887
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_15/forward_15_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2648205
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:08:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f87dce57e90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1005, '_step_count': 1006, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.441231 valid_loss:0.437948 each epoch time:11.88761
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002101  valid_dq/boxsize 0.002084  train_dp 0.418772  valid_dp 0.415672 reg_loss 17.579480
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:09:04
run time  0:00:59.295509
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_15/forward_15_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2657220
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:09:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd71c97af50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1010, '_step_count': 1011, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.578834 valid_loss:0.577596 each epoch time:11.44069
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003830  valid_dq/boxsize 0.003825  train_dp 0.549352  valid_dp 0.548149 reg_loss 36.535578
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:10:03
run time  0:00:57.754166
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_15/forward_15_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2666235
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:10:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcb19549dd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1015, '_step_count': 1016, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.663546 valid_loss:0.662652 each epoch time:11.49650
optimizer lr 0.00096  boxsize 6.48886  train_dq/boxsize 0.005235  valid_dq/boxsize 0.005237  train_dp 0.629580  valid_dp 0.628669 reg_loss 37.576508
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:11:02
run time  0:00:57.875354
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_15/forward_15_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2675250
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:11:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f22ff7fdc10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1020, '_step_count': 1021, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.578426 valid_loss:0.577197 each epoch time:11.87578
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003828  valid_dq/boxsize 0.003824  train_dp 0.548958  valid_dp 0.547762 reg_loss 34.761296
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:12:03
run time  0:00:59.139133
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_15/backward_15_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2684265
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:12:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa72c7f5310>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1025, '_step_count': 1026, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.441050 valid_loss:0.437824 each epoch time:11.87405
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002102  valid_dq/boxsize 0.002085  train_dp 0.418584  valid_dp 0.415538 reg_loss 16.803210
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:13:05
run time  0:00:59.147200
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_15/backward_15_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2693281
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:13:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f740614f310>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1030, '_step_count': 1031, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.365770 valid_loss:0.372644 each epoch time:12.02172
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001508  train_dp 0.347062  valid_dp 0.353569 reg_loss 13.997728
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:14:05
run time  0:00:59.783439
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_15/backward_15_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2702296
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:14:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9f17d21350>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1035, '_step_count': 1036, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.513048 valid_loss:0.510570 each epoch time:11.86716
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002925  valid_dq/boxsize 0.002916  train_dp 0.486882  valid_dp 0.484493 reg_loss 29.404719
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:15:08
run time  0:00:59.681905
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_15/backward_15_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2711320
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:15:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9d252d3790>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1040, '_step_count': 1041, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.365635 valid_loss:0.372521 each epoch time:12.00604
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001508  train_dp 0.346931  valid_dp 0.353449 reg_loss 14.055222
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:16:10
run time  0:00:59.058368
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_15/backward_15_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2720334
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:16:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2fcc21ec90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1045, '_step_count': 1046, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.440799 valid_loss:0.437552 each epoch time:11.69571
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002101  valid_dq/boxsize 0.002084  train_dp 0.418337  valid_dp 0.415273 reg_loss 17.319776
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:17:09
run time  0:00:58.138482
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_15/backward_15_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2729352
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:17:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2a5e707e10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1050, '_step_count': 1051, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.365491 valid_loss:0.372385 each epoch time:11.68665
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.346795  valid_dp 0.353321 reg_loss 14.121497
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:18:10
run time  0:00:59.150413
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_15/backward_15_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2738367
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:18:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcd5bfb2d90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1055, '_step_count': 1056, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.440692 valid_loss:0.437442 each epoch time:11.76832
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002101  valid_dq/boxsize 0.002084  train_dp 0.418235  valid_dp 0.415168 reg_loss 17.355729
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:19:10
run time  0:00:59.134604
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_16/forward_16_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2747382
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:19:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f935edcb790>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1060, '_step_count': 1061, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.365365 valid_loss:0.372264 each epoch time:11.60101
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.346675  valid_dp 0.353206 reg_loss 14.148430
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:20:09
run time  0:00:58.420311
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_16/forward_16_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2756397
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:20:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fda3b7d8dd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1065, '_step_count': 1066, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.512801 valid_loss:0.510319 each epoch time:11.66447
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002925  valid_dq/boxsize 0.002915  train_dp 0.486640  valid_dp 0.484247 reg_loss 29.612182
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:21:09
run time  0:00:58.384454
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_16/forward_16_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2765413
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:21:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f544b828d90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1070, '_step_count': 1071, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.365267 valid_loss:0.372166 each epoch time:11.53120
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.346580  valid_dp 0.353111 reg_loss 14.107270
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:22:08
run time  0:00:57.786419
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_16/forward_16_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2774428
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:22:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f87b4c1cd90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1075, '_step_count': 1076, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.440495 valid_loss:0.437238 each epoch time:11.70981
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.418044  valid_dp 0.414970 reg_loss 17.356684
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:23:07
run time  0:00:58.513600
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_16/forward_16_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2783443
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:23:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd18360b110>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1080, '_step_count': 1081, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.577927 valid_loss:0.576702 each epoch time:12.01933
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003830  valid_dq/boxsize 0.003825  train_dp 0.548447  valid_dp 0.547256 reg_loss 36.453252
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:24:07
run time  0:00:59.412923
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_16/forward_16_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2792458
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:24:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5a0b19e2d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1085, '_step_count': 1086, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.662513 valid_loss:0.661623 each epoch time:11.64236
optimizer lr 0.00096  boxsize 6.48886  train_dq/boxsize 0.005235  valid_dq/boxsize 0.005238  train_dp 0.628543  valid_dp 0.627636 reg_loss 37.534043
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:25:07
run time  0:00:58.173729
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_16/forward_16_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2801473
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:25:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa96f14ef90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1090, '_step_count': 1091, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.577522 valid_loss:0.576307 each epoch time:11.83648
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003828  valid_dq/boxsize 0.003823  train_dp 0.548057  valid_dp 0.546876 reg_loss 34.672023
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:26:08
run time  0:00:59.723897
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_16/backward_16_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2810488
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:26:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb84722b890>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1095, '_step_count': 1096, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.440315 valid_loss:0.437114 each epoch time:11.78076
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002101  valid_dq/boxsize 0.002084  train_dp 0.417855  valid_dp 0.414835 reg_loss 16.592505
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:27:07
run time  0:00:58.853447
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_16/backward_16_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2819508
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:27:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fec66dd4f90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1100, '_step_count': 1101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.365134 valid_loss:0.371995 each epoch time:12.02229
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.346434  valid_dp 0.352929 reg_loss 13.790348
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:28:08
run time  0:00:59.701342
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_16/backward_16_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2828523
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:28:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f60725c3310>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1105, '_step_count': 1106, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.512238 valid_loss:0.509768 each epoch time:11.81391
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002925  valid_dq/boxsize 0.002915  train_dp 0.486076  valid_dp 0.483696 reg_loss 29.132373
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:29:08
run time  0:00:59.566475
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_16/backward_16_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2837538
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:29:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd9d3344290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1110, '_step_count': 1111, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.365001 valid_loss:0.371875 each epoch time:11.97175
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.346305  valid_dp 0.352812 reg_loss 13.851755
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:30:09
run time  0:00:59.439587
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_16/backward_16_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2846555
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:30:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe9335d1cd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1115, '_step_count': 1116, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.440067 valid_loss:0.436845 each epoch time:11.86802
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002084  train_dp 0.417612  valid_dp 0.414572 reg_loss 17.097593
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:31:09
run time  0:00:59.410380
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_16/backward_16_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2855571
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:31:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb35b67df50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1120, '_step_count': 1121, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.364860 valid_loss:0.371743 each epoch time:11.97072
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001507  train_dp 0.346171  valid_dp 0.352686 reg_loss 13.922951
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:32:10
run time  0:00:59.470997
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_16/backward_16_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2864586
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:32:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f479361f250>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1125, '_step_count': 1126, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.439962 valid_loss:0.436737 each epoch time:11.61347
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.417511  valid_dp 0.414468 reg_loss 17.141848
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:33:10
run time  0:00:58.970134
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_17/forward_17_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2873601
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:33:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f01954ff710>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1130, '_step_count': 1131, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.364736 valid_loss:0.371627 each epoch time:11.61011
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.346053  valid_dp 0.352576 reg_loss 13.949344
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:34:10
run time  0:00:58.167501
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_17/forward_17_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2882619
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:34:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7e053d1d50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1135, '_step_count': 1136, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.511993 valid_loss:0.509517 each epoch time:11.79680
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002925  valid_dq/boxsize 0.002914  train_dp 0.485834  valid_dp 0.483449 reg_loss 29.345991
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:35:09
run time  0:00:58.824515
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_17/forward_17_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2891634
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:35:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1bbfd0dd10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1140, '_step_count': 1141, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.364641 valid_loss:0.371531 each epoch time:11.55452
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.345960  valid_dp 0.352483 reg_loss 13.912853
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:36:09
run time  0:00:58.262754
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_17/forward_17_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2900649
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:36:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4bce0d1d50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1145, '_step_count': 1146, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.439767 valid_loss:0.436539 each epoch time:11.73135
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.417322  valid_dp 0.414275 reg_loss 17.154912
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:37:11
run time  0:00:59.535074
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_17/forward_17_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2909672
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:37:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2260eadf50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1150, '_step_count': 1151, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.577023 valid_loss:0.575809 each epoch time:11.54374
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003830  valid_dq/boxsize 0.003825  train_dp 0.547543  valid_dp 0.546364 reg_loss 36.415984
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:38:10
run time  0:00:57.974577
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_17/forward_17_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2918688
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:38:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa555518090>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1155, '_step_count': 1156, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.661478 valid_loss:0.660593 each epoch time:11.93165
optimizer lr 0.00096  boxsize 6.48886  train_dq/boxsize 0.005236  valid_dq/boxsize 0.005239  train_dp 0.627501  valid_dp 0.626597 reg_loss 37.522029
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:39:10
run time  0:00:59.092483
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_17/forward_17_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2927703
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:39:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f39cf98a090>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1160, '_step_count': 1161, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.576619 valid_loss:0.575420 each epoch time:12.02704
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003828  valid_dq/boxsize 0.003823  train_dp 0.547155  valid_dp 0.545989 reg_loss 34.634295
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:40:10
run time  0:00:59.391760
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_17/backward_17_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2936718
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:40:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f85029b5e10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1165, '_step_count': 1166, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.439588 valid_loss:0.436410 each epoch time:11.64960
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002084  train_dp 0.417133  valid_dp 0.414134 reg_loss 16.403326
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:41:10
run time  0:00:58.509041
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_17/backward_17_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2945733
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:41:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faa61d00910>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1170, '_step_count': 1171, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.364510 valid_loss:0.371359 each epoch time:12.12822
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.345816  valid_dp 0.352299 reg_loss 13.604491
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:42:11
run time  0:01:00.078207
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_17/backward_17_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2954749
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:42:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe7680d9610>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1175, '_step_count': 1176, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.511433 valid_loss:0.508972 each epoch time:11.80644
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002925  valid_dq/boxsize 0.002915  train_dp 0.485272  valid_dp 0.482903 reg_loss 28.875651
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:43:11
run time  0:00:58.972997
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_17/backward_17_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2963766
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:43:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc4b8332ad0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1180, '_step_count': 1181, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.364380 valid_loss:0.371242 each epoch time:11.96141
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.345689  valid_dp 0.352183 reg_loss 13.665653
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:44:14
run time  0:00:59.809726
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_17/backward_17_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2972786
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:44:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f87b7ba9ad0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1185, '_step_count': 1186, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.439344 valid_loss:0.436147 each epoch time:11.95171
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.416893  valid_dp 0.413877 reg_loss 16.906286
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:45:14
run time  0:00:59.262449
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_17/backward_17_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2981800
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:45:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fac1ee51f90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1190, '_step_count': 1191, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.364240 valid_loss:0.371111 each epoch time:11.98576
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.345557  valid_dp 0.352060 reg_loss 13.736481
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:46:14
run time  0:00:59.674598
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_17/backward_17_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2990815
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:46:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1efe35bf50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1195, '_step_count': 1196, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.439239 valid_loss:0.436041 each epoch time:11.78506
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.416792  valid_dp 0.413775 reg_loss 16.955032
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:47:14
run time  0:00:59.090169
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_18/forward_18_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  2999830
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:47:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff618aa6d90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1200, '_step_count': 1201, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.364118 valid_loss:0.370998 each epoch time:11.70468
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.345440  valid_dp 0.351952 reg_loss 13.766466
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:48:13
run time  0:00:58.153686
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_18/forward_18_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3008846
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:48:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb4c0244190>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1205, '_step_count': 1206, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.511189 valid_loss:0.508723 each epoch time:11.74257
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002925  valid_dq/boxsize 0.002914  train_dp 0.485031  valid_dp 0.482656 reg_loss 29.111917
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:49:13
run time  0:00:58.343903
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_18/forward_18_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3017862
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:49:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8c0ea49e50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1210, '_step_count': 1211, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.364025 valid_loss:0.370905 each epoch time:11.57704
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001476  valid_dq/boxsize 0.001506  train_dp 0.345349  valid_dp 0.351861 reg_loss 13.733577
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:50:12
run time  0:00:58.595697
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_18/forward_18_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3026877
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:50:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faeeb492090>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1215, '_step_count': 1216, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.439047 valid_loss:0.435847 each epoch time:11.91865
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002099  valid_dq/boxsize 0.002082  train_dp 0.416604  valid_dp 0.413585 reg_loss 16.975895
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:51:13
run time  0:00:59.432846
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_18/forward_18_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3035892
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:51:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7deed79d90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1220, '_step_count': 1221, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.576121 valid_loss:0.574922 each epoch time:11.71982
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003830  valid_dq/boxsize 0.003825  train_dp 0.546638  valid_dp 0.545476 reg_loss 36.370704
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:52:11
run time  0:00:57.428261
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_18/forward_18_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3044907
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:52:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7c522a0150>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1225, '_step_count': 1226, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.660446 valid_loss:0.659562 each epoch time:11.59377
optimizer lr 0.00096  boxsize 6.48886  train_dq/boxsize 0.005237  valid_dq/boxsize 0.005240  train_dp 0.626461  valid_dp 0.625557 reg_loss 37.523745
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:53:10
run time  0:00:58.063058
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_18/forward_18_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3053922
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:53:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f83db87fed0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1230, '_step_count': 1231, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.575719 valid_loss:0.574532 each epoch time:11.95561
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003828  valid_dq/boxsize 0.003823  train_dp 0.546253  valid_dp 0.545100 reg_loss 34.602672
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:54:10
run time  0:00:59.385255
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_18/backward_18_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3062937
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:54:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f025add4990>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1235, '_step_count': 1236, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.438869 valid_loss:0.435708 each epoch time:11.60208
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002084  train_dp 0.416415  valid_dp 0.413433 reg_loss 16.235408
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:55:10
run time  0:00:58.532745
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_18/backward_18_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3071953
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:55:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0a957b8090>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1240, '_step_count': 1241, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.363897 valid_loss:0.370733 each epoch time:11.95279
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.345206  valid_dp 0.351675 reg_loss 13.434665
memory usage : 3.1  at e= 5
end date/time : 20211025, 18:56:10
run time  0:00:59.582152
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_18/backward_18_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3080968
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:56:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f307c51bb90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1245, '_step_count': 1246, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.510631 valid_loss:0.508181 each epoch time:11.86136
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002925  valid_dq/boxsize 0.002915  train_dp 0.484470  valid_dp 0.482112 reg_loss 28.636268
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:57:10
run time  0:00:59.532975
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_18/backward_18_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3089989
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:57:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f05e553ec10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1250, '_step_count': 1251, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.363769 valid_loss:0.370617 each epoch time:11.81347
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.345081  valid_dp 0.351562 reg_loss 13.491749
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:58:11
run time  0:00:58.927305
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_18/backward_18_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3099004
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:58:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdad577be50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1255, '_step_count': 1256, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.438627 valid_loss:0.435453 each epoch time:11.93851
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.416178  valid_dp 0.413185 reg_loss 16.730167
memory usage : 3.2  at e= 5
end date/time : 20211025, 18:59:14
run time  0:00:59.157807
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_18/backward_18_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3108021
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:59:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f28e62b0050>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1260, '_step_count': 1261, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.363632 valid_loss:0.370493 each epoch time:12.07264
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.344951  valid_dp 0.351445 reg_loss 13.560004
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:00:15
run time  0:00:59.031325
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_18/backward_18_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3117037
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:00:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc5a4782310>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1265, '_step_count': 1266, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.438524 valid_loss:0.435344 each epoch time:12.01802
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.416079  valid_dp 0.413080 reg_loss 16.777689
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:01:17
run time  0:00:59.503203
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_19/forward_19_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3126053
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:01:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbcf0decd10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1270, '_step_count': 1271, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.363511 valid_loss:0.370381 each epoch time:11.61737
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001476  valid_dq/boxsize 0.001505  train_dp 0.344836  valid_dp 0.351339 reg_loss 13.591030
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:02:17
run time  0:00:58.602054
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_19/forward_19_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3135068
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:02:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efce6ad8a10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1275, '_step_count': 1276, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.510388 valid_loss:0.507932 each epoch time:11.57670
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002925  valid_dq/boxsize 0.002914  train_dp 0.484229  valid_dp 0.481865 reg_loss 28.880083
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:03:16
run time  0:00:57.719965
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_19/forward_19_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3144083
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:03:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcaf399bed0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1280, '_step_count': 1281, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.363419 valid_loss:0.370290 each epoch time:11.65409
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001476  valid_dq/boxsize 0.001505  train_dp 0.344745  valid_dp 0.351248 reg_loss 13.564358
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:04:15
run time  0:00:58.379749
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_19/forward_19_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3153098
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:04:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6e96057ad0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1285, '_step_count': 1286, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.438333 valid_loss:0.435151 each epoch time:11.88619
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002099  valid_dq/boxsize 0.002082  train_dp 0.415892  valid_dp 0.412891 reg_loss 16.805319
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:05:15
run time  0:00:59.307746
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_19/forward_19_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3162113
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:05:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f88767c6550>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1290, '_step_count': 1291, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.575221 valid_loss:0.574035 each epoch time:11.58375
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003830  valid_dq/boxsize 0.003826  train_dp 0.545735  valid_dp 0.544586 reg_loss 36.337744
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:06:17
run time  0:00:58.440945
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_19/forward_19_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3171131
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:06:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd9670c8e10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1295, '_step_count': 1296, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.659411 valid_loss:0.658529 each epoch time:11.59088
optimizer lr 0.00096  boxsize 6.48886  train_dq/boxsize 0.005239  valid_dq/boxsize 0.005242  train_dp 0.625415  valid_dp 0.624512 reg_loss 37.514041
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:07:16
run time  0:00:58.221543
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_19/forward_19_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3180147
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:07:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f330f152310>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1300, '_step_count': 1301, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.574819 valid_loss:0.573642 each epoch time:11.43022
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003828  valid_dq/boxsize 0.003824  train_dp 0.545349  valid_dp 0.544209 reg_loss 34.563325
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:08:15
run time  0:00:57.179797
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_19/backward_19_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3189162
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:08:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f95dc0a75d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1305, '_step_count': 1306, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.438156 valid_loss:0.435018 each epoch time:11.71282
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002084  train_dp 0.415703  valid_dp 0.412743 reg_loss 16.070659
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:09:14
run time  0:00:58.115462
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_19/backward_19_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3198177
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:09:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7a6998af50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1310, '_step_count': 1311, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.363294 valid_loss:0.370117 each epoch time:11.41901
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001506  train_dp 0.344604  valid_dp 0.351062 reg_loss 13.266909
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:10:13
run time  0:00:58.375870
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_19/backward_19_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3207192
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:10:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f710c016290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1315, '_step_count': 1316, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.509833 valid_loss:0.507395 each epoch time:11.86133
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002925  valid_dq/boxsize 0.002915  train_dp 0.483670  valid_dp 0.481326 reg_loss 28.405106
memory usage : 3.1  at e= 5
end date/time : 20211025, 19:11:13
run time  0:00:59.777738
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_19/backward_19_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3216207
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:11:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fab35cb0c50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1320, '_step_count': 1321, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.363167 valid_loss:0.370002 each epoch time:11.66196
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.344480  valid_dp 0.350950 reg_loss 13.327666
memory usage : 3.1  at e= 5
end date/time : 20211025, 19:12:13
run time  0:00:59.157227
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_19/backward_19_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3225228
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:12:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdca5430210>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1325, '_step_count': 1326, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.437916 valid_loss:0.434760 each epoch time:11.47999
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.415467  valid_dp 0.412490 reg_loss 16.563345
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:13:12
run time  0:00:57.810077
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_19/backward_19_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3234244
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:13:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f90d4d6df50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1330, '_step_count': 1331, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.363030 valid_loss:0.369879 each epoch time:12.14871
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.344351  valid_dp 0.350833 reg_loss 13.401322
memory usage : 3.1  at e= 5
end date/time : 20211025, 19:14:12
run time  0:00:59.351352
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_19/backward_19_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3243259
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:14:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6d3e1dfd90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1335, '_step_count': 1336, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.437813 valid_loss:0.434654 each epoch time:11.70226
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.415369  valid_dp 0.412389 reg_loss 16.614267
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:15:12
run time  0:00:58.401376
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_20/forward_20_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3252274
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:15:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f04432739d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1340, '_step_count': 1341, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.362911 valid_loss:0.369769 each epoch time:11.70170
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001476  valid_dq/boxsize 0.001505  train_dp 0.344238  valid_dp 0.350729 reg_loss 13.431644
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:16:11
run time  0:00:58.576625
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_20/forward_20_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3261289
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:16:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f57b36b8950>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1345, '_step_count': 1346, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.509591 valid_loss:0.507147 each epoch time:11.51011
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002925  valid_dq/boxsize 0.002914  train_dp 0.483429  valid_dp 0.481080 reg_loss 28.657137
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:17:10
run time  0:00:57.791871
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_20/forward_20_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3270307
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:17:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f760a641210>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1350, '_step_count': 1351, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.362820 valid_loss:0.369679 each epoch time:11.75445
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001476  valid_dq/boxsize 0.001505  train_dp 0.344148  valid_dp 0.350640 reg_loss 13.408928
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:18:08
run time  0:00:57.385426
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_20/forward_20_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3279322
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:18:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd21b802ad0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1355, '_step_count': 1356, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.437624 valid_loss:0.434460 each epoch time:11.21577
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002099  valid_dq/boxsize 0.002082  train_dp 0.415183  valid_dp 0.412198 reg_loss 16.647462
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:19:06
run time  0:00:57.032161
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_20/forward_20_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3288337
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:19:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7749beb1d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1360, '_step_count': 1361, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.574323 valid_loss:0.573149 each epoch time:12.00187
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003831  valid_dq/boxsize 0.003826  train_dp 0.544831  valid_dp 0.543695 reg_loss 36.319932
memory usage : 3.1  at e= 5
end date/time : 20211025, 19:20:06
run time  0:00:59.214545
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_20/forward_20_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3297352
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:20:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff7dc611310>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1365, '_step_count': 1366, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.658376 valid_loss:0.657497 each epoch time:11.73190
optimizer lr 0.00096  boxsize 6.48886  train_dq/boxsize 0.005241  valid_dq/boxsize 0.005244  train_dp 0.624369  valid_dp 0.623467 reg_loss 37.493210
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:21:07
run time  0:00:59.194301
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_20/forward_20_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3306367
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:21:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f745f247fd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1370, '_step_count': 1371, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.573919 valid_loss:0.572759 each epoch time:11.80093
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003829  valid_dq/boxsize 0.003824  train_dp 0.544445  valid_dp 0.543321 reg_loss 34.554217
memory usage : 3.1  at e= 5
end date/time : 20211025, 19:22:08
run time  0:00:59.091569
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_20/backward_20_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3315382
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:22:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc4f3534e90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1375, '_step_count': 1376, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.437449 valid_loss:0.434329 each epoch time:11.65305
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002084  train_dp 0.414994  valid_dp 0.412051 reg_loss 15.911990
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:23:08
run time  0:00:58.603558
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_20/backward_20_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3324423
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:23:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f88d85e6710>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1380, '_step_count': 1381, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.362698 valid_loss:0.369509 each epoch time:11.94814
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001506  train_dp 0.344009  valid_dp 0.350454 reg_loss 13.110090
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:24:08
run time  0:00:59.403969
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_20/backward_20_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3333438
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:24:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f54e49b0d90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1385, '_step_count': 1386, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.509035 valid_loss:0.506614 each epoch time:11.87253
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002926  valid_dq/boxsize 0.002915  train_dp 0.482868  valid_dp 0.480542 reg_loss 28.197565
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:25:08
run time  0:00:59.074079
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_20/backward_20_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3342453
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:25:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6166457b10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1390, '_step_count': 1391, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.362572 valid_loss:0.369396 each epoch time:12.02179
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.343885  valid_dp 0.350343 reg_loss 13.172394
memory usage : 3.1  at e= 5
end date/time : 20211025, 19:26:08
run time  0:00:59.197735
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_20/backward_20_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3351468
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:26:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f09fd457a10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1395, '_step_count': 1396, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.437211 valid_loss:0.434073 each epoch time:11.91135
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.414760  valid_dp 0.411801 reg_loss 16.409647
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:27:08
run time  0:00:59.033080
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_20/backward_20_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3360484
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:27:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f08eb0cee50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1400, '_step_count': 1401, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.362437 valid_loss:0.369271 each epoch time:11.94456
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.343757  valid_dp 0.350226 reg_loss 13.243092
memory usage : 3.1  at e= 5
end date/time : 20211025, 19:28:08
run time  0:00:59.622382
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_20/backward_20_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3369499
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:28:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f80c6a3fdd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1405, '_step_count': 1406, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.437109 valid_loss:0.433968 each epoch time:11.71813
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.414662  valid_dp 0.411700 reg_loss 16.464674
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:29:08
run time  0:00:59.273226
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_21/forward_21_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3378515
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:29:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f53465560d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1410, '_step_count': 1411, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.362318 valid_loss:0.369159 each epoch time:11.70681
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001476  valid_dq/boxsize 0.001505  train_dp 0.343644  valid_dp 0.350119 reg_loss 13.278968
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:30:07
run time  0:00:58.075701
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_21/forward_21_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3387532
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:30:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f66f301ef90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1415, '_step_count': 1416, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.508796 valid_loss:0.506365 each epoch time:11.36025
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002925  valid_dq/boxsize 0.002915  train_dp 0.482630  valid_dp 0.480294 reg_loss 28.442763
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:31:05
run time  0:00:56.396819
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_21/forward_21_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3396547
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:31:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4abb749d50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1420, '_step_count': 1421, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.362228 valid_loss:0.369071 each epoch time:11.59652
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001476  valid_dq/boxsize 0.001505  train_dp 0.343555  valid_dp 0.350033 reg_loss 13.256710
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:32:06
run time  0:00:57.992081
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_21/forward_21_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3405565
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:32:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f669cde4750>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1425, '_step_count': 1426, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.436921 valid_loss:0.433776 each epoch time:11.50706
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002099  valid_dq/boxsize 0.002083  train_dp 0.414477  valid_dp 0.411511 reg_loss 16.505538
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:33:04
run time  0:00:58.033114
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_21/forward_21_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3414581
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:33:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa27304d650>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1430, '_step_count': 1431, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.573425 valid_loss:0.572266 each epoch time:11.65071
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003832  valid_dq/boxsize 0.003827  train_dp 0.543926  valid_dp 0.542804 reg_loss 36.298717
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:34:04
run time  0:00:58.360158
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_21/forward_21_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3423596
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:34:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f52f4441c90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1435, '_step_count': 1436, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.657339 valid_loss:0.656463 each epoch time:11.52641
optimizer lr 0.00096  boxsize 6.48886  train_dq/boxsize 0.005243  valid_dq/boxsize 0.005247  train_dp 0.623317  valid_dp 0.622418 reg_loss 37.506070
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:35:02
run time  0:00:57.192203
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_21/forward_21_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3432611
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:35:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcbb3841b10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1440, '_step_count': 1441, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.573022 valid_loss:0.571872 each epoch time:11.68428
optimizer lr 0.00096  boxsize 7.69800  train_dq/boxsize 0.003830  valid_dq/boxsize 0.003825  train_dp 0.543540  valid_dp 0.542429 reg_loss 34.546465
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:36:02
run time  0:00:59.183792
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_21/backward_21_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3441626
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:36:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f228c14cd50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1445, '_step_count': 1446, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.436746 valid_loss:0.433644 each epoch time:11.76441
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002101  valid_dq/boxsize 0.002084  train_dp 0.414288  valid_dp 0.411362 reg_loss 15.765181
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:37:02
run time  0:00:58.999388
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_21/backward_21_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3450641
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:37:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd7a36177d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1450, '_step_count': 1451, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.362109 valid_loss:0.368910 each epoch time:11.92895
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.343418  valid_dp 0.349854 reg_loss 12.962318
memory usage : 3.1  at e= 5
end date/time : 20211025, 19:38:04
run time  0:00:59.305293
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_21/backward_21_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3459657
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:38:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1c56f81e50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1455, '_step_count': 1456, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.508239 valid_loss:0.505830 each epoch time:11.56679
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002926  valid_dq/boxsize 0.002915  train_dp 0.482067  valid_dp 0.479754 reg_loss 27.985729
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:39:04
run time  0:00:59.090269
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_21/backward_21_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3468672
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:39:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f78d45ac9d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1460, '_step_count': 1461, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.361984 valid_loss:0.368796 each epoch time:11.72905
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001506  train_dp 0.343295  valid_dp 0.349742 reg_loss 13.027278
memory usage : 3.1  at e= 5
end date/time : 20211025, 19:40:04
run time  0:00:59.112134
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_21/backward_21_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3477687
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:40:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6caff25c90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1465, '_step_count': 1466, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.436509 valid_loss:0.433390 each epoch time:11.83227
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002084  train_dp 0.414055  valid_dp 0.411113 reg_loss 16.267138
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:41:04
run time  0:00:58.971858
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_21/backward_21_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3486702
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:41:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efff29438d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1470, '_step_count': 1471, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.361849 valid_loss:0.368675 each epoch time:11.70712
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.343168  valid_dp 0.349627 reg_loss 13.100299
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:42:05
run time  0:00:59.205396
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_21/backward_21_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3495717
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:42:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3fbc10bb50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1475, '_step_count': 1476, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.436407 valid_loss:0.433286 each epoch time:11.64665
optimizer lr 0.00096  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.413957  valid_dp 0.411013 reg_loss 16.326899
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:43:04
run time  0:00:58.485460
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_22/forward_22_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3504732
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:43:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa86be26e50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1480, '_step_count': 1481, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.361731 valid_loss:0.368564 each epoch time:11.56822
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001476  valid_dq/boxsize 0.001505  train_dp 0.343055  valid_dp 0.349522 reg_loss 13.135746
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:44:04
run time  0:00:58.524589
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_22/forward_22_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3513747
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:44:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f49ecc1bd10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1485, '_step_count': 1486, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.508000 valid_loss:0.505581 each epoch time:11.64306
optimizer lr 0.00096  boxsize 8.94427  train_dq/boxsize 0.002926  valid_dq/boxsize 0.002915  train_dp 0.481828  valid_dp 0.479506 reg_loss 28.246445
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:45:03
run time  0:00:58.202491
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_22/forward_22_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3522763
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:45:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4276264050>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1490, '_step_count': 1491, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.361642 valid_loss:0.368475 each epoch time:11.56533
optimizer lr 0.00096  boxsize 12.64911  train_dq/boxsize 0.001476  valid_dq/boxsize 0.001505  train_dp 0.342967  valid_dp 0.349434 reg_loss 13.116515
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:46:02
run time  0:00:58.245318
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_22/forward_22_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3531778
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:46:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f48f3503190>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009603999999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1495, '_step_count': 1496, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009603999999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.436220 valid_loss:0.433096 each epoch time:11.91168
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002083  train_dp 0.413773  valid_dp 0.410827 reg_loss 16.372200
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:47:03
run time  0:00:59.473621
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_22/forward_22_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3540793
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:47:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8ac01bb390>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1500, '_step_count': 1501, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.572531 valid_loss:0.571385 each epoch time:11.91012
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003833  valid_dq/boxsize 0.003828  train_dp 0.543023  valid_dp 0.541916 reg_loss 36.287803
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:48:06
run time  0:00:59.327138
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_22/forward_22_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3549815
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:48:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f10090f6bd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1505, '_step_count': 1506, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.656312 valid_loss:0.655447 each epoch time:11.51021
optimizer lr 0.00094  boxsize 6.48886  train_dq/boxsize 0.005245  valid_dq/boxsize 0.005249  train_dp 0.622275  valid_dp 0.621385 reg_loss 37.523691
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:49:04
run time  0:00:57.052607
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_22/forward_22_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3558829
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:49:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f51274c5790>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1510, '_step_count': 1511, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.572132 valid_loss:0.570997 each epoch time:11.76414
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003831  valid_dq/boxsize 0.003826  train_dp 0.542642  valid_dp 0.541546 reg_loss 34.575302
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:50:03
run time  0:00:58.847040
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_22/backward_22_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3567845
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:50:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7c64059450>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1515, '_step_count': 1516, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.436050 valid_loss:0.432965 each epoch time:11.61894
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002101  valid_dq/boxsize 0.002085  train_dp 0.413586  valid_dp 0.410677 reg_loss 15.631556
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:51:04
run time  0:00:58.463177
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_22/backward_22_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3576860
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:51:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f838a9f83d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1520, '_step_count': 1521, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.361527 valid_loss:0.368320 each epoch time:12.04538
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.342832  valid_dp 0.349261 reg_loss 12.821076
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:52:05
run time  0:00:59.735585
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_22/backward_22_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3585875
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:52:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6d88cc9e10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1525, '_step_count': 1526, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.507451 valid_loss:0.505059 each epoch time:11.85509
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002927  valid_dq/boxsize 0.002916  train_dp 0.481272  valid_dp 0.478978 reg_loss 27.790809
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:53:05
run time  0:00:58.956792
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_22/backward_22_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3594890
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:53:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f681e754990>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1530, '_step_count': 1531, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.361405 valid_loss:0.368209 each epoch time:11.80123
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.342713  valid_dp 0.349152 reg_loss 12.889035
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:54:05
run time  0:00:59.368674
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_22/backward_22_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3603907
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:54:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe710a0a110>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1535, '_step_count': 1536, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.435818 valid_loss:0.432716 each epoch time:11.89424
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002101  valid_dq/boxsize 0.002084  train_dp 0.413359  valid_dp 0.410433 reg_loss 16.146976
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:55:06
run time  0:00:58.880360
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_22/backward_22_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3612921
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:55:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0618c43fd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1540, '_step_count': 1541, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.361273 valid_loss:0.368084 each epoch time:11.81769
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.342589  valid_dp 0.349034 reg_loss 12.965621
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:56:07
run time  0:00:59.547548
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_22/backward_22_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3621937
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:56:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6d9bdf9990>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1545, '_step_count': 1546, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.435718 valid_loss:0.432616 each epoch time:11.58003
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002101  valid_dq/boxsize 0.002084  train_dp 0.413263  valid_dp 0.410337 reg_loss 16.209937
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:57:09
run time  0:00:58.383643
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_23/forward_23_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3630954
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:57:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f07790cf210>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1550, '_step_count': 1551, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.361157 valid_loss:0.367978 each epoch time:11.72654
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.342478  valid_dp 0.348934 reg_loss 13.003339
memory usage : 3.2  at e= 5
end date/time : 20211025, 19:58:08
run time  0:00:59.046067
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_23/forward_23_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3639969
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:58:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f071357da10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1555, '_step_count': 1556, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.507218 valid_loss:0.504817 each epoch time:11.47702
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002927  valid_dq/boxsize 0.002916  train_dp 0.481038  valid_dp 0.478735 reg_loss 28.062898
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:59:08
run time  0:00:57.814994
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_23/forward_23_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3648984
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:59:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7d53417c10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1560, '_step_count': 1561, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.361069 valid_loss:0.367893 each epoch time:11.57776
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.342391  valid_dp 0.348849 reg_loss 12.984123
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:00:06
run time  0:00:58.210027
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_23/forward_23_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3657999
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:00:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feda3d0ce90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1565, '_step_count': 1566, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.435536 valid_loss:0.432432 each epoch time:11.71452
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002100  valid_dq/boxsize 0.002084  train_dp 0.413082  valid_dp 0.410156 reg_loss 16.262428
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:01:07
run time  0:00:59.015793
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_23/forward_23_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3667014
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:01:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f52725f6290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1570, '_step_count': 1571, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.571649 valid_loss:0.570515 each epoch time:11.64539
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003835  valid_dq/boxsize 0.003829  train_dp 0.542131  valid_dp 0.541037 reg_loss 36.259203
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:02:07
run time  0:00:58.849391
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_23/forward_23_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3676029
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:02:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f37f167afd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1575, '_step_count': 1576, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.655291 valid_loss:0.654429 each epoch time:11.56384
optimizer lr 0.00094  boxsize 6.48886  train_dq/boxsize 0.005248  valid_dq/boxsize 0.005252  train_dp 0.621237  valid_dp 0.620352 reg_loss 37.495545
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:03:05
run time  0:00:57.298891
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_23/forward_23_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3685044
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:03:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f572321e1d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1580, '_step_count': 1581, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.571247 valid_loss:0.570125 each epoch time:11.70010
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003832  valid_dq/boxsize 0.003827  train_dp 0.541747  valid_dp 0.540664 reg_loss 34.573546
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:04:06
run time  0:00:59.318116
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_23/backward_23_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3694059
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:04:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff0be15eed0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1585, '_step_count': 1586, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.435366 valid_loss:0.432298 each epoch time:11.82986
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002102  valid_dq/boxsize 0.002086  train_dp 0.412896  valid_dp 0.410002 reg_loss 15.518656
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:05:06
run time  0:00:59.649065
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_23/backward_23_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3703075
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:05:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb132452bd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1590, '_step_count': 1591, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.360958 valid_loss:0.367736 each epoch time:11.81794
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.342258  valid_dp 0.348672 reg_loss 12.694241
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:06:08
run time  0:00:59.831970
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_23/backward_23_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3712091
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:06:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd17a62c190>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1595, '_step_count': 1596, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.506670 valid_loss:0.504299 each epoch time:11.89429
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002928  valid_dq/boxsize 0.002917  train_dp 0.480481  valid_dp 0.478209 reg_loss 27.607267
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:07:08
run time  0:00:59.274854
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_23/backward_23_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3721106
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:07:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb6c7709f50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1600, '_step_count': 1601, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.360835 valid_loss:0.367627 each epoch time:11.80671
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.342138  valid_dp 0.348566 reg_loss 12.764774
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:08:08
run time  0:00:59.228731
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_23/backward_23_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3730121
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:08:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f809423b690>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1605, '_step_count': 1606, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.435134 valid_loss:0.432051 each epoch time:11.50633
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002102  valid_dq/boxsize 0.002085  train_dp 0.412668  valid_dp 0.409761 reg_loss 16.035427
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:09:07
run time  0:00:58.121211
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_23/backward_23_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3739136
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:09:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efd73794f50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1610, '_step_count': 1611, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.360702 valid_loss:0.367507 each epoch time:12.04147
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.342013  valid_dp 0.348453 reg_loss 12.838990
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:10:07
run time  0:00:59.289847
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_23/backward_23_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3748151
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:10:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc072071250>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1615, '_step_count': 1616, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.435034 valid_loss:0.431951 each epoch time:11.84212
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002101  valid_dq/boxsize 0.002085  train_dp 0.412572  valid_dp 0.409665 reg_loss 16.101621
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:11:08
run time  0:00:59.879772
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_24/forward_24_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3757167
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:11:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1cf3c26d90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1620, '_step_count': 1621, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.360585 valid_loss:0.367402 each epoch time:11.75077
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.341902  valid_dp 0.348353 reg_loss 12.879786
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:12:07
run time  0:00:58.421771
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_24/forward_24_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3766182
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:12:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd1841b18d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1625, '_step_count': 1626, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.506436 valid_loss:0.504059 each epoch time:11.57780
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002928  valid_dq/boxsize 0.002917  train_dp 0.480246  valid_dp 0.477968 reg_loss 27.892447
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:13:06
run time  0:00:58.339345
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_24/forward_24_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3775197
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:13:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fabde85dad0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1630, '_step_count': 1631, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.360498 valid_loss:0.367314 each epoch time:11.61965
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.341815  valid_dp 0.348265 reg_loss 12.863934
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:14:06
run time  0:00:58.182654
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_24/forward_24_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3784212
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:14:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa296332410>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1635, '_step_count': 1636, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.434852 valid_loss:0.431769 each epoch time:11.44747
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002101  valid_dq/boxsize 0.002084  train_dp 0.412391  valid_dp 0.409485 reg_loss 16.151773
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:15:05
run time  0:00:58.326372
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_24/forward_24_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3793228
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:15:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f29c1832090>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1640, '_step_count': 1641, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.570765 valid_loss:0.569641 each epoch time:11.16329
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003836  valid_dq/boxsize 0.003831  train_dp 0.541235  valid_dp 0.540151 reg_loss 36.245414
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:16:01
run time  0:00:55.671366
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_24/forward_24_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3802243
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:16:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa44a207190>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1645, '_step_count': 1646, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.654268 valid_loss:0.653412 each epoch time:11.71835
optimizer lr 0.00094  boxsize 6.48886  train_dq/boxsize 0.005251  valid_dq/boxsize 0.005255  train_dp 0.620196  valid_dp 0.619315 reg_loss 37.473944
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:17:00
run time  0:00:58.571694
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_24/forward_24_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3811259
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:17:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f79ead9d590>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1650, '_step_count': 1651, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.570360 valid_loss:0.569251 each epoch time:11.92645
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003834  valid_dq/boxsize 0.003829  train_dp 0.540848  valid_dp 0.539779 reg_loss 34.571192
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:18:01
run time  0:00:59.379522
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_24/backward_24_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3820277
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:18:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1011aa3ed0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1655, '_step_count': 1656, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.434682 valid_loss:0.431632 each epoch time:11.59891
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002103  valid_dq/boxsize 0.002087  train_dp 0.412202  valid_dp 0.409325 reg_loss 15.412757
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:19:01
run time  0:00:58.083672
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_24/backward_24_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3829298
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:19:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f37dd451110>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1660, '_step_count': 1661, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.360389 valid_loss:0.367161 each epoch time:11.52460
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001508  train_dp 0.341683  valid_dp 0.348091 reg_loss 12.577628
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:20:00
run time  0:00:58.677369
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_24/backward_24_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3838313
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:20:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7276ea6cd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1665, '_step_count': 1666, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.505888 valid_loss:0.503540 each epoch time:11.97591
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002929  valid_dq/boxsize 0.002918  train_dp 0.479688  valid_dp 0.477440 reg_loss 27.428057
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:21:01
run time  0:01:00.107818
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_24/backward_24_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3847328
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:21:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbc453a9cd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1670, '_step_count': 1671, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.360265 valid_loss:0.367052 each epoch time:12.07938
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001507  train_dp 0.341562  valid_dp 0.347984 reg_loss 12.642562
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:22:02
run time  0:00:59.721010
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_24/backward_24_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3856343
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:22:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5d53fc3310>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1675, '_step_count': 1676, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.434451 valid_loss:0.431389 each epoch time:11.38138
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002102  valid_dq/boxsize 0.002086  train_dp 0.411975  valid_dp 0.409089 reg_loss 15.936610
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:23:03
run time  0:00:57.995029
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_24/backward_24_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3865358
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:23:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efed4774850>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1680, '_step_count': 1681, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.360131 valid_loss:0.366927 each epoch time:11.88413
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.341437  valid_dp 0.347867 reg_loss 12.722989
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:24:04
run time  0:01:00.055591
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_24/backward_24_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3874375
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:24:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fba94ee0f90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1685, '_step_count': 1686, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.434350 valid_loss:0.431288 each epoch time:11.77813
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002102  valid_dq/boxsize 0.002086  train_dp 0.411879  valid_dp 0.408993 reg_loss 16.004477
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:25:04
run time  0:00:58.481156
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_25/forward_25_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3883389
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:25:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff7e4cd89d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1690, '_step_count': 1691, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.360014 valid_loss:0.366819 each epoch time:11.63920
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.341325  valid_dp 0.347765 reg_loss 12.767945
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:26:03
run time  0:00:58.202473
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_25/forward_25_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3892404
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:26:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb77453a850>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1695, '_step_count': 1696, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.505654 valid_loss:0.503299 each epoch time:11.55399
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002930  valid_dq/boxsize 0.002918  train_dp 0.479452  valid_dp 0.477199 reg_loss 27.739386
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:27:02
run time  0:00:57.769971
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_25/forward_25_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3901419
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:27:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc1e66a4390>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1700, '_step_count': 1701, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.359926 valid_loss:0.366734 each epoch time:11.83780
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001477  valid_dq/boxsize 0.001506  train_dp 0.341237  valid_dp 0.347680 reg_loss 12.748488
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:28:01
run time  0:00:58.150130
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_25/forward_25_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3910434
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:28:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f78183258d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1705, '_step_count': 1706, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.434168 valid_loss:0.431105 each epoch time:11.80390
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002102  valid_dq/boxsize 0.002085  train_dp 0.411698  valid_dp 0.408811 reg_loss 16.064619
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:29:01
run time  0:00:59.665817
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_25/forward_25_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3919449
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:29:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7ec445c3d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1710, '_step_count': 1711, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.569878 valid_loss:0.568767 each epoch time:11.57584
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003838  valid_dq/boxsize 0.003833  train_dp 0.540333  valid_dp 0.539264 reg_loss 36.251740
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:30:01
run time  0:00:58.110739
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_25/forward_25_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3928466
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:30:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f784249d290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1715, '_step_count': 1716, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.653239 valid_loss:0.652389 each epoch time:11.62165
optimizer lr 0.00094  boxsize 6.48886  train_dq/boxsize 0.005254  valid_dq/boxsize 0.005258  train_dp 0.619146  valid_dp 0.618270 reg_loss 37.471681
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:31:00
run time  0:00:57.998150
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_25/forward_25_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3937485
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:31:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd9a07fff50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1720, '_step_count': 1721, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.569471 valid_loss:0.568376 each epoch time:11.87309
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003835  valid_dq/boxsize 0.003830  train_dp 0.539945  valid_dp 0.538891 reg_loss 34.556785
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:31:59
run time  0:00:58.639103
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_25/backward_25_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3946500
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:32:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa738a18510>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1725, '_step_count': 1726, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.433998 valid_loss:0.430965 each epoch time:11.82090
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002104  valid_dq/boxsize 0.002088  train_dp 0.411507  valid_dp 0.408647 reg_loss 15.314449
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:32:59
run time  0:00:59.308518
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_25/backward_25_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3955515
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:33:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fae831dfd50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1730, '_step_count': 1731, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.359819 valid_loss:0.366582 each epoch time:11.92945
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001508  train_dp 0.341105  valid_dp 0.347504 reg_loss 12.465786
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:34:03
run time  0:00:59.804163
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_25/backward_25_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3964537
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:34:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f615a592d10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1735, '_step_count': 1736, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.505103 valid_loss:0.502779 each epoch time:11.84581
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002931  valid_dq/boxsize 0.002919  train_dp 0.478890  valid_dp 0.476669 reg_loss 27.268204
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:35:04
run time  0:00:59.721806
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_25/backward_25_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3973552
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:35:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6b2a72a290>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1740, '_step_count': 1741, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.359694 valid_loss:0.366473 each epoch time:11.96406
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001508  train_dp 0.340983  valid_dp 0.347398 reg_loss 12.533837
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:36:05
run time  0:00:59.537451
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_25/backward_25_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3982566
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:36:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4d91229490>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1745, '_step_count': 1746, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.433765 valid_loss:0.430722 each epoch time:11.61978
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002103  valid_dq/boxsize 0.002087  train_dp 0.411280  valid_dp 0.408411 reg_loss 15.846161
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:37:05
run time  0:00:59.033919
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_25/backward_25_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  3991581
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:37:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f649252ba50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1750, '_step_count': 1751, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.359559 valid_loss:0.366350 each epoch time:11.90733
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001507  train_dp 0.340857  valid_dp 0.347284 reg_loss 12.616061
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:38:06
run time  0:00:59.475324
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_25/backward_25_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4000597
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:38:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4a01a57cd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1755, '_step_count': 1756, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.433665 valid_loss:0.430621 each epoch time:11.95994
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002103  valid_dq/boxsize 0.002086  train_dp 0.411184  valid_dp 0.408316 reg_loss 15.920288
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:39:07
run time  0:00:59.233987
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_26/forward_26_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4009612
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:39:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe39a576890>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1760, '_step_count': 1761, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.359441 valid_loss:0.366239 each epoch time:11.43237
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.340745  valid_dp 0.347178 reg_loss 12.660585
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:40:06
run time  0:00:58.153105
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_26/forward_26_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4018627
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:40:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1d23a83510>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1765, '_step_count': 1766, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.504869 valid_loss:0.502540 each epoch time:11.43858
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002931  valid_dq/boxsize 0.002919  train_dp 0.478654  valid_dp 0.476428 reg_loss 27.587899
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:41:05
run time  0:00:58.080687
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_26/forward_26_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4027642
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:41:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efcb80c0d90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1770, '_step_count': 1771, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.359352 valid_loss:0.366156 each epoch time:11.41214
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001478  valid_dq/boxsize 0.001507  train_dp 0.340656  valid_dp 0.347094 reg_loss 12.645779
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:42:03
run time  0:00:56.992061
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_26/forward_26_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4036657
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:42:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7f6bbc8e10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1775, '_step_count': 1776, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.433482 valid_loss:0.430439 each epoch time:11.71692
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002103  valid_dq/boxsize 0.002086  train_dp 0.411001  valid_dp 0.408135 reg_loss 15.987463
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:43:03
run time  0:00:59.071151
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_26/forward_26_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4045672
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:43:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f014a1b8210>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1780, '_step_count': 1781, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.568988 valid_loss:0.567888 each epoch time:11.41339
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003840  valid_dq/boxsize 0.003834  train_dp 0.539427  valid_dp 0.538370 reg_loss 36.235411
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:44:02
run time  0:00:58.225727
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_26/forward_26_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4054688
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:44:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f786bd4d4d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1785, '_step_count': 1786, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.652205 valid_loss:0.651359 each epoch time:11.87995
optimizer lr 0.00094  boxsize 6.48886  train_dq/boxsize 0.005257  valid_dq/boxsize 0.005261  train_dp 0.618091  valid_dp 0.617219 reg_loss 37.416841
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:45:01
run time  0:00:58.602230
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_26/forward_26_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4063703
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:45:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4303944c50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1790, '_step_count': 1791, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.568577 valid_loss:0.567495 each epoch time:11.62233
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003837  valid_dq/boxsize 0.003832  train_dp 0.539036  valid_dp 0.537996 reg_loss 34.527767
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:46:02
run time  0:00:59.447012
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_26/backward_26_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4072718
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:46:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd0911ebd50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1795, '_step_count': 1796, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.433313 valid_loss:0.430298 each epoch time:11.87670
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002105  valid_dq/boxsize 0.002089  train_dp 0.410809  valid_dp 0.407967 reg_loss 15.229270
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:47:02
run time  0:00:59.345326
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_26/backward_26_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4081734
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:47:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f93c98eacd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1800, '_step_count': 1801, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.359246 valid_loss:0.366004 each epoch time:11.87718
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001480  valid_dq/boxsize 0.001509  train_dp 0.340522  valid_dp 0.346917 reg_loss 12.361932
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:48:03
run time  0:01:00.068375
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_26/backward_26_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4090749
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:48:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f85b02b1e90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1805, '_step_count': 1806, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.504315 valid_loss:0.502017 each epoch time:12.01708
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002932  valid_dq/boxsize 0.002921  train_dp 0.478087  valid_dp 0.475894 reg_loss 27.112336
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:49:04
run time  0:00:59.997371
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_26/backward_26_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4099765
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:49:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa52b4f39d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1810, '_step_count': 1811, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.359119 valid_loss:0.365895 each epoch time:11.88448
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001480  valid_dq/boxsize 0.001509  train_dp 0.340399  valid_dp 0.346811 reg_loss 12.430884
memory usage : 3.1  at e= 5
end date/time : 20211025, 20:50:05
run time  0:00:59.350413
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_26/backward_26_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4108781
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:50:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fedeba0da10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1815, '_step_count': 1816, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.433078 valid_loss:0.430058 each epoch time:11.53798
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002104  valid_dq/boxsize 0.002088  train_dp 0.410580  valid_dp 0.407735 reg_loss 15.773549
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:51:04
run time  0:00:58.279901
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_26/backward_26_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4117796
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:51:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f08c4e2f190>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1820, '_step_count': 1821, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.358983 valid_loss:0.365770 each epoch time:11.60105
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001508  train_dp 0.340272  valid_dp 0.346695 reg_loss 12.517737
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:52:04
run time  0:00:59.281801
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_26/backward_26_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4126811
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:52:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc1b57d3e10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1825, '_step_count': 1826, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.432977 valid_loss:0.429957 each epoch time:11.22750
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002104  valid_dq/boxsize 0.002088  train_dp 0.410483  valid_dp 0.407639 reg_loss 15.845908
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:53:03
run time  0:00:57.069012
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_27/forward_27_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4135827
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:53:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb8d634ad10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1830, '_step_count': 1831, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.358864 valid_loss:0.365662 each epoch time:11.81698
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001508  train_dp 0.340160  valid_dp 0.346593 reg_loss 12.563566
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:54:02
run time  0:00:57.983904
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_27/forward_27_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4144842
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:54:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd67546abd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1835, '_step_count': 1836, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.504081 valid_loss:0.501776 each epoch time:11.72710
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002933  valid_dq/boxsize 0.002921  train_dp 0.477849  valid_dp 0.475650 reg_loss 27.451973
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:55:03
run time  0:00:58.517531
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_27/forward_27_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4153861
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:55:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9588f83490>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1840, '_step_count': 1841, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.358775 valid_loss:0.365575 each epoch time:11.59583
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001479  valid_dq/boxsize 0.001508  train_dp 0.340070  valid_dp 0.346505 reg_loss 12.548926
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:56:04
run time  0:00:58.010411
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_27/forward_27_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4162876
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:56:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f18d51ffc10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1845, '_step_count': 1846, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.432793 valid_loss:0.429773 each epoch time:11.49997
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002104  valid_dq/boxsize 0.002088  train_dp 0.410300  valid_dp 0.407456 reg_loss 15.918589
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:57:04
run time  0:00:57.659453
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_27/forward_27_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4171891
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:57:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6b182c1a90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1850, '_step_count': 1851, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.568093 valid_loss:0.567003 each epoch time:11.59808
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003842  valid_dq/boxsize 0.003837  train_dp 0.538515  valid_dp 0.537468 reg_loss 36.245190
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:58:02
run time  0:00:58.002803
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_27/forward_27_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4180907
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:58:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3c6caa6850>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1855, '_step_count': 1856, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.651166 valid_loss:0.650324 each epoch time:11.61128
optimizer lr 0.00094  boxsize 6.48886  train_dq/boxsize 0.005261  valid_dq/boxsize 0.005265  train_dp 0.617030  valid_dp 0.616161 reg_loss 37.360859
memory usage : 3.2  at e= 5
end date/time : 20211025, 20:59:04
run time  0:00:58.687654
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_27/forward_27_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  4189922
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:59:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6c10302350>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1860, '_step_count': 1861, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.567680 valid_loss:0.566608 each epoch time:11.92846
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003840  valid_dq/boxsize 0.003834  train_dp 0.538122  valid_dp 0.537092 reg_loss 34.511346
memory usage : 3.1  at e= 5
end date/time : 20211025, 21:00:06
run time  0:00:59.470530
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_27/backward_27_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  5063
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:00:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa12a2b4350>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1865, '_step_count': 1866, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.432625 valid_loss:0.429629 each epoch time:11.74766
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002106  valid_dq/boxsize 0.002090  train_dp 0.410107  valid_dp 0.407283 reg_loss 15.151771
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:01:06
run time  0:00:59.030523
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_27/backward_27_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  14078
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:01:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb3c1fd2950>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1870, '_step_count': 1871, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.358669 valid_loss:0.365421 each epoch time:12.08662
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001481  valid_dq/boxsize 0.001510  train_dp 0.339935  valid_dp 0.346324 reg_loss 12.265795
memory usage : 3.1  at e= 5
end date/time : 20211025, 21:02:07
run time  0:00:59.659320
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_27/backward_27_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  23093
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:02:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6a6038d190>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1875, '_step_count': 1876, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.503523 valid_loss:0.501254 each epoch time:11.89241
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002934  valid_dq/boxsize 0.002922  train_dp 0.477279  valid_dp 0.475115 reg_loss 26.980600
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:03:07
run time  0:00:59.499558
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_27/backward_27_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  32108
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:03:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3066902810>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1880, '_step_count': 1881, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.358542 valid_loss:0.365309 each epoch time:12.01733
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001481  valid_dq/boxsize 0.001510  train_dp 0.339810  valid_dp 0.346215 reg_loss 12.337567
memory usage : 3.1  at e= 5
end date/time : 20211025, 21:04:10
run time  0:00:59.734777
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_27/backward_27_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  41124
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:04:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8ee8f26210>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1885, '_step_count': 1886, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.432389 valid_loss:0.429391 each epoch time:11.75259
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002106  valid_dq/boxsize 0.002089  train_dp 0.409877  valid_dp 0.407055 reg_loss 15.706250
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:05:09
run time  0:00:58.160352
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_27/backward_27_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  50141
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:05:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f662f1a9350>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1890, '_step_count': 1891, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.358404 valid_loss:0.365184 each epoch time:11.88752
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001480  valid_dq/boxsize 0.001509  train_dp 0.339683  valid_dp 0.346100 reg_loss 12.427137
memory usage : 3.1  at e= 5
end date/time : 20211025, 21:06:10
run time  0:01:00.076101
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_27/backward_27_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  59156
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:06:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3873508a90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1895, '_step_count': 1896, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.432287 valid_loss:0.429290 each epoch time:11.43709
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002105  valid_dq/boxsize 0.002089  train_dp 0.409780  valid_dp 0.406958 reg_loss 15.786958
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:07:08
run time  0:00:57.248406
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_28/forward_28_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  68171
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:07:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2e59f4c890>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1900, '_step_count': 1901, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.358285 valid_loss:0.365077 each epoch time:11.60439
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001480  valid_dq/boxsize 0.001508  train_dp 0.339570  valid_dp 0.345998 reg_loss 12.474133
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:08:08
run time  0:00:58.688731
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_28/forward_28_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  77186
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:08:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8be5d72f50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1905, '_step_count': 1906, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.503287 valid_loss:0.501011 each epoch time:11.50948
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002935  valid_dq/boxsize 0.002923  train_dp 0.477038  valid_dp 0.474870 reg_loss 27.334657
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:09:08
run time  0:00:57.581937
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_28/forward_28_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  86201
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:09:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9ccbde8750>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1910, '_step_count': 1911, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.358195 valid_loss:0.364990 each epoch time:11.43831
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001480  valid_dq/boxsize 0.001508  train_dp 0.339479  valid_dp 0.345910 reg_loss 12.458815
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:10:06
run time  0:00:57.981466
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_28/forward_28_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  95217
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:10:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7d79ece450>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1915, '_step_count': 1916, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.432103 valid_loss:0.429103 each epoch time:11.38327
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002105  valid_dq/boxsize 0.002089  train_dp 0.409596  valid_dp 0.406771 reg_loss 15.864920
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:11:05
run time  0:00:57.091542
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_28/forward_28_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  104233
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:11:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa53fad3d50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1920, '_step_count': 1921, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.567194 valid_loss:0.566115 each epoch time:11.55582
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003845  valid_dq/boxsize 0.003839  train_dp 0.537597  valid_dp 0.536561 reg_loss 36.228611
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:12:04
run time  0:00:58.548964
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_28/forward_28_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  113248
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:12:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3bd9e2c190>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1925, '_step_count': 1926, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.650119 valid_loss:0.649282 each epoch time:11.55411
optimizer lr 0.00094  boxsize 6.48886  train_dq/boxsize 0.005265  valid_dq/boxsize 0.005269  train_dp 0.615957  valid_dp 0.615094 reg_loss 37.321062
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:13:04
run time  0:00:58.615437
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_28/forward_28_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  122263
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:13:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1d59a49a50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1930, '_step_count': 1931, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.566777 valid_loss:0.565716 each epoch time:11.81368
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003842  valid_dq/boxsize 0.003837  train_dp 0.537200  valid_dp 0.536182 reg_loss 34.498554
memory usage : 3.1  at e= 5
end date/time : 20211025, 21:14:03
run time  0:00:58.909169
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_28/backward_28_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  131278
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:14:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2b3450ef50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1935, '_step_count': 1936, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.431935 valid_loss:0.428960 each epoch time:11.76657
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002108  valid_dq/boxsize 0.002092  train_dp 0.409401  valid_dp 0.406597 reg_loss 15.084061
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:15:02
run time  0:00:57.994977
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_28/backward_28_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  140293
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:15:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f73788c5f10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1940, '_step_count': 1941, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.358090 valid_loss:0.364838 each epoch time:11.81676
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001482  valid_dq/boxsize 0.001511  train_dp 0.339343  valid_dp 0.345730 reg_loss 12.177554
memory usage : 3.1  at e= 5
end date/time : 20211025, 21:16:03
run time  0:00:59.652551
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_28/backward_28_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  149308
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:16:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2060d7f090>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1945, '_step_count': 1946, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.502726 valid_loss:0.500485 each epoch time:11.87582
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002936  valid_dq/boxsize 0.002924  train_dp 0.476462  valid_dp 0.474329 reg_loss 26.849781
memory usage : 3.1  at e= 5
end date/time : 20211025, 21:17:03
run time  0:00:59.906994
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_28/backward_28_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  158329
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:17:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb8fd4608d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1950, '_step_count': 1951, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.357961 valid_loss:0.364724 each epoch time:11.67043
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001482  valid_dq/boxsize 0.001510  train_dp 0.339217  valid_dp 0.345619 reg_loss 12.248778
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:18:07
run time  0:00:59.729913
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_28/backward_28_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  167349
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:18:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb2d73d7e50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1955, '_step_count': 1956, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.431697 valid_loss:0.428721 each epoch time:11.62777
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002107  valid_dq/boxsize 0.002091  train_dp 0.409169  valid_dp 0.406367 reg_loss 15.655209
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:19:06
run time  0:00:57.771596
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_28/backward_28_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  176363
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:19:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb81e079550>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1960, '_step_count': 1961, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.357822 valid_loss:0.364600 each epoch time:12.02034
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001481  valid_dq/boxsize 0.001510  train_dp 0.339089  valid_dp 0.345504 reg_loss 12.343849
memory usage : 3.1  at e= 5
end date/time : 20211025, 21:20:06
run time  0:00:59.648310
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_28/backward_28_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  185378
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:20:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa7aab79fd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1965, '_step_count': 1966, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.431595 valid_loss:0.428619 each epoch time:11.47187
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002107  valid_dq/boxsize 0.002090  train_dp 0.409072  valid_dp 0.406271 reg_loss 15.737053
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:21:04
run time  0:00:57.272295
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/forward_29/forward_29_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  194394
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:21:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff923b5ba50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1970, '_step_count': 1971, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.357702 valid_loss:0.364493 each epoch time:11.53922
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001480  valid_dq/boxsize 0.001509  train_dp 0.338976  valid_dp 0.345403 reg_loss 12.397560
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:22:03
run time  0:00:58.277709
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/forward_29/forward_29_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  203409
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:22:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3366b545d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1975, '_step_count': 1976, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.502490 valid_loss:0.500243 each epoch time:11.53300
optimizer lr 0.00094  boxsize 8.94427  train_dq/boxsize 0.002937  valid_dq/boxsize 0.002925  train_dp 0.476221  valid_dp 0.474083 reg_loss 27.223612
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:23:03
run time  0:00:58.533927
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/forward_29/forward_29_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  212424
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:23:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9d5b9dc6d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1980, '_step_count': 1981, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.357612 valid_loss:0.364404 each epoch time:11.54310
optimizer lr 0.00094  boxsize 12.64911  train_dq/boxsize 0.001481  valid_dq/boxsize 0.001509  train_dp 0.338884  valid_dp 0.345312 reg_loss 12.381301
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:24:02
run time  0:00:57.872338
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/forward_29/forward_29_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  221439
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:24:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd29a63af90>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1985, '_step_count': 1986, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.431410 valid_loss:0.428435 each epoch time:11.61482
optimizer lr 0.00094  boxsize 10.69045  train_dq/boxsize 0.002107  valid_dq/boxsize 0.002091  train_dp 0.408887  valid_dp 0.406086 reg_loss 15.821185
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:25:00
run time  0:00:57.645442
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/forward_29/forward_29_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  230454
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:25:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f25d89c4c10>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1990, '_step_count': 1991, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.566290 valid_loss:0.565218 each epoch time:11.64685
optimizer lr 0.00094  boxsize 7.69800  train_dq/boxsize 0.003848  valid_dq/boxsize 0.003842  train_dp 0.536670  valid_dp 0.535642 reg_loss 36.257050
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:25:59
run time  0:00:58.577725
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/forward_29/forward_29_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  239469
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:26:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7c97c42190>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009411919999999999, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 1995, '_step_count': 1996, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009411919999999999]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.649065 valid_loss:0.648235 each epoch time:11.74738
optimizer lr 0.00092  boxsize 6.48886  train_dq/boxsize 0.005269  valid_dq/boxsize 0.005273  train_dp 0.614875  valid_dp 0.614019 reg_loss 37.289683
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:27:00
run time  0:00:59.323608
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/forward_29/forward_29_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  248484
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:27:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f92e177ce50>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009223681599999998, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 2000, '_step_count': 2001, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009223681599999998]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.565872 valid_loss:0.564814 each epoch time:11.69692
optimizer lr 0.00092  boxsize 7.69800  train_dq/boxsize 0.003845  valid_dq/boxsize 0.003839  train_dp 0.536274  valid_dp 0.535261 reg_loss 34.485263
memory usage : 3.1  at e= 5
end date/time : 20211025, 21:28:00
run time  0:00:58.983328
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/backward_29/backward_29_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  257499
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:28:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0395fa5150>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009223681599999998, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 2005, '_step_count': 2006, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009223681599999998]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.431245 valid_loss:0.428288 each epoch time:11.42019
optimizer lr 0.00092  boxsize 10.69045  train_dq/boxsize 0.002110  valid_dq/boxsize 0.002094  train_dp 0.408692  valid_dp 0.405907 reg_loss 15.020443
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:28:58
run time  0:00:57.884729
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/backward_29/backward_29_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  266517
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:28:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efcaca01dd0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009223681599999998, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 2010, '_step_count': 2011, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009223681599999998]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.357511 valid_loss:0.364260 each epoch time:11.92145
optimizer lr 0.00092  boxsize 12.64911  train_dq/boxsize 0.001483  valid_dq/boxsize 0.001512  train_dp 0.338749  valid_dp 0.345137 reg_loss 12.092252
memory usage : 3.1  at e= 5
end date/time : 20211025, 21:29:59
run time  0:00:59.674328
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/backward_29/backward_29_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  275532
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:30:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdf578f8250>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009223681599999998, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 2015, '_step_count': 2016, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009223681599999998]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.501929 valid_loss:0.499717 each epoch time:11.91126
optimizer lr 0.00092  boxsize 8.94427  train_dq/boxsize 0.002939  valid_dq/boxsize 0.002927  train_dp 0.475644  valid_dp 0.473541 reg_loss 26.741346
memory usage : 3.1  at e= 5
end date/time : 20211025, 21:30:59
run time  0:00:59.596385
mean mem :  3.1 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/backward_29/backward_29_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  284552
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:31:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe4a82ca0d0>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009223681599999998, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 2020, '_step_count': 2021, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009223681599999998]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.357383 valid_loss:0.364147 each epoch time:11.98973
optimizer lr 0.00092  boxsize 12.64911  train_dq/boxsize 0.001483  valid_dq/boxsize 0.001512  train_dp 0.338625  valid_dp 0.345027 reg_loss 12.169116
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:32:00
run time  0:00:59.683999
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/backward_29/backward_29_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  293571
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:32:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f25d1547050>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009223681599999998, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 2025, '_step_count': 2026, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009223681599999998]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.431008 valid_loss:0.428051 each epoch time:11.41177
optimizer lr 0.00092  boxsize 10.69045  train_dq/boxsize 0.002109  valid_dq/boxsize 0.002093  train_dp 0.408463  valid_dp 0.405680 reg_loss 15.613516
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:32:58
run time  0:00:57.203365
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/backward_29/backward_29_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.001
pid :  302586
uname :  posix.uname_result(sysname='Linux', nodename='jae10', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:32:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  5 -> ... -> 64 -> 2
MLP_net initialized :  5 -> ... -> 64 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
pairwise_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.001
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbd58845910>
=> loading checkpoint '../data/gen_by_ML/pw-auto-lambda0.0l1reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=5, out_features=64, bias=True)
    (1): Tanh()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0009223681599999998, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.001], 'last_epoch': 2030, '_step_count': 2031, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0009223681599999998]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mae_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0 clip value 10.0
5 epoch: train_loss:0.357244 valid_loss:0.364022 each epoch time:11.96661
optimizer lr 0.00092  boxsize 12.64911  train_dq/boxsize 0.001482  valid_dq/boxsize 0.001511  train_dp 0.338498  valid_dp 0.344912 reg_loss 12.270640
memory usage : 3.2  at e= 5
end date/time : 20211025, 21:33:59
run time  0:00:59.633991
mean mem :  3.2 , std mem :  0.0
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/pw-auto-lambda0.0l1reg/1rho0.10/backward_29/backward_29_loss.txt
forward 2rho0.14
