forward 1rho0.10, first run no save model .....
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446143
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:07:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f75a9ea27d0>
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.621607 valid_loss:0.216081 each epoch time:20.30710
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000061  train_dp 0.211103  valid_dp 0.215309 reg_loss 4.097703
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:08:53
run time  0:01:41.113163
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/rho0/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/forward_1/forward_1_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446159
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:08:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f13c3805990>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 5, '_step_count': 6, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.437237 valid_loss:0.265971 each epoch time:19.78450
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000110  valid_dq/boxsize 0.000109  train_dp 0.271696  valid_dp 0.264804 reg_loss 1.643656
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:10:34
run time  0:01:40.114354
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_1/forward_1_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446181
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:10:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe9bcfb93d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 10, '_step_count': 11, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.302306 valid_loss:0.224569 each epoch time:19.57550
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000087  valid_dq/boxsize 0.000088  train_dp 0.220777  valid_dp 0.223456 reg_loss 0.804233
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:12:14
run time  0:01:38.608588
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_1/forward_1_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446199
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:12:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f23ef55aa50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 15, '_step_count': 16, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.528778 valid_loss:0.338001 each epoch time:20.49028
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000199  valid_dq/boxsize 0.000200  train_dp 0.339055  valid_dp 0.336214 reg_loss 1.879421
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:13:58
run time  0:01:42.411716
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_1/forward_1_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446215
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:13:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f10df6d2310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 20, '_step_count': 21, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.248328 valid_loss:0.237635 each epoch time:19.42954
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000112  valid_dq/boxsize 0.000112  train_dp 0.234731  valid_dp 0.236223 reg_loss 0.121807
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:15:39
run time  0:01:40.147960
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_1/forward_1_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446233
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:15:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f46716e9a50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 25, '_step_count': 26, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.302461 valid_loss:0.267667 each epoch time:20.12076
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000139  valid_dq/boxsize 0.000136  train_dp 0.274694  valid_dp 0.266217 reg_loss 0.262760
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:17:22
run time  0:01:40.022631
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_1/forward_1_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446253
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:17:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f29a100b850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 30, '_step_count': 31, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.493797 valid_loss:0.374310 each epoch time:20.33592
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000263  valid_dq/boxsize 0.000262  train_dp 0.376491  valid_dp 0.372290 reg_loss 1.152806
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:19:06
run time  0:01:42.457919
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_1/forward_1_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446270
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:19:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9d015feb90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 35, '_step_count': 36, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.477766 valid_loss:0.421047 each epoch time:20.57478
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000319  valid_dq/boxsize 0.000319  train_dp 0.422475  valid_dp 0.418978 reg_loss 0.532242
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:20:50
run time  0:01:42.934118
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_1/forward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_1/forward_1_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446287
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:20:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faa24daecd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 40, '_step_count': 41, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.407121 valid_loss:0.360722 each epoch time:20.51488
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000258  valid_dq/boxsize 0.000255  train_dp 0.363581  valid_dp 0.358757 reg_loss 0.415551
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:22:33
run time  0:01:41.644845
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_1/backward_1_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446304
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:22:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7facec0cd5d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 45, '_step_count': 46, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.268873 valid_loss:0.260668 each epoch time:20.51559
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000147  valid_dq/boxsize 0.000143  train_dp 0.266575  valid_dp 0.259138 reg_loss 0.007315
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:24:15
run time  0:01:40.821676
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_1/backward_1_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446323
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:24:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f61b5050f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 50, '_step_count': 51, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.210370 valid_loss:0.210500 each epoch time:20.08970
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000097  train_dp 0.207891  valid_dp 0.209267 reg_loss 0.012461
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:25:56
run time  0:01:40.196788
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_1/backward_1_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446339
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:25:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f35a5ac7c50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 55, '_step_count': 56, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.358556 valid_loss:0.291066 each epoch time:20.29363
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000171  valid_dq/boxsize 0.000171  train_dp 0.292869  valid_dp 0.289539 reg_loss 0.641583
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:27:38
run time  0:01:40.851043
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_1/backward_1_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446356
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:27:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f97d8bbd310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 60, '_step_count': 61, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.197779 valid_loss:0.198156 each epoch time:20.28338
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000088  valid_dq/boxsize 0.000086  train_dp 0.196669  valid_dp 0.197064 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:29:21
run time  0:01:41.168358
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_1/backward_1_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446372
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:29:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3715f46150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 65, '_step_count': 66, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.233136 valid_loss:0.226342 each epoch time:20.55960
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000107  valid_dq/boxsize 0.000104  train_dp 0.231796  valid_dp 0.225226 reg_loss 0.001935
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:31:04
run time  0:01:41.844237
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_1/backward_1_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446389
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:31:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe9c39a2ed0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 70, '_step_count': 71, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.181878 valid_loss:0.182915 each epoch time:19.85887
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000071  train_dp 0.180970  valid_dp 0.182018 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:32:45
run time  0:01:40.231123
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_1/backward_1_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_1/backward_1_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446409
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:32:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1407107710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 75, '_step_count': 76, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.219292 valid_loss:0.213177 each epoch time:20.79182
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000090  valid_dq/boxsize 0.000088  train_dp 0.218284  valid_dp 0.212234 reg_loss 0.000411
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:34:29
run time  0:01:42.330911
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_2/forward_2_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446426
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:34:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f22ec0c7b10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 80, '_step_count': 81, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.172403 valid_loss:0.174001 each epoch time:19.57735
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000063  valid_dq/boxsize 0.000063  train_dp 0.171597  valid_dp 0.173207 reg_loss 0.000124
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:36:11
run time  0:01:40.579383
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_2/forward_2_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446443
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:36:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa8352d9190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 85, '_step_count': 86, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.291773 valid_loss:0.256702 each epoch time:19.48477
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000130  valid_dq/boxsize 0.000130  train_dp 0.258939  valid_dp 0.255543 reg_loss 0.316725
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:37:51
run time  0:01:38.880584
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_2/forward_2_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446460
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:37:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb977962cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 90, '_step_count': 91, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.172703 valid_loss:0.173018 each epoch time:19.95520
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000065  valid_dq/boxsize 0.000065  train_dp 0.170558  valid_dp 0.172191 reg_loss 0.013196
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:39:34
run time  0:01:42.472297
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_2/forward_2_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446477
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:39:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8bb27e9a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 95, '_step_count': 96, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.208517 valid_loss:0.202631 each epoch time:19.82030
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000084  valid_dq/boxsize 0.000081  train_dp 0.207623  valid_dp 0.201762 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:41:16
run time  0:01:40.166600
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_2/forward_2_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446494
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:41:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f90643c6510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 100, '_step_count': 101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.325155 valid_loss:0.292051 each epoch time:20.12265
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000173  valid_dq/boxsize 0.000173  train_dp 0.294301  valid_dp 0.290716 reg_loss 0.295261
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:42:58
run time  0:01:41.125132
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_2/forward_2_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446511
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:42:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbf7d7d9310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 105, '_step_count': 106, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.354506 valid_loss:0.345767 each epoch time:20.29836
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000241  valid_dq/boxsize 0.000240  train_dp 0.349122  valid_dp 0.344212 reg_loss 0.038176
memory usage : 3.3  at e= 5
end date/time : 20211025, 00:44:42
run time  0:01:42.071945
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_2/forward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_2/forward_2_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446529
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:44:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc487af8290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 110, '_step_count': 111, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.308751 valid_loss:0.286095 each epoch time:20.50435
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000178  valid_dq/boxsize 0.000175  train_dp 0.289707  valid_dp 0.284750 reg_loss 0.176766
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:46:28
run time  0:01:42.740538
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_2/backward_2_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446546
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:46:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f273479bf90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 115, '_step_count': 116, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.208017 valid_loss:0.201663 each epoch time:19.90766
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000095  valid_dq/boxsize 0.000092  train_dp 0.206707  valid_dp 0.200681 reg_loss 0.002996
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:48:12
run time  0:01:40.024530
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_2/backward_2_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446562
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:48:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f22638ff1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 120, '_step_count': 121, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.161065 valid_loss:0.161939 each epoch time:19.99677
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000061  train_dp 0.160291  valid_dp 0.161173 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:49:55
run time  0:01:41.980932
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_2/backward_2_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446578
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:49:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb6b8ff2250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 125, '_step_count': 126, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.255530 valid_loss:0.233418 each epoch time:19.50676
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000115  valid_dq/boxsize 0.000115  train_dp 0.235283  valid_dp 0.232388 reg_loss 0.192171
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:51:37
run time  0:01:39.902253
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_2/backward_2_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446595
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:51:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa64dbd3210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 130, '_step_count': 131, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.154890 valid_loss:0.156000 each epoch time:19.89604
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000056  train_dp 0.154180  valid_dp 0.155294 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:53:19
run time  0:01:41.271754
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_2/backward_2_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446613
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:53:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa91b686a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 135, '_step_count': 136, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.190125 valid_loss:0.184773 each epoch time:19.82861
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000072  train_dp 0.189097  valid_dp 0.184002 reg_loss 0.002396
memory usage : 3.4  at e= 5
end date/time : 20211025, 00:55:00
run time  0:01:39.605880
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_2/backward_2_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446629
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:55:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f145d97ea90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 140, '_step_count': 141, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.147839 valid_loss:0.149210 each epoch time:19.64875
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000049  train_dp 0.147215  valid_dp 0.148586 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:56:41
run time  0:01:39.724958
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_2/backward_2_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_2/backward_2_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446646
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:56:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fad7ce87cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 145, '_step_count': 146, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.183532 valid_loss:0.178346 each epoch time:20.32124
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000067  valid_dq/boxsize 0.000065  train_dp 0.182818  valid_dp 0.177653 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 00:58:26
run time  0:01:42.196749
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_3/forward_3_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446663
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 00:58:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd4e5139250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 150, '_step_count': 151, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.142900 valid_loss:0.144354 each epoch time:20.05256
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000046  valid_dq/boxsize 0.000046  train_dp 0.142324  valid_dp 0.143776 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:00:08
run time  0:01:41.089323
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_3/forward_3_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446680
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:00:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2b4f9184d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 155, '_step_count': 156, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.232238 valid_loss:0.215342 each epoch time:20.24246
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000096  train_dp 0.217775  valid_dp 0.214486 reg_loss 0.135976
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:01:50
run time  0:01:40.386376
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_3/forward_3_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446697
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:01:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1a75886250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 160, '_step_count': 161, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.140574 valid_loss:0.141970 each epoch time:20.26855
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000046  valid_dq/boxsize 0.000046  train_dp 0.139995  valid_dp 0.141389 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:03:32
run time  0:01:41.092865
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_3/forward_3_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446716
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:03:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc2864030d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 165, '_step_count': 166, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.175330 valid_loss:0.170343 each epoch time:20.60472
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000060  train_dp 0.174610  valid_dp 0.169702 reg_loss 0.000624
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:05:17
run time  0:01:41.368140
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_3/forward_3_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446732
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:05:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8ee2fa6fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 170, '_step_count': 171, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.267844 valid_loss:0.248672 each epoch time:20.19686
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000138  valid_dq/boxsize 0.000136  train_dp 0.252009  valid_dp 0.247625 reg_loss 0.147750
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:06:59
run time  0:01:41.073468
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_3/forward_3_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446748
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:07:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff4091280d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 175, '_step_count': 176, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.306888 valid_loss:0.301167 each epoch time:21.12402
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000202  valid_dq/boxsize 0.000201  train_dp 0.304251  valid_dp 0.299860 reg_loss 0.013283
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:08:45
run time  0:01:44.762321
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_3/forward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_3/forward_3_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446771
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:08:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f972f73f610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 180, '_step_count': 181, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.257727 valid_loss:0.245790 each epoch time:20.33555
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000145  valid_dq/boxsize 0.000143  train_dp 0.249271  valid_dp 0.244693 reg_loss 0.073380
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:10:29
run time  0:01:42.236487
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_3/backward_3_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446790
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:10:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb9d6136950>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 185, '_step_count': 186, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.174236 valid_loss:0.168980 each epoch time:19.96791
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000069  train_dp 0.173468  valid_dp 0.168237 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:12:13
run time  0:01:40.323388
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_3/backward_3_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446806
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:12:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff84dc71710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 190, '_step_count': 191, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.135540 valid_loss:0.135631 each epoch time:20.20076
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000046  valid_dq/boxsize 0.000047  train_dp 0.133368  valid_dp 0.135041 reg_loss 0.015956
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:13:56
run time  0:01:41.992588
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_3/backward_3_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446824
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:13:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6ed5c0ee10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 195, '_step_count': 196, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.209364 valid_loss:0.199292 each epoch time:19.74992
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000091  valid_dq/boxsize 0.000090  train_dp 0.201547  valid_dp 0.198484 reg_loss 0.069987
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:15:39
run time  0:01:41.032741
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_3/backward_3_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446841
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:15:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb04eb27b50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 200, '_step_count': 201, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.129459 valid_loss:0.130740 each epoch time:20.39096
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000042  train_dp 0.128926  valid_dp 0.130204 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:17:22
run time  0:01:41.420306
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_3/backward_3_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446862
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:17:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc52a394ad0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 205, '_step_count': 206, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.163340 valid_loss:0.158492 each epoch time:19.97720
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000059  train_dp 0.162686  valid_dp 0.157859 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:19:03
run time  0:01:39.993789
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_3/backward_3_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446879
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:19:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3872a191d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 210, '_step_count': 211, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.125498 valid_loss:0.126862 each epoch time:20.50709
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000040  train_dp 0.124996  valid_dp 0.126355 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:20:45
run time  0:01:41.189844
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_3/backward_3_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_3/backward_3_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446895
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:20:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f858b53c710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 215, '_step_count': 216, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.158515 valid_loss:0.153842 each epoch time:20.65699
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000054  train_dp 0.157915  valid_dp 0.153260 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:22:29
run time  0:01:41.782314
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_4/forward_4_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446912
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:22:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8da1293b50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 220, '_step_count': 221, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.121923 valid_loss:0.123211 each epoch time:20.16327
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000037  train_dp 0.121067  valid_dp 0.122738 reg_loss 0.003943
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:24:12
run time  0:01:40.936727
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_4/forward_4_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446928
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:24:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f832609ff50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 225, '_step_count': 226, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.193090 valid_loss:0.187185 each epoch time:19.86478
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000081  valid_dq/boxsize 0.000080  train_dp 0.189294  valid_dp 0.186469 reg_loss 0.030733
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:25:53
run time  0:01:39.781488
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_4/forward_4_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446946
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:25:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4a4b4a1310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 230, '_step_count': 231, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.119426 valid_loss:0.120994 each epoch time:20.28405
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000037  train_dp 0.118963  valid_dp 0.120523 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:27:35
run time  0:01:40.925973
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_4/forward_4_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446964
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:27:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fccd6a12a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 235, '_step_count': 236, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.152476 valid_loss:0.147964 each epoch time:19.53743
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.151905  valid_dp 0.147409 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:29:16
run time  0:01:38.271087
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_4/forward_4_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446981
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:29:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efe41430350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 240, '_step_count': 241, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.227887 valid_loss:0.218298 each epoch time:19.69760
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000118  valid_dq/boxsize 0.000117  train_dp 0.221106  valid_dp 0.217401 reg_loss 0.058741
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:30:57
run time  0:01:39.351943
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_4/forward_4_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  446998
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:30:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f70c4023390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 245, '_step_count': 246, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.272454 valid_loss:0.267826 each epoch time:20.87533
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000180  valid_dq/boxsize 0.000181  train_dp 0.271045  valid_dp 0.266651 reg_loss 0.002388
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:32:43
run time  0:01:44.791998
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_4/forward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_4/forward_4_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447015
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:32:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8978b02e90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 250, '_step_count': 251, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.220000 valid_loss:0.215162 each epoch time:20.10060
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000123  valid_dq/boxsize 0.000121  train_dp 0.218151  valid_dp 0.214228 reg_loss 0.009026
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:34:26
run time  0:01:41.533118
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_4/backward_4_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447031
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:34:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe49bfa7b50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 255, '_step_count': 256, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.149993 valid_loss:0.145321 each epoch time:19.48563
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000057  train_dp 0.149359  valid_dp 0.144709 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:36:07
run time  0:01:39.535628
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_4/backward_4_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447047
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:36:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2c9c287bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 260, '_step_count': 261, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.113987 valid_loss:0.115276 each epoch time:19.91694
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000037  train_dp 0.113520  valid_dp 0.114802 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:37:48
run time  0:01:40.587543
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_4/backward_4_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447065
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:37:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efbd7b0d9d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 265, '_step_count': 266, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.177848 valid_loss:0.174926 each epoch time:20.18854
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000080  valid_dq/boxsize 0.000079  train_dp 0.176977  valid_dp 0.174217 reg_loss 0.001536
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:39:30
run time  0:01:40.593208
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_4/backward_4_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447082
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:39:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5458d50a50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 270, '_step_count': 271, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.111287 valid_loss:0.112627 each epoch time:20.17148
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.110832  valid_dp 0.112164 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:41:15
run time  0:01:41.505866
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_4/backward_4_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447100
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:41:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f99112e99d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 275, '_step_count': 276, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.142310 valid_loss:0.137991 each epoch time:19.76488
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000051  train_dp 0.141748  valid_dp 0.137446 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:42:57
run time  0:01:38.165943
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_4/backward_4_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447117
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:42:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdfd2358b10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 280, '_step_count': 281, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.108321 valid_loss:0.109764 each epoch time:19.55866
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.107888  valid_dp 0.109322 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:44:38
run time  0:01:40.134852
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_4/backward_4_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_4/backward_4_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447134
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:44:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f890d35a650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 285, '_step_count': 286, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.139687 valid_loss:0.135416 each epoch time:20.34877
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.139137  valid_dp 0.134882 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:46:20
run time  0:01:40.513562
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_5/forward_5_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447150
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:46:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd6e56784d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 290, '_step_count': 291, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.106025 valid_loss:0.107503 each epoch time:20.33626
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.105602  valid_dp 0.107071 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:48:02
run time  0:01:40.580949
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_5/forward_5_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447168
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:48:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2f2bff29d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 295, '_step_count': 296, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.168777 valid_loss:0.166194 each epoch time:20.24040
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000073  train_dp 0.168117  valid_dp 0.165541 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 01:49:44
run time  0:01:40.848458
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_5/forward_5_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447185
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:49:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f050e393d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 300, '_step_count': 301, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.104153 valid_loss:0.105637 each epoch time:20.52952
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.103734  valid_dp 0.105208 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:51:27
run time  0:01:40.907467
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_5/forward_5_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447201
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:51:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faad5bb1b10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 305, '_step_count': 306, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.134897 valid_loss:0.130762 each epoch time:20.66135
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.134371  valid_dp 0.130251 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 01:53:09
run time  0:01:41.427669
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_5/forward_5_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447218
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:53:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7f187dee50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 310, '_step_count': 311, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.199318 valid_loss:0.196113 each epoch time:20.54851
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000110  valid_dq/boxsize 0.000109  train_dp 0.198232  valid_dp 0.195271 reg_loss 0.002403
memory usage : 3.6  at e= 5
end date/time : 20211025, 01:54:51
run time  0:01:40.719957
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_5/forward_5_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447234
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:54:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8ff2813190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 315, '_step_count': 316, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.245232 valid_loss:0.239644 each epoch time:20.73595
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000164  valid_dq/boxsize 0.000162  train_dp 0.243798  valid_dp 0.238593 reg_loss 0.003720
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:56:36
run time  0:01:43.667599
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_5/forward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_5/forward_5_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447250
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:56:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f969bb78190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 320, '_step_count': 321, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.194508 valid_loss:0.191459 each epoch time:20.09594
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000108  valid_dq/boxsize 0.000107  train_dp 0.193674  valid_dp 0.190634 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 01:58:19
run time  0:01:41.795119
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_5/backward_5_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447267
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 01:58:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1de94a76d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 325, '_step_count': 326, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.131906 valid_loss:0.127735 each epoch time:20.67446
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000051  train_dp 0.131341  valid_dp 0.127188 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:00:03
run time  0:01:40.522015
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_5/backward_5_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447285
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:00:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2e966bca90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 330, '_step_count': 331, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.099992 valid_loss:0.101356 each epoch time:19.83635
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.099557  valid_dp 0.100911 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:01:44
run time  0:01:39.497744
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_5/backward_5_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447302
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:01:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f94679f2cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 335, '_step_count': 336, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.158504 valid_loss:0.156229 each epoch time:20.05456
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000073  valid_dq/boxsize 0.000073  train_dp 0.157847  valid_dp 0.155578 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:03:28
run time  0:01:40.592395
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_5/backward_5_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447318
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:03:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa188462450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 340, '_step_count': 341, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.097503 valid_loss:0.098970 each epoch time:19.74298
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.097089  valid_dp 0.098545 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:05:10
run time  0:01:39.874070
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_5/backward_5_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447335
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:05:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f17c8e541d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 345, '_step_count': 346, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.126832 valid_loss:0.122862 each epoch time:20.23514
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000048  train_dp 0.126302  valid_dp 0.122348 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:06:52
run time  0:01:41.300588
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_5/backward_5_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447352
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:06:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f78aa5e0410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 350, '_step_count': 351, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.095624 valid_loss:0.097101 each epoch time:19.92170
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.095219  valid_dp 0.096686 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:08:35
run time  0:01:41.335804
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_5/backward_5_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_5/backward_5_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447371
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:08:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f10d8c2b5d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 355, '_step_count': 356, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.125151 valid_loss:0.121205 each epoch time:20.42386
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000048  train_dp 0.124620  valid_dp 0.120690 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:10:17
run time  0:01:41.124352
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_6/forward_6_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447388
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:10:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0de5d0ad10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 360, '_step_count': 361, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.094196 valid_loss:0.095703 each epoch time:20.08186
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.093789  valid_dp 0.095286 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:12:01
run time  0:01:41.156686
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_6/forward_6_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447429
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:12:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1ca324f610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 365, '_step_count': 366, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.152632 valid_loss:0.150337 each epoch time:20.05492
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000072  train_dp 0.151985  valid_dp 0.149697 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:13:44
run time  0:01:40.402471
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_6/forward_6_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447445
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:13:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f04b886c610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 370, '_step_count': 371, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.093236 valid_loss:0.094762 each epoch time:20.13976
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.092680  valid_dp 0.094335 reg_loss 0.001405
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:15:26
run time  0:01:40.916529
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_6/forward_6_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447461
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:15:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8520949110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 375, '_step_count': 376, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.122004 valid_loss:0.118113 each epoch time:20.42693
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.121477  valid_dp 0.117601 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:17:11
run time  0:01:40.953731
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_6/forward_6_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447481
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:17:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f92f5de4390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 380, '_step_count': 381, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.180937 valid_loss:0.178082 each epoch time:20.27608
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000104  valid_dq/boxsize 0.000104  train_dp 0.179774  valid_dp 0.177281 reg_loss 0.003604
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:18:55
run time  0:01:40.582845
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_6/forward_6_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447498
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:18:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdf3224d590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 385, '_step_count': 386, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.225026 valid_loss:0.219673 each epoch time:20.70636
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000160  valid_dq/boxsize 0.000158  train_dp 0.223789  valid_dp 0.218649 reg_loss 0.002016
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:20:42
run time  0:01:42.603772
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_6/forward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_6/forward_6_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447515
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:20:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7ea8f30610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 390, '_step_count': 391, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.177590 valid_loss:0.174926 each epoch time:19.87034
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000105  valid_dq/boxsize 0.000104  train_dp 0.176779  valid_dp 0.174123 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:22:22
run time  0:01:39.433854
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_6/backward_6_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447532
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:22:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7facfee0b1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 395, '_step_count': 396, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.119431 valid_loss:0.115556 each epoch time:20.28150
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.118880  valid_dp 0.115022 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:24:06
run time  0:01:40.880276
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_6/backward_6_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447549
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:24:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc660797190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 400, '_step_count': 401, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.089673 valid_loss:0.090995 each epoch time:20.10286
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.089259  valid_dp 0.090569 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:25:49
run time  0:01:40.420311
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_6/backward_6_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447566
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:25:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe7ad66b690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 405, '_step_count': 406, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.145189 valid_loss:0.143063 each epoch time:20.48831
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000073  train_dp 0.144526  valid_dp 0.142409 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:27:32
run time  0:01:41.635684
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_6/backward_6_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447583
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:27:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f58766ca090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 410, '_step_count': 411, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.088424 valid_loss:0.089789 each epoch time:19.98958
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.088005  valid_dp 0.089358 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:29:13
run time  0:01:39.882108
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_6/backward_6_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447602
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:29:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fef91e5c710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 415, '_step_count': 416, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.115791 valid_loss:0.112007 each epoch time:20.08246
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.115263  valid_dp 0.111493 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:30:55
run time  0:01:40.564019
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_6/backward_6_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447619
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:30:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f78c3c85690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 420, '_step_count': 421, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.087074 valid_loss:0.088470 each epoch time:19.67457
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.086661  valid_dp 0.088045 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:32:38
run time  0:01:40.519981
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_6/backward_6_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_6/backward_6_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447637
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:32:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5729f58350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 425, '_step_count': 426, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.114323 valid_loss:0.110631 each epoch time:20.19497
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.113800  valid_dp 0.110123 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:34:21
run time  0:01:40.753750
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_7/forward_7_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447655
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:34:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4be0036190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 430, '_step_count': 431, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.085853 valid_loss:0.087291 each epoch time:19.85907
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.085438  valid_dp 0.086863 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:36:01
run time  0:01:39.319680
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_7/forward_7_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447672
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:36:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffb84d50850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 435, '_step_count': 436, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.140191 valid_loss:0.138193 each epoch time:20.03782
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000071  train_dp 0.139551  valid_dp 0.137559 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:37:44
run time  0:01:41.292801
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_7/forward_7_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447689
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:37:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f916f3749d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 440, '_step_count': 441, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.084736 valid_loss:0.086205 each epoch time:20.56665
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.084324  valid_dp 0.085780 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:39:27
run time  0:01:41.807227
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_7/forward_7_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447706
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:39:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f538be291d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 445, '_step_count': 446, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.111951 valid_loss:0.108315 each epoch time:19.80705
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000048  train_dp 0.111420  valid_dp 0.107798 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:41:10
run time  0:01:39.536980
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_7/forward_7_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447723
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:41:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f756a2ec3d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 450, '_step_count': 451, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.166793 valid_loss:0.164473 each epoch time:20.50438
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000103  valid_dq/boxsize 0.000102  train_dp 0.166002  valid_dp 0.163688 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:42:53
run time  0:01:41.689898
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_7/forward_7_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447741
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:42:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbe46fafc10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 455, '_step_count': 456, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.208627 valid_loss:0.203359 each epoch time:20.26810
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000154  valid_dq/boxsize 0.000152  train_dp 0.207628  valid_dp 0.202376 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:44:36
run time  0:01:42.549262
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_7/forward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_7/forward_7_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447757
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:44:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f02ebeffe50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 460, '_step_count': 461, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.164645 valid_loss:0.162376 each epoch time:20.14860
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000103  valid_dq/boxsize 0.000103  train_dp 0.163646  valid_dp 0.161584 reg_loss 0.002059
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:46:18
run time  0:01:40.611828
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_7/backward_7_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447774
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:46:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0bdb7880d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 465, '_step_count': 466, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.110111 valid_loss:0.106467 each epoch time:19.89456
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.109561  valid_dp 0.105934 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:47:59
run time  0:01:39.700746
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_7/backward_7_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447790
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:48:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f377cf56e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 470, '_step_count': 471, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.082508 valid_loss:0.083762 each epoch time:20.26280
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.082085  valid_dp 0.083328 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:49:42
run time  0:01:40.981834
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_7/backward_7_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447807
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:49:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f00efd510d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 475, '_step_count': 476, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.134224 valid_loss:0.132246 each epoch time:19.60946
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000071  train_dp 0.133578  valid_dp 0.131607 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:51:22
run time  0:01:38.834338
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_7/backward_7_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447824
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:51:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0013832850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 480, '_step_count': 481, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.081283 valid_loss:0.082587 each epoch time:19.53845
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.080864  valid_dp 0.082156 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:53:05
run time  0:01:39.541514
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_7/backward_7_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447842
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:53:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fac90a49490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 485, '_step_count': 486, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.107451 valid_loss:0.103920 each epoch time:19.73704
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.106902  valid_dp 0.103386 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 02:54:48
run time  0:01:39.938356
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_7/backward_7_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447859
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:54:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5c6a949d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 490, '_step_count': 491, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.080444 valid_loss:0.081762 each epoch time:19.80455
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.080012  valid_dp 0.081319 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:56:28
run time  0:01:39.224458
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_7/backward_7_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_7/backward_7_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447876
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:56:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efc0a096510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 495, '_step_count': 496, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.0001]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.106187 valid_loss:0.102725 each epoch time:19.76515
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.105647  valid_dp 0.102200 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 02:58:10
run time  0:01:39.718594
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_8/forward_8_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447893
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:58:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9315026390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 500, '_step_count': 501, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.079422 valid_loss:0.080784 each epoch time:20.05811
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.078997  valid_dp 0.080347 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 02:59:51
run time  0:01:40.456530
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_8/forward_8_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447910
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 02:59:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6c38d302d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 505, '_step_count': 506, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.130725 valid_loss:0.128811 each epoch time:20.03024
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000073  valid_dq/boxsize 0.000072  train_dp 0.130076  valid_dp 0.128169 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:01:33
run time  0:01:40.261207
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_8/forward_8_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447927
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:01:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efcaca250d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 510, '_step_count': 511, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.078594 valid_loss:0.079964 each epoch time:19.92075
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.078167  valid_dp 0.079526 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:03:16
run time  0:01:40.576692
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_8/forward_8_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447944
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:03:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0f35f20d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 515, '_step_count': 516, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.104151 valid_loss:0.100781 each epoch time:19.95902
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.103614  valid_dp 0.100258 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:04:58
run time  0:01:40.369359
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_8/forward_8_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447961
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:04:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4fecd5c210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 520, '_step_count': 521, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.156100 valid_loss:0.153967 each epoch time:20.37245
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000102  valid_dq/boxsize 0.000101  train_dp 0.155314  valid_dp 0.153187 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:06:39
run time  0:01:40.301865
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_8/forward_8_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447977
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:06:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f01bb556410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 525, '_step_count': 526, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.195270 valid_loss:0.190131 each epoch time:20.26179
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000150  valid_dq/boxsize 0.000148  train_dp 0.194293  valid_dp 0.189167 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:08:22
run time  0:01:41.966267
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_8/forward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_8/forward_8_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  447994
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:08:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5ee8eb6f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 530, '_step_count': 531, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.154390 valid_loss:0.152588 each epoch time:20.32306
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000104  valid_dq/boxsize 0.000104  train_dp 0.153545  valid_dp 0.151785 reg_loss 0.000442
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:10:05
run time  0:01:41.430638
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_8/backward_8_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448013
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:10:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fce91064490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 535, '_step_count': 536, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.102863 valid_loss:0.099468 each epoch time:19.48378
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000051  train_dp 0.102299  valid_dp 0.098918 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:11:46
run time  0:01:38.702708
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_8/backward_8_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448030
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:11:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd3436b0bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 540, '_step_count': 541, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.076988 valid_loss:0.078345 each epoch time:20.26715
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.076504  valid_dp 0.077888 reg_loss 0.000424
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:13:27
run time  0:01:39.397281
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_8/backward_8_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448048
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:13:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2e1346f810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 545, '_step_count': 546, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.126117 valid_loss:0.124307 each epoch time:20.01125
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000073  train_dp 0.125455  valid_dp 0.123653 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:15:07
run time  0:01:38.962474
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_8/backward_8_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448065
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:15:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1c2c1d3390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 550, '_step_count': 551, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.075978 valid_loss:0.077294 each epoch time:20.43166
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.075542  valid_dp 0.076846 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:16:50
run time  0:01:40.914088
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_8/backward_8_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448082
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:16:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb468e3ad50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 555, '_step_count': 556, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.100536 valid_loss:0.097276 each epoch time:20.08704
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.099991  valid_dp 0.096745 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:18:33
run time  0:01:41.229323
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_8/backward_8_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448102
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:18:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb2feee3710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 560, '_step_count': 561, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.075138 valid_loss:0.076495 each epoch time:19.64652
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.074705  valid_dp 0.076050 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:20:12
run time  0:01:38.279668
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_8/backward_8_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_8/backward_8_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448119
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:20:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2114a15d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 565, '_step_count': 566, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.099703 valid_loss:0.096484 each epoch time:19.88662
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.099159  valid_dp 0.095954 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:21:53
run time  0:01:39.742342
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_9/forward_9_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448136
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:21:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7effa5f62590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 570, '_step_count': 571, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.074456 valid_loss:0.075837 each epoch time:20.48613
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.074023  valid_dp 0.075391 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:23:39
run time  0:01:42.189935
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_9/forward_9_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448153
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:23:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc4c5d0db10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 575, '_step_count': 576, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.123471 valid_loss:0.121769 each epoch time:19.80032
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.122803  valid_dp 0.121108 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:25:20
run time  0:01:39.777483
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_9/forward_9_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448169
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:25:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f90aebb2bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 580, '_step_count': 581, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.074003 valid_loss:0.075361 each epoch time:19.83313
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.073559  valid_dp 0.074905 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:27:02
run time  0:01:40.369853
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_9/forward_9_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448186
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:27:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f768d5fc090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 585, '_step_count': 586, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.098307 valid_loss:0.095088 each epoch time:20.14150
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000050  train_dp 0.097755  valid_dp 0.094549 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:28:45
run time  0:01:39.840126
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_9/forward_9_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448213
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:28:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1fa95120d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 590, '_step_count': 591, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.147082 valid_loss:0.145305 each epoch time:20.31272
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000099  valid_dq/boxsize 0.000099  train_dp 0.146317  valid_dp 0.144543 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:30:26
run time  0:01:39.762668
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_9/forward_9_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448231
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:30:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbadb267190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 595, '_step_count': 596, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.184372 valid_loss:0.179467 each epoch time:20.25291
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000145  valid_dq/boxsize 0.000143  train_dp 0.183430  valid_dp 0.178537 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:32:10
run time  0:01:42.695763
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_9/forward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_9/forward_9_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448247
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:32:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd4842b7590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 600, '_step_count': 601, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.145671 valid_loss:0.143812 each epoch time:20.31106
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000101  valid_dq/boxsize 0.000101  train_dp 0.144776  valid_dp 0.143037 reg_loss 0.001164
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:33:53
run time  0:01:41.591173
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_9/backward_9_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448265
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:33:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2a1e1162d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 605, '_step_count': 606, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.096866 valid_loss:0.093676 each epoch time:20.30131
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.096309  valid_dp 0.093133 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:35:35
run time  0:01:40.345021
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_9/backward_9_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448281
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:35:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd3d6321450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 610, '_step_count': 611, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.072391 valid_loss:0.073660 each epoch time:19.58123
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.071949  valid_dp 0.073206 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:37:15
run time  0:01:39.508756
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_9/backward_9_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448298
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:37:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f616546c950>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 615, '_step_count': 616, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.119478 valid_loss:0.117762 each epoch time:20.64722
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000074  train_dp 0.118812  valid_dp 0.117103 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:38:57
run time  0:01:39.843362
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_9/backward_9_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448315
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:39:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa38b58e350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 620, '_step_count': 621, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.071766 valid_loss:0.073066 each epoch time:20.20773
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.071321  valid_dp 0.072609 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:40:39
run time  0:01:39.539543
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_9/backward_9_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448333
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:40:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb7cda73f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 625, '_step_count': 626, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.095251 valid_loss:0.092137 each epoch time:20.47454
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.094698  valid_dp 0.091597 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:42:23
run time  0:01:42.348164
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_9/backward_9_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448349
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:42:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1f86466190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 630, '_step_count': 631, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.071093 valid_loss:0.072428 each epoch time:19.46798
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.070650  valid_dp 0.071973 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:44:06
run time  0:01:39.530220
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_9/backward_9_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_9/backward_9_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448366
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:44:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe88d2de350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 635, '_step_count': 636, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.094674 valid_loss:0.091576 each epoch time:19.85615
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000051  train_dp 0.094112  valid_dp 0.091026 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:45:48
run time  0:01:40.788405
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_10/forward_10_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448383
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:45:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fadda893350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 640, '_step_count': 641, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.070584 valid_loss:0.071953 each epoch time:20.08445
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.070134  valid_dp 0.071491 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:47:30
run time  0:01:40.144283
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_10/forward_10_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448401
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:47:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efc908e84d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 645, '_step_count': 646, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.117198 valid_loss:0.115562 each epoch time:20.18418
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000073  train_dp 0.116537  valid_dp 0.114907 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:49:12
run time  0:01:40.588970
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_10/forward_10_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448417
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:49:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdf3a990dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 650, '_step_count': 651, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.070079 valid_loss:0.071430 each epoch time:20.20580
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.069631  valid_dp 0.070970 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 03:50:53
run time  0:01:40.497214
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_10/forward_10_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448435
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:50:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdfd14cb3d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 655, '_step_count': 656, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.093378 valid_loss:0.090335 each epoch time:20.24763
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.092822  valid_dp 0.089791 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:52:36
run time  0:01:41.013486
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_10/forward_10_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448452
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:52:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0212545b10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 660, '_step_count': 661, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.140416 valid_loss:0.138814 each epoch time:20.75504
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000102  valid_dq/boxsize 0.000101  train_dp 0.139634  valid_dp 0.138036 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:54:18
run time  0:01:40.673037
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_10/forward_10_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448470
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:54:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbb532ccf90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 665, '_step_count': 666, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.176375 valid_loss:0.171712 each epoch time:20.50566
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000144  valid_dq/boxsize 0.000142  train_dp 0.175442  valid_dp 0.170791 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:56:03
run time  0:01:43.767489
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_10/forward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_10/forward_10_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448486
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:56:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8c40ee7190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 670, '_step_count': 671, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.138967 valid_loss:0.137356 each epoch time:19.95182
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000100  train_dp 0.138194  valid_dp 0.136587 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 03:57:46
run time  0:01:42.168782
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_10/backward_10_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448503
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:57:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7eff7630ec10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 675, '_step_count': 676, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.092334 valid_loss:0.089289 each epoch time:19.56836
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.091776  valid_dp 0.088745 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 03:59:29
run time  0:01:39.522722
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_10/backward_10_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448520
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 03:59:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f71d9594190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 680, '_step_count': 681, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.068929 valid_loss:0.070185 each epoch time:19.92453
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.068484  valid_dp 0.069729 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:01:09
run time  0:01:38.819012
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_10/backward_10_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448537
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:01:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5520ab9d90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 685, '_step_count': 686, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.114146 valid_loss:0.112466 each epoch time:20.06216
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.113476  valid_dp 0.111804 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:02:51
run time  0:01:41.319524
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_10/backward_10_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448554
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:02:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f902d6f7290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 690, '_step_count': 691, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.068346 valid_loss:0.069670 each epoch time:19.44830
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.067894  valid_dp 0.069207 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:04:33
run time  0:01:40.459628
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_10/backward_10_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448571
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:04:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffa5a1ea510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 695, '_step_count': 696, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.090925 valid_loss:0.087946 each epoch time:19.48987
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.090365  valid_dp 0.087400 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:06:13
run time  0:01:39.240385
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_10/backward_10_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448588
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:06:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc4f95f5110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 700, '_step_count': 701, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.067771 valid_loss:0.069124 each epoch time:20.13056
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.067321  valid_dp 0.068662 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:07:54
run time  0:01:40.001086
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_10/backward_10_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_10/backward_10_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448605
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:07:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff261088b50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 705, '_step_count': 706, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.090726 valid_loss:0.087739 each epoch time:19.93757
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000053  train_dp 0.090149  valid_dp 0.087177 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:09:35
run time  0:01:39.680517
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_11/forward_11_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448621
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:09:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f862becdb10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 710, '_step_count': 711, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.067404 valid_loss:0.068770 each epoch time:19.88409
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.066945  valid_dp 0.068301 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:11:20
run time  0:01:40.493285
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_11/forward_11_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448638
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:11:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efc5e0a6610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 715, '_step_count': 716, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.112185 valid_loss:0.110590 each epoch time:20.09508
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.111518  valid_dp 0.109930 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:13:01
run time  0:01:40.307574
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_11/forward_11_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448655
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:13:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f28807a6c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 720, '_step_count': 721, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.066924 valid_loss:0.068297 each epoch time:19.75311
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.066469  valid_dp 0.067831 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:14:42
run time  0:01:39.385399
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_11/forward_11_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448671
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:14:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe2538ee4d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 725, '_step_count': 726, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.089371 valid_loss:0.086480 each epoch time:20.12089
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.088807  valid_dp 0.085929 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:16:27
run time  0:01:40.703578
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_11/forward_11_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448688
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:16:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fda6e3b0f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 730, '_step_count': 731, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.134416 valid_loss:0.132755 each epoch time:19.56900
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000099  valid_dq/boxsize 0.000099  train_dp 0.133651  valid_dp 0.131993 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:18:07
run time  0:01:38.718390
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_11/forward_11_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448709
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:18:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0085eb6290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 735, '_step_count': 736, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.169396 valid_loss:0.164749 each epoch time:20.43070
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000144  valid_dq/boxsize 0.000143  train_dp 0.168378  valid_dp 0.163822 reg_loss 0.000847
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:19:50
run time  0:01:41.949593
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_11/forward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_11/forward_11_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448726
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:19:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe884fbd410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 740, '_step_count': 741, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.133233 valid_loss:0.131659 each epoch time:20.19352
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000100  train_dp 0.132459  valid_dp 0.130890 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:21:32
run time  0:01:40.643724
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_11/backward_11_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448744
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:21:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb785c78250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 745, '_step_count': 746, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.088364 valid_loss:0.085510 each epoch time:19.92095
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000051  train_dp 0.087801  valid_dp 0.084960 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:23:16
run time  0:01:40.368399
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_11/backward_11_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448761
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:23:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdfacd23350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 750, '_step_count': 751, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.065893 valid_loss:0.067248 each epoch time:19.94966
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.065440  valid_dp 0.066784 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:24:59
run time  0:01:40.986170
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_11/backward_11_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448778
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:25:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe7257cbb10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 755, '_step_count': 756, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.109390 valid_loss:0.107925 each epoch time:20.26567
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.108722  valid_dp 0.107262 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:26:39
run time  0:01:39.429518
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_11/backward_11_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448795
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:26:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3f7c8b3050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 760, '_step_count': 761, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.065405 valid_loss:0.066783 each epoch time:19.57065
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.064948  valid_dp 0.066315 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:28:20
run time  0:01:38.030441
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_11/backward_11_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448812
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:28:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f762ca9c850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 765, '_step_count': 766, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.087174 valid_loss:0.084375 each epoch time:20.59892
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.086610  valid_dp 0.083824 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:30:03
run time  0:01:40.791149
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_11/backward_11_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448829
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:30:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6dfc8c59d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 770, '_step_count': 771, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.064927 valid_loss:0.066337 each epoch time:20.08307
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.064472  valid_dp 0.065869 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:31:46
run time  0:01:41.773723
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_11/backward_11_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_11/backward_11_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448846
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:31:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb2e0cde3d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 775, '_step_count': 776, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.086675 valid_loss:0.083910 each epoch time:19.62958
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.086112  valid_dp 0.083359 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:33:25
run time  0:01:38.245332
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_12/forward_12_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448863
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:33:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f695d4e3450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 780, '_step_count': 781, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.064515 valid_loss:0.065946 each epoch time:20.21546
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.064059  valid_dp 0.065478 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:35:07
run time  0:01:40.977399
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_12/forward_12_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448879
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:35:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feb32ba0a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 785, '_step_count': 786, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.107790 valid_loss:0.106304 each epoch time:20.28358
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.107121  valid_dp 0.105641 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:36:51
run time  0:01:41.072618
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_12/forward_12_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448895
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:36:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f74d4bd9690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 790, '_step_count': 791, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.064179 valid_loss:0.065655 each epoch time:19.16927
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.063720  valid_dp 0.065184 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:38:31
run time  0:01:38.327510
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_12/forward_12_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448915
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:38:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdf5c57a750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 795, '_step_count': 796, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.085890 valid_loss:0.083156 each epoch time:19.79050
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000053  train_dp 0.085316  valid_dp 0.082594 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:40:13
run time  0:01:40.167957
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_12/forward_12_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448933
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:40:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff24f9fd5d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 800, '_step_count': 801, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.129322 valid_loss:0.127745 each epoch time:20.11219
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000100  train_dp 0.128551  valid_dp 0.126976 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:41:54
run time  0:01:39.828601
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_12/forward_12_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448953
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:41:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0bd1fe5290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 805, '_step_count': 806, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.162844 valid_loss:0.158404 each epoch time:21.20399
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000142  valid_dq/boxsize 0.000141  train_dp 0.161921  valid_dp 0.157492 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:43:38
run time  0:01:43.027626
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_12/forward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_12/forward_12_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448970
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:43:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6351895e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 810, '_step_count': 811, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.128871 valid_loss:0.126926 each epoch time:20.32377
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000101  train_dp 0.127475  valid_dp 0.126150 reg_loss 0.006230
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:45:22
run time  0:01:42.213976
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_12/backward_12_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  448987
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:45:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd2564ef8d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 815, '_step_count': 816, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.085257 valid_loss:0.082564 each epoch time:19.90574
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000053  train_dp 0.084583  valid_dp 0.081998 reg_loss 0.000963
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:47:03
run time  0:01:39.945479
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_12/backward_12_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449004
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:47:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd7f5685fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 820, '_step_count': 821, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.063421 valid_loss:0.064742 each epoch time:19.70238
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.062955  valid_dp 0.064265 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:48:44
run time  0:01:39.848957
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_12/backward_12_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449022
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:48:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0aad89d690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 825, '_step_count': 826, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.105399 valid_loss:0.104018 each epoch time:19.97267
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.104728  valid_dp 0.103353 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:50:27
run time  0:01:40.402436
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_12/backward_12_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449039
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:50:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8107580610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 830, '_step_count': 831, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.062871 valid_loss:0.064239 each epoch time:19.86974
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.062410  valid_dp 0.063767 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 04:52:08
run time  0:01:40.047192
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_12/backward_12_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449057
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:52:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8bd402a3d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 835, '_step_count': 836, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.083891 valid_loss:0.081307 each epoch time:20.32398
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.083325  valid_dp 0.080753 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 04:53:52
run time  0:01:42.453652
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_12/backward_12_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449074
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:53:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc434d9e590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 840, '_step_count': 841, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.062427 valid_loss:0.063837 each epoch time:19.49000
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.061967  valid_dp 0.063366 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:55:33
run time  0:01:40.189837
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_12/backward_12_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_12/backward_12_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449092
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:55:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb2116315d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 845, '_step_count': 846, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.083437 valid_loss:0.080881 each epoch time:19.99617
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.082872  valid_dp 0.080328 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:57:14
run time  0:01:39.784611
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_13/forward_13_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449108
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:57:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f17346fd990>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 850, '_step_count': 851, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.062055 valid_loss:0.063490 each epoch time:19.95845
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.061596  valid_dp 0.063019 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 04:58:57
run time  0:01:40.928870
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_13/forward_13_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449126
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 04:58:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9f4a9da050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 855, '_step_count': 856, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.103919 valid_loss:0.102523 each epoch time:20.02211
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.103252  valid_dp 0.101862 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:00:40
run time  0:01:41.223967
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_13/forward_13_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449144
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:00:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f95590534d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 860, '_step_count': 861, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.061786 valid_loss:0.063229 each epoch time:20.41652
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.061326  valid_dp 0.062757 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:02:22
run time  0:01:40.222701
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_13/forward_13_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449160
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:02:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f60cd85d8d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 865, '_step_count': 866, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.082663 valid_loss:0.080146 each epoch time:20.19525
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.082099  valid_dp 0.079593 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:04:05
run time  0:01:41.546752
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_13/forward_13_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449177
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:04:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6d0ef57150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 870, '_step_count': 871, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.124830 valid_loss:0.123418 each epoch time:20.76114
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000100  train_dp 0.124061  valid_dp 0.122652 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:05:48
run time  0:01:41.490006
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_13/forward_13_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449193
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:05:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd97d80f090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 875, '_step_count': 876, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.157069 valid_loss:0.153324 each epoch time:20.28707
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000139  valid_dq/boxsize 0.000140  train_dp 0.156062  valid_dp 0.152414 reg_loss 0.001033
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:07:33
run time  0:01:43.720654
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_13/forward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_13/forward_13_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449210
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:07:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa3a984de50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 880, '_step_count': 881, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.123811 valid_loss:0.122437 each epoch time:19.88707
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000100  train_dp 0.123040  valid_dp 0.121670 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:09:15
run time  0:01:40.215754
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_13/backward_13_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449226
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:09:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f17ea2200d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 885, '_step_count': 886, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.081826 valid_loss:0.079322 each epoch time:20.08894
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.081259  valid_dp 0.078767 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:10:57
run time  0:01:40.417156
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_13/backward_13_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449244
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:10:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fae8666f4d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 890, '_step_count': 891, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.060964 valid_loss:0.062350 each epoch time:21.09044
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000037  train_dp 0.060502  valid_dp 0.061876 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:12:40
run time  0:01:42.582566
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_13/backward_13_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449261
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:12:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc28e8876d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 895, '_step_count': 896, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.101950 valid_loss:0.100562 each epoch time:20.04851
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.101276  valid_dp 0.099896 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:14:22
run time  0:01:40.237650
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_13/backward_13_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449279
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:14:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f091616d090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 900, '_step_count': 901, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.060675 valid_loss:0.062082 each epoch time:20.11669
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.060214  valid_dp 0.061609 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:16:06
run time  0:01:40.184710
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_13/backward_13_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449296
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:16:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f677e38ce10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 905, '_step_count': 906, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.081027 valid_loss:0.078566 each epoch time:20.55711
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.080462  valid_dp 0.078013 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:17:50
run time  0:01:42.303854
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_13/backward_13_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449315
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:17:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7d6d911690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 910, '_step_count': 911, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.060254 valid_loss:0.061685 each epoch time:20.53566
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.059795  valid_dp 0.061215 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:19:33
run time  0:01:41.398526
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_13/backward_13_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_13/backward_13_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449333
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:19:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc270e83790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 915, '_step_count': 916, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.080601 valid_loss:0.078174 each epoch time:19.70236
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.080038  valid_dp 0.077623 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:21:13
run time  0:01:39.045171
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_14/forward_14_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449350
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:21:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9fa96420d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 920, '_step_count': 921, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.059915 valid_loss:0.061365 each epoch time:20.12520
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.059458  valid_dp 0.060896 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:22:54
run time  0:01:39.517235
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_14/forward_14_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449367
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:22:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f50f15ec090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 925, '_step_count': 926, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.100448 valid_loss:0.099094 each epoch time:20.20132
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000073  train_dp 0.099786  valid_dp 0.098439 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:24:35
run time  0:01:40.541568
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_14/forward_14_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449384
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:24:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa942642390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 930, '_step_count': 931, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.059646 valid_loss:0.061093 each epoch time:19.78244
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.059189  valid_dp 0.060624 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:26:16
run time  0:01:39.683306
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_14/forward_14_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449400
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:26:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4e00e324d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 935, '_step_count': 936, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.079960 valid_loss:0.077563 each epoch time:20.25473
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.079390  valid_dp 0.077004 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:27:59
run time  0:01:41.208417
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_14/forward_14_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449417
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:28:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1a1c1ffa90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 940, '_step_count': 941, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.121223 valid_loss:0.119846 each epoch time:19.89516
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000101  valid_dq/boxsize 0.000101  train_dp 0.120443  valid_dp 0.119070 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:29:42
run time  0:01:41.411700
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_14/forward_14_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449434
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:29:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f43dbd02290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 945, '_step_count': 946, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.152603 valid_loss:0.148439 each epoch time:20.62034
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000140  valid_dq/boxsize 0.000138  train_dp 0.151635  valid_dp 0.147544 reg_loss 0.000623
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:31:26
run time  0:01:41.706770
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_14/forward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_14/forward_14_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449451
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:31:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f197f7ddb10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 950, '_step_count': 951, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.120069 valid_loss:0.118721 each epoch time:20.50393
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000100  valid_dq/boxsize 0.000099  train_dp 0.119303  valid_dp 0.117957 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:33:09
run time  0:01:41.529149
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_14/backward_14_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449468
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:33:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9a9664aa90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 955, '_step_count': 956, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.079308 valid_loss:0.076928 each epoch time:20.33228
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.078741  valid_dp 0.076373 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:34:52
run time  0:01:40.772809
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_14/backward_14_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449485
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:34:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f35031752d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 960, '_step_count': 961, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.058994 valid_loss:0.060370 each epoch time:20.22713
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.058535  valid_dp 0.059899 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:36:34
run time  0:01:40.551572
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_14/backward_14_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449503
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:36:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f99c3abc7d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 965, '_step_count': 966, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.098665 valid_loss:0.097340 each epoch time:20.28298
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000074  valid_dq/boxsize 0.000074  train_dp 0.098000  valid_dp 0.096682 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:38:17
run time  0:01:40.714494
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_14/backward_14_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449520
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:38:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe2c5d0b550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 970, '_step_count': 971, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.058649 valid_loss:0.060082 each epoch time:20.19305
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.058190  valid_dp 0.059611 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:40:00
run time  0:01:40.587556
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_14/backward_14_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449536
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:40:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa95d016390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 975, '_step_count': 976, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.078703 valid_loss:0.076343 each epoch time:19.72151
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000054  valid_dq/boxsize 0.000053  train_dp 0.078129  valid_dp 0.075781 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:41:40
run time  0:01:39.551769
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_14/backward_14_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449552
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:41:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f720a0e3650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 980, '_step_count': 981, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.058386 valid_loss:0.059843 each epoch time:19.93236
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000037  valid_dq/boxsize 0.000038  train_dp 0.057922  valid_dp 0.059369 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:43:22
run time  0:01:40.024915
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_14/backward_14_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_14/backward_14_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449568
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:43:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3652ca3150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 985, '_step_count': 986, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.078177 valid_loss:0.075894 each epoch time:19.99956
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.077611  valid_dp 0.075339 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:45:04
run time  0:01:40.411643
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_15/forward_15_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449585
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:45:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa569d5af90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 990, '_step_count': 991, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.058047 valid_loss:0.059507 each epoch time:20.00044
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.057586  valid_dp 0.059036 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:46:46
run time  0:01:39.998309
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_15/forward_15_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449602
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:46:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f74f0091e90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.8e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 995, '_step_count': 996, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.8e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.097555 valid_loss:0.096260 each epoch time:20.70381
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000075  valid_dq/boxsize 0.000074  train_dp 0.096888  valid_dp 0.095599 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:48:29
run time  0:01:42.051484
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_15/forward_15_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449619
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:48:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbe0a834f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1000, '_step_count': 1001, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.057794 valid_loss:0.059244 each epoch time:19.49419
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.057333  valid_dp 0.058771 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:50:11
run time  0:01:40.116388
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_15/forward_15_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449635
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:50:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f879c36e810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1005, '_step_count': 1006, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.077489 valid_loss:0.075247 each epoch time:19.92606
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000053  valid_dq/boxsize 0.000052  train_dp 0.076925  valid_dp 0.074694 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:51:51
run time  0:01:38.801111
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_15/forward_15_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449653
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:51:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feabf47f450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1010, '_step_count': 1011, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.117163 valid_loss:0.115755 each epoch time:20.28406
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000097  train_dp 0.116413  valid_dp 0.115007 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:53:35
run time  0:01:42.674074
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_15/forward_15_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449670
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:53:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1616f59290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1015, '_step_count': 1016, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.147826 valid_loss:0.143880 each epoch time:20.72697
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000136  valid_dq/boxsize 0.000134  train_dp 0.146946  valid_dp 0.143010 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 05:55:20
run time  0:01:43.767083
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_15/forward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_15/forward_15_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449687
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:55:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcc057c0a50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1020, '_step_count': 1021, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.116488 valid_loss:0.115128 each epoch time:21.11269
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000098  valid_dq/boxsize 0.000097  train_dp 0.115736  valid_dp 0.114379 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 05:57:07
run time  0:01:43.203288
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_15/backward_15_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449704
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:57:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd30360e510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1025, '_step_count': 1026, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.076843 valid_loss:0.074642 each epoch time:19.73598
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.076287  valid_dp 0.074098 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 05:58:48
run time  0:01:40.162571
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_15/backward_15_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449721
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 05:58:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6357327e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1030, '_step_count': 1031, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.057136 valid_loss:0.058526 each epoch time:20.06213
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.056685  valid_dp 0.058064 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:00:31
run time  0:01:41.615321
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_15/backward_15_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449737
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:00:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3330ddebd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1035, '_step_count': 1036, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.095737 valid_loss:0.094449 each epoch time:20.08833
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000073  valid_dq/boxsize 0.000072  train_dp 0.095085  valid_dp 0.093803 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:02:15
run time  0:01:40.428986
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_15/backward_15_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449754
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:02:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc41ba211d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1040, '_step_count': 1041, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056825 valid_loss:0.058255 each epoch time:20.19235
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.056374  valid_dp 0.057792 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:04:00
run time  0:01:40.561177
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_15/backward_15_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449771
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:04:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdce5604350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1045, '_step_count': 1046, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.076081 valid_loss:0.073924 each epoch time:19.98610
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.075527  valid_dp 0.073381 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:05:41
run time  0:01:40.419027
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_15/backward_15_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449789
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:05:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbc6beaa310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1050, '_step_count': 1051, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056518 valid_loss:0.057973 each epoch time:19.45116
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.056067  valid_dp 0.057511 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:07:20
run time  0:01:37.782461
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_15/backward_15_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_15/backward_15_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449805
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:07:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f25223532d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1055, '_step_count': 1056, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.075750 valid_loss:0.073625 each epoch time:19.74569
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.075197  valid_dp 0.073082 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:09:02
run time  0:01:40.607308
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_16/forward_16_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449824
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:09:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1d631f6f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1060, '_step_count': 1061, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056247 valid_loss:0.057721 each epoch time:19.35311
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.055796  valid_dp 0.057260 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:10:42
run time  0:01:38.425363
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_16/forward_16_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449840
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:10:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3b3fc2b410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1065, '_step_count': 1066, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.094599 valid_loss:0.093337 each epoch time:20.32023
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000072  train_dp 0.093952  valid_dp 0.092697 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:12:24
run time  0:01:41.058915
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_16/forward_16_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449856
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:12:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcc9c50a090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1070, '_step_count': 1071, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056047 valid_loss:0.057523 each epoch time:20.53508
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.055595  valid_dp 0.057060 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:14:10
run time  0:01:42.547353
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_16/forward_16_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449874
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:14:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f80001af250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1075, '_step_count': 1076, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.075171 valid_loss:0.073050 each epoch time:19.47516
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.074619  valid_dp 0.072509 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:15:51
run time  0:01:38.118973
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_16/forward_16_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449891
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:15:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff71b500510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1080, '_step_count': 1081, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.113848 valid_loss:0.112553 each epoch time:20.46410
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000096  valid_dq/boxsize 0.000096  train_dp 0.113108  valid_dp 0.111816 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:17:39
run time  0:01:44.410087
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_16/forward_16_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449937
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:17:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9d0137d350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1085, '_step_count': 1086, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.144205 valid_loss:0.140336 each epoch time:20.64259
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000136  valid_dq/boxsize 0.000134  train_dp 0.143322  valid_dp 0.139464 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:19:25
run time  0:01:44.665968
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_16/forward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_16/forward_16_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449954
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:19:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f17e637d950>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1090, '_step_count': 1091, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.113349 valid_loss:0.112092 each epoch time:20.52115
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000097  valid_dq/boxsize 0.000097  train_dp 0.112602  valid_dp 0.111348 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:21:07
run time  0:01:40.862325
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_16/backward_16_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449971
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:21:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb2248b4450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1095, '_step_count': 1096, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.074642 valid_loss:0.072567 each epoch time:19.96458
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000050  train_dp 0.074091  valid_dp 0.072028 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:22:48
run time  0:01:39.887520
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_16/backward_16_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  449987
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:22:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa065dc20d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1100, '_step_count': 1101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.055462 valid_loss:0.056899 each epoch time:20.17867
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.055015  valid_dp 0.056441 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:24:30
run time  0:01:40.391246
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_16/backward_16_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450004
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:24:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7c9eb91d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1105, '_step_count': 1106, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.093160 valid_loss:0.091909 each epoch time:20.39695
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000072  train_dp 0.092513  valid_dp 0.091267 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:26:11
run time  0:01:39.801910
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_16/backward_16_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450023
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:26:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe11c4bbe10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1110, '_step_count': 1111, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.055181 valid_loss:0.056644 each epoch time:19.91037
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.054734  valid_dp 0.056186 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:27:52
run time  0:01:40.376315
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_16/backward_16_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450039
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:27:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7875c00450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1115, '_step_count': 1116, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.074027 valid_loss:0.071975 each epoch time:20.10312
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.073470  valid_dp 0.071428 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:29:33
run time  0:01:39.584492
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_16/backward_16_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450055
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:29:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5439299ad0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1120, '_step_count': 1121, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.054927 valid_loss:0.056421 each epoch time:20.16805
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000036  valid_dq/boxsize 0.000037  train_dp 0.054476  valid_dp 0.055958 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:31:15
run time  0:01:40.963268
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_16/backward_16_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_16/backward_16_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450072
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:31:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4636c57490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1125, '_step_count': 1126, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.073670 valid_loss:0.071656 each epoch time:20.66801
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000052  valid_dq/boxsize 0.000051  train_dp 0.073118  valid_dp 0.071115 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:32:59
run time  0:01:41.522648
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_17/forward_17_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450089
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:33:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd612299f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1130, '_step_count': 1131, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.054666 valid_loss:0.056172 each epoch time:19.77258
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.054218  valid_dp 0.055712 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:34:40
run time  0:01:38.894603
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_17/forward_17_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450105
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:34:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9faadc1250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1135, '_step_count': 1136, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.092214 valid_loss:0.091006 each epoch time:20.19261
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000073  valid_dq/boxsize 0.000072  train_dp 0.091565  valid_dp 0.090363 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:36:21
run time  0:01:39.889643
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_17/forward_17_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450122
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:36:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8a2858e1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1140, '_step_count': 1141, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.054464 valid_loss:0.055998 each epoch time:20.15219
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.054016  valid_dp 0.055539 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:38:02
run time  0:01:40.406195
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_17/forward_17_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450139
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:38:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1883e69190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1145, '_step_count': 1146, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.073145 valid_loss:0.071172 each epoch time:20.05123
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.072596  valid_dp 0.070634 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:39:46
run time  0:01:40.938769
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_17/forward_17_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450156
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:39:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f133bfb8d90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1150, '_step_count': 1151, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.111017 valid_loss:0.109743 each epoch time:20.34086
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000096  valid_dq/boxsize 0.000096  train_dp 0.110277  valid_dp 0.109006 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:41:29
run time  0:01:41.443429
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_17/forward_17_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450172
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:41:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f264d657590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1155, '_step_count': 1156, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.140396 valid_loss:0.136683 each epoch time:19.87186
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000134  valid_dq/boxsize 0.000132  train_dp 0.139529  valid_dp 0.135826 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:43:11
run time  0:01:40.897781
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_17/forward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_17/forward_17_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450188
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:43:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f07434c0310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1160, '_step_count': 1161, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.110276 valid_loss:0.108979 each epoch time:20.60797
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000095  valid_dq/boxsize 0.000094  train_dp 0.109548  valid_dp 0.108253 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:44:55
run time  0:01:42.243670
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_17/backward_17_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450206
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:44:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa23fc852d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1165, '_step_count': 1166, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.072808 valid_loss:0.070862 each epoch time:20.27818
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.072262  valid_dp 0.070327 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:46:36
run time  0:01:40.575479
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_17/backward_17_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450223
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:46:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbf94e7ae50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1170, '_step_count': 1171, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.053993 valid_loss:0.055439 each epoch time:19.81133
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.053552  valid_dp 0.054988 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:48:17
run time  0:01:39.314553
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_17/backward_17_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450240
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:48:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f64b917d450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1175, '_step_count': 1176, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.090887 valid_loss:0.089602 each epoch time:19.94448
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000072  valid_dq/boxsize 0.000071  train_dp 0.090245  valid_dp 0.088968 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:50:00
run time  0:01:41.477733
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_17/backward_17_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450257
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:50:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd3111ecf90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1180, '_step_count': 1181, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.053760 valid_loss:0.055187 each epoch time:19.89590
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.053320  valid_dp 0.054736 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:51:42
run time  0:01:40.730959
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_17/backward_17_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450273
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:51:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7aba9193d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1185, '_step_count': 1186, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.072045 valid_loss:0.070189 each epoch time:20.13095
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.071504  valid_dp 0.069659 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:53:24
run time  0:01:40.919262
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_17/backward_17_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450289
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:53:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f89812da390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1190, '_step_count': 1191, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.053468 valid_loss:0.054921 each epoch time:20.46451
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.053029  valid_dp 0.054471 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 06:55:05
run time  0:01:40.357255
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_17/backward_17_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_17/backward_17_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450306
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:55:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6f1d1fbb10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1195, '_step_count': 1196, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.071785 valid_loss:0.069963 each epoch time:20.42494
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.071240  valid_dp 0.069429 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 06:56:48
run time  0:01:41.768633
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_18/forward_18_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450322
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:56:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f582c6a6a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1200, '_step_count': 1201, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.053251 valid_loss:0.054723 each epoch time:19.89649
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.052810  valid_dp 0.054271 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 06:58:31
run time  0:01:41.024568
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_18/forward_18_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450339
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 06:58:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdce318f850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1205, '_step_count': 1206, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.089806 valid_loss:0.088592 each epoch time:20.31317
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000071  valid_dq/boxsize 0.000070  train_dp 0.089173  valid_dp 0.087965 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:00:15
run time  0:01:43.145506
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_18/forward_18_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450355
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:00:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbc680b7d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1210, '_step_count': 1211, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.053016 valid_loss:0.054493 each epoch time:20.09925
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000035  train_dp 0.052579  valid_dp 0.054045 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:01:57
run time  0:01:40.315697
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_18/forward_18_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450371
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:01:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fef5a229290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1215, '_step_count': 1216, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.071199 valid_loss:0.069410 each epoch time:19.67961
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.070661  valid_dp 0.068883 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:03:39
run time  0:01:40.531448
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_18/forward_18_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450389
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:03:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f390433fa10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1220, '_step_count': 1221, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.108357 valid_loss:0.107091 each epoch time:19.96946
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000095  valid_dq/boxsize 0.000095  train_dp 0.107622  valid_dp 0.106359 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:05:22
run time  0:01:40.347719
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_18/forward_18_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450406
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:05:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff6a6bef490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1225, '_step_count': 1226, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.137461 valid_loss:0.133777 each epoch time:20.73708
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000134  valid_dq/boxsize 0.000133  train_dp 0.136555  valid_dp 0.132914 reg_loss 0.000333
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:07:08
run time  0:01:44.733540
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_18/forward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_18/forward_18_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450423
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:07:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7febea6b4510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1230, '_step_count': 1231, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.107648 valid_loss:0.106480 each epoch time:20.79945
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000095  valid_dq/boxsize 0.000095  train_dp 0.106918  valid_dp 0.105752 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:08:52
run time  0:01:42.338244
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_18/backward_18_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450440
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:08:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f91c4138a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1235, '_step_count': 1236, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.070719 valid_loss:0.068915 each epoch time:20.36400
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.070180  valid_dp 0.068386 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:10:35
run time  0:01:41.613386
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_18/backward_18_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450459
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:10:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdf819ddb10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1240, '_step_count': 1241, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.052515 valid_loss:0.053956 each epoch time:19.48687
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000035  train_dp 0.052077  valid_dp 0.053507 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:12:16
run time  0:01:39.959248
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_18/backward_18_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450475
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:12:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5cb682ec50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1245, '_step_count': 1246, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.088901 valid_loss:0.087693 each epoch time:19.58949
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000073  valid_dq/boxsize 0.000072  train_dp 0.088247  valid_dp 0.087046 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:13:57
run time  0:01:39.996496
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_18/backward_18_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450493
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:13:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7d59c34710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1250, '_step_count': 1251, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.052403 valid_loss:0.053886 each epoch time:20.19737
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.051956  valid_dp 0.053428 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:15:40
run time  0:01:41.266722
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_18/backward_18_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450509
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:15:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbe38562d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1255, '_step_count': 1256, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.070263 valid_loss:0.068471 each epoch time:19.89051
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000051  valid_dq/boxsize 0.000050  train_dp 0.069719  valid_dp 0.067938 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:17:21
run time  0:01:39.974955
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_18/backward_18_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450529
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:17:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3c8b8be790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1260, '_step_count': 1261, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.052103 valid_loss:0.053590 each epoch time:19.94087
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000036  train_dp 0.051663  valid_dp 0.053138 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:19:02
run time  0:01:40.383263
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_18/backward_18_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_18/backward_18_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450546
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:19:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5d22139e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1265, '_step_count': 1266, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.069952 valid_loss:0.068205 each epoch time:20.50174
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.069413  valid_dp 0.067677 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:20:45
run time  0:01:41.493946
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_19/forward_19_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450563
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:20:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1fd9942a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1270, '_step_count': 1271, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.051875 valid_loss:0.053370 each epoch time:20.41811
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000035  valid_dq/boxsize 0.000035  train_dp 0.051438  valid_dp 0.052922 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:22:28
run time  0:01:41.748258
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_19/forward_19_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450579
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:22:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd754273610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1275, '_step_count': 1276, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.087637 valid_loss:0.086521 each epoch time:20.04290
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000070  train_dp 0.087009  valid_dp 0.085898 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:24:11
run time  0:01:41.942132
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_19/forward_19_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450596
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:24:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff13172b410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1280, '_step_count': 1281, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.051663 valid_loss:0.053157 each epoch time:20.01645
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.051229  valid_dp 0.052712 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:25:52
run time  0:01:39.764336
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_19/forward_19_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450614
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:25:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7c0c099210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1285, '_step_count': 1286, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.069428 valid_loss:0.067714 each epoch time:19.48813
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.068895  valid_dp 0.067191 reg_loss 0.000000
memory usage : 3.6  at e= 5
end date/time : 20211025, 07:27:33
run time  0:01:39.651750
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_19/forward_19_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450631
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:27:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f748dec8b10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1290, '_step_count': 1291, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.105716 valid_loss:0.104553 each epoch time:20.33682
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000094  valid_dq/boxsize 0.000094  train_dp 0.104992  valid_dp 0.103831 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:29:17
run time  0:01:42.732777
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_19/forward_19_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450649
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:29:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2df1a142d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1295, '_step_count': 1296, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.133712 valid_loss:0.130081 each epoch time:20.87102
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000130  valid_dq/boxsize 0.000129  train_dp 0.132866  valid_dp 0.129245 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:31:03
run time  0:01:44.567910
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_19/forward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_19/forward_19_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450668
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:31:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f85c01e35d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1300, '_step_count': 1301, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.105194 valid_loss:0.104037 each epoch time:20.16439
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000094  valid_dq/boxsize 0.000094  train_dp 0.104471  valid_dp 0.103316 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:32:46
run time  0:01:41.552792
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_19/backward_19_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450690
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:32:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f41ba6b3c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1305, '_step_count': 1306, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.069015 valid_loss:0.067267 each epoch time:20.23186
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.068483  valid_dp 0.066746 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:34:26
run time  0:01:38.835215
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_19/backward_19_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450708
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:34:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7a51eb6250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1310, '_step_count': 1311, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.051216 valid_loss:0.052655 each epoch time:20.14739
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.050786  valid_dp 0.052214 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:36:07
run time  0:01:40.157321
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_19/backward_19_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450724
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:36:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f00a9f4ba10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1315, '_step_count': 1316, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.086359 valid_loss:0.085269 each epoch time:20.53421
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000069  valid_dq/boxsize 0.000069  train_dp 0.085738  valid_dp 0.084653 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:37:50
run time  0:01:41.968308
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_19/backward_19_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450741
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:37:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f17ce418310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1320, '_step_count': 1321, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.050967 valid_loss:0.052418 each epoch time:20.36153
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.050540  valid_dp 0.051980 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:39:33
run time  0:01:39.780770
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_19/backward_19_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450802
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:39:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f399fdac450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1325, '_step_count': 1326, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.068521 valid_loss:0.066811 each epoch time:19.77839
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.067985  valid_dp 0.066286 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:41:14
run time  0:01:39.675052
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_19/backward_19_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450818
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:41:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6de34f4390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1330, '_step_count': 1331, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.050782 valid_loss:0.052275 each epoch time:20.39518
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.050349  valid_dp 0.051830 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:42:57
run time  0:01:42.374500
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_19/backward_19_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_19/backward_19_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450835
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:42:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5a2c170d90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1335, '_step_count': 1336, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.068235 valid_loss:0.066553 each epoch time:20.14963
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000050  valid_dq/boxsize 0.000049  train_dp 0.067704  valid_dp 0.066032 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:44:39
run time  0:01:40.386293
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_20/forward_20_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450851
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:44:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7dcd7e24d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1340, '_step_count': 1341, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.050569 valid_loss:0.052073 each epoch time:20.30790
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.050139  valid_dp 0.051632 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:46:22
run time  0:01:41.282027
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_20/forward_20_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450867
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:46:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faa99d250d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1345, '_step_count': 1346, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.085687 valid_loss:0.084620 each epoch time:20.53146
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000070  valid_dq/boxsize 0.000069  train_dp 0.085061  valid_dp 0.083999 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:48:06
run time  0:01:41.432425
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_20/forward_20_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450886
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:48:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f03b1405dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1350, '_step_count': 1351, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.050408 valid_loss:0.051932 each epoch time:20.14421
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000035  train_dp 0.049978  valid_dp 0.051491 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:49:49
run time  0:01:40.196029
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_20/forward_20_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450903
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:49:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdbe4454550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1355, '_step_count': 1356, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.067807 valid_loss:0.066154 each epoch time:20.28977
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.067278  valid_dp 0.065636 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:51:32
run time  0:01:41.244743
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_20/forward_20_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450920
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:51:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f156247a410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1360, '_step_count': 1361, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.103207 valid_loss:0.102133 each epoch time:20.27977
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000092  valid_dq/boxsize 0.000092  train_dp 0.102497  valid_dp 0.101424 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:53:13
run time  0:01:40.105767
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_20/forward_20_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450937
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:53:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f64236f1150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1365, '_step_count': 1366, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.131267 valid_loss:0.127618 each epoch time:20.80477
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000131  valid_dq/boxsize 0.000129  train_dp 0.130419  valid_dp 0.126782 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 07:54:58
run time  0:01:43.319884
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_20/forward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_20/forward_20_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450954
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:54:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f11706ec350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1370, '_step_count': 1371, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.102712 valid_loss:0.101635 each epoch time:20.25679
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000092  valid_dq/boxsize 0.000092  train_dp 0.102005  valid_dp 0.100929 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 07:56:41
run time  0:01:42.200771
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_20/backward_20_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450971
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:56:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6772bc8150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1375, '_step_count': 1376, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.067359 valid_loss:0.065773 each epoch time:19.79319
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.066837  valid_dp 0.065263 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 07:58:23
run time  0:01:40.138685
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_20/backward_20_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  450988
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 07:58:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f655b66f350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1380, '_step_count': 1381, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.049964 valid_loss:0.051451 each epoch time:20.14276
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.049542  valid_dp 0.051019 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:00:06
run time  0:01:40.256774
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_20/backward_20_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451005
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:00:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f58e504e2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1385, '_step_count': 1386, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.084489 valid_loss:0.083479 each epoch time:19.84038
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000069  valid_dq/boxsize 0.000068  train_dp 0.083872  valid_dp 0.082868 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:01:47
run time  0:01:38.904339
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_20/backward_20_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451022
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:01:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7b77db6e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1390, '_step_count': 1391, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.049781 valid_loss:0.051286 each epoch time:19.85267
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.049358  valid_dp 0.050853 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:03:27
run time  0:01:39.563178
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_20/backward_20_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451039
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:03:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f68f3295f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1395, '_step_count': 1396, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.066872 valid_loss:0.065318 each epoch time:19.81719
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.066351  valid_dp 0.064808 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:05:14
run time  0:01:42.052584
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_20/backward_20_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451055
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:05:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f618d255190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1400, '_step_count': 1401, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.049554 valid_loss:0.051085 each epoch time:19.75577
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.049133  valid_dp 0.050653 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:06:59
run time  0:01:40.847079
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_20/backward_20_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_20/backward_20_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451072
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:07:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f92827c0410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1405, '_step_count': 1406, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.066794 valid_loss:0.065233 each epoch time:19.53509
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.066267  valid_dp 0.064717 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:08:41
run time  0:01:40.805370
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_21/forward_21_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451088
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:08:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0223064390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1410, '_step_count': 1411, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.049425 valid_loss:0.050974 each epoch time:19.56397
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000034  train_dp 0.049001  valid_dp 0.050539 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:10:22
run time  0:01:40.280682
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_21/forward_21_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451104
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:10:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f41e3739710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1415, '_step_count': 1416, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.083789 valid_loss:0.082771 each epoch time:20.05020
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000069  valid_dq/boxsize 0.000068  train_dp 0.083175  valid_dp 0.082163 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:12:07
run time  0:01:40.654494
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_21/forward_21_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451121
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:12:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f31cfa8a450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1420, '_step_count': 1421, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.049290 valid_loss:0.050841 each epoch time:19.83877
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000034  train_dp 0.048865  valid_dp 0.050405 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:13:49
run time  0:01:40.255580
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_21/forward_21_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451138
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:13:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faca1ee44d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1425, '_step_count': 1426, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.066291 valid_loss:0.064767 each epoch time:20.28883
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.065770  valid_dp 0.064256 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:15:34
run time  0:01:41.440125
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_21/forward_21_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451155
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:15:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f512d2ce510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1430, '_step_count': 1431, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.101357 valid_loss:0.100324 each epoch time:20.01746
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000093  valid_dq/boxsize 0.000093  train_dp 0.100643  valid_dp 0.099610 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:17:16
run time  0:01:41.421712
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_21/forward_21_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451175
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:17:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f481c908950>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1435, '_step_count': 1436, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.128424 valid_loss:0.124892 each epoch time:20.47757
optimizer lr 0.00010  boxsize 6.48886  train_dq/boxsize 0.000129  valid_dq/boxsize 0.000128  train_dp 0.127586  valid_dp 0.124063 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:19:03
run time  0:01:43.444706
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_21/forward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_21/forward_21_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451192
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:19:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f07270b8650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1440, '_step_count': 1441, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.100840 valid_loss:0.099804 each epoch time:20.70120
optimizer lr 0.00010  boxsize 7.69800  train_dq/boxsize 0.000093  valid_dq/boxsize 0.000093  train_dp 0.100126  valid_dp 0.099091 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:20:46
run time  0:01:41.905053
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_21/backward_21_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451208
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:20:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f31b2ad0f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1445, '_step_count': 1446, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.065917 valid_loss:0.064402 each epoch time:20.30812
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.065394  valid_dp 0.063889 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:22:28
run time  0:01:41.067420
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_21/backward_21_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451225
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:22:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff670fa1190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1450, '_step_count': 1451, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048864 valid_loss:0.050388 each epoch time:20.32251
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.048442  valid_dp 0.049956 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:24:10
run time  0:01:41.032565
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_21/backward_21_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451243
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:24:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb4bb1fc450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1455, '_step_count': 1456, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.082822 valid_loss:0.081860 each epoch time:20.65796
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000069  valid_dq/boxsize 0.000069  train_dp 0.082201  valid_dp 0.081244 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:25:53
run time  0:01:41.737758
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_21/backward_21_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451260
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:25:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4e95997090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1460, '_step_count': 1461, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048686 valid_loss:0.050239 each epoch time:20.19668
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000034  valid_dq/boxsize 0.000034  train_dp 0.048263  valid_dp 0.049804 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:27:38
run time  0:01:40.818751
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_21/backward_21_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451277
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:27:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f17c0a0d550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1465, '_step_count': 1466, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.065409 valid_loss:0.063923 each epoch time:20.41946
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000048  train_dp 0.064889  valid_dp 0.063413 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:29:20
run time  0:01:40.692240
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_21/backward_21_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451295
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:29:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f42bf533bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1470, '_step_count': 1471, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048522 valid_loss:0.050099 each epoch time:19.92028
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.048099  valid_dp 0.049665 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:31:02
run time  0:01:40.345675
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_21/backward_21_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_21/backward_21_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451313
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:31:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa6192353d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1475, '_step_count': 1476, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.065215 valid_loss:0.063731 each epoch time:19.47532
optimizer lr 0.00010  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000048  train_dp 0.064696  valid_dp 0.063223 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:32:42
run time  0:01:39.167156
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_22/forward_22_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451330
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:32:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f44f71f7a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1480, '_step_count': 1481, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048297 valid_loss:0.049883 each epoch time:20.47107
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.047879  valid_dp 0.049455 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:34:26
run time  0:01:41.039308
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_22/forward_22_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451346
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:34:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f16b8b68550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1485, '_step_count': 1486, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.082032 valid_loss:0.081092 each epoch time:20.15752
optimizer lr 0.00010  boxsize 8.94427  train_dq/boxsize 0.000068  valid_dq/boxsize 0.000068  train_dp 0.081422  valid_dp 0.080487 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:36:09
run time  0:01:41.086080
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_22/forward_22_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451365
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:36:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1237a3f210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1490, '_step_count': 1491, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048151 valid_loss:0.049752 each epoch time:20.16668
optimizer lr 0.00010  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.047735  valid_dp 0.049324 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:37:50
run time  0:01:40.254619
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_22/forward_22_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451382
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:37:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdd3b23ee90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.604e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1495, '_step_count': 1496, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.604e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.064808 valid_loss:0.063349 each epoch time:20.00763
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.064294  valid_dp 0.062846 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:39:34
run time  0:01:41.145230
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_22/forward_22_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451400
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:39:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4161830050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1500, '_step_count': 1501, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.098847 valid_loss:0.097861 each epoch time:20.59002
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000090  valid_dq/boxsize 0.000090  train_dp 0.098155  valid_dp 0.097170 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:41:16
run time  0:01:41.039288
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_22/forward_22_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451417
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:41:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efe58ba4f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1505, '_step_count': 1506, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.126566 valid_loss:0.122979 each epoch time:20.90823
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000130  valid_dq/boxsize 0.000128  train_dp 0.125723  valid_dp 0.122149 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:43:01
run time  0:01:44.180319
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_22/forward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_22/forward_22_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451434
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:43:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb22b2e2190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1510, '_step_count': 1511, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.098614 valid_loss:0.097618 each epoch time:20.17631
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000091  valid_dq/boxsize 0.000090  train_dp 0.097917  valid_dp 0.096923 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 08:44:45
run time  0:01:42.652759
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_22/backward_22_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451452
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:44:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f021022b550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1515, '_step_count': 1516, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.064543 valid_loss:0.063064 each epoch time:20.29066
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000049  valid_dq/boxsize 0.000047  train_dp 0.064024  valid_dp 0.062556 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:46:27
run time  0:01:40.583044
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_22/backward_22_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451469
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:46:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff279e19b90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1520, '_step_count': 1521, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047812 valid_loss:0.049408 each epoch time:19.90495
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.047395  valid_dp 0.048980 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:48:11
run time  0:01:41.934337
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_22/backward_22_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451485
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:48:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6f981dd050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1525, '_step_count': 1526, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.080946 valid_loss:0.080052 each epoch time:20.38276
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000068  valid_dq/boxsize 0.000067  train_dp 0.080342  valid_dp 0.079452 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:49:54
run time  0:01:40.950866
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_22/backward_22_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451501
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:49:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb0f2330250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1530, '_step_count': 1531, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047591 valid_loss:0.049193 each epoch time:20.12527
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000034  train_dp 0.047178  valid_dp 0.048770 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:51:36
run time  0:01:40.982155
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_22/backward_22_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451519
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:51:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff8421022d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1535, '_step_count': 1536, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.064000 valid_loss:0.062560 each epoch time:20.32626
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.063490  valid_dp 0.062060 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:53:19
run time  0:01:41.021096
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_22/backward_22_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451536
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:53:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7aa6767050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1540, '_step_count': 1541, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047402 valid_loss:0.049022 each epoch time:20.35252
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000033  valid_dq/boxsize 0.000033  train_dp 0.046990  valid_dp 0.048600 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:55:02
run time  0:01:41.347685
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_22/backward_22_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_22/backward_22_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451554
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:55:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faec7225410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1545, '_step_count': 1546, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.063789 valid_loss:0.062373 each epoch time:20.18188
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000048  valid_dq/boxsize 0.000047  train_dp 0.063280  valid_dp 0.061874 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 08:56:43
run time  0:01:40.559350
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_23/forward_23_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451571
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:56:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2bca46e3d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1550, '_step_count': 1551, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047233 valid_loss:0.048868 each epoch time:20.03905
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.046822  valid_dp 0.048446 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 08:58:24
run time  0:01:39.159311
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_23/forward_23_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451588
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 08:58:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcb5881b5d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1555, '_step_count': 1556, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.080320 valid_loss:0.079446 each epoch time:20.06087
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000067  valid_dq/boxsize 0.000067  train_dp 0.079717  valid_dp 0.078849 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:00:06
run time  0:01:41.021170
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_23/forward_23_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451605
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:00:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6c23fad690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1560, '_step_count': 1561, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047107 valid_loss:0.048762 each epoch time:20.14891
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.046696  valid_dp 0.048340 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:01:48
run time  0:01:40.635953
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_23/forward_23_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451621
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:01:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f82b8279650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1565, '_step_count': 1566, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.063451 valid_loss:0.062059 each epoch time:20.08510
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000047  train_dp 0.062943  valid_dp 0.061562 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:03:30
run time  0:01:40.423889
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_23/forward_23_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451638
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:03:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff2417b9d90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1570, '_step_count': 1571, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.097091 valid_loss:0.096207 each epoch time:20.60285
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000090  valid_dq/boxsize 0.000090  train_dp 0.096372  valid_dp 0.095516 reg_loss 0.000282
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:05:13
run time  0:01:41.526802
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_23/forward_23_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451655
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:05:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2a5ead0350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1575, '_step_count': 1576, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.123132 valid_loss:0.119794 each epoch time:20.49916
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000125  valid_dq/boxsize 0.000123  train_dp 0.122322  valid_dp 0.118993 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:06:57
run time  0:01:43.214565
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_23/forward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_23/forward_23_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451672
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:06:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2232b19e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1580, '_step_count': 1581, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.096509 valid_loss:0.095623 each epoch time:20.27098
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000089  valid_dq/boxsize 0.000088  train_dp 0.095828  valid_dp 0.094942 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:08:41
run time  0:01:42.583879
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_23/backward_23_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451688
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:08:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2bf1310ed0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1585, '_step_count': 1586, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.063113 valid_loss:0.061720 each epoch time:20.15494
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.062614  valid_dp 0.061231 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:10:28
run time  0:01:42.714204
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_23/backward_23_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451705
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:10:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f183adbb510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1590, '_step_count': 1591, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046769 valid_loss:0.048384 each epoch time:20.10059
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.046367  valid_dp 0.047971 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:12:12
run time  0:01:40.625925
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_23/backward_23_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451722
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:12:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f56c331e1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1595, '_step_count': 1596, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.079265 valid_loss:0.078386 each epoch time:20.84591
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000066  valid_dq/boxsize 0.000065  train_dp 0.078675  valid_dp 0.077801 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:13:54
run time  0:01:40.891158
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_23/backward_23_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451738
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:13:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2feaec54d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1600, '_step_count': 1601, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046568 valid_loss:0.048193 each epoch time:20.06082
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.046167  valid_dp 0.047781 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:15:38
run time  0:01:41.331471
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_23/backward_23_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451756
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:15:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feaf8efb550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1605, '_step_count': 1606, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.062822 valid_loss:0.061437 each epoch time:20.03688
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.062316  valid_dp 0.060942 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:17:20
run time  0:01:40.861795
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_23/backward_23_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451777
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:17:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3ff9acb350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1610, '_step_count': 1611, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046461 valid_loss:0.048100 each epoch time:19.90543
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.046055  valid_dp 0.047684 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:19:01
run time  0:01:39.380610
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_23/backward_23_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_23/backward_23_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451794
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:19:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff039b5c750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1615, '_step_count': 1616, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.062534 valid_loss:0.061191 each epoch time:19.96621
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.062033  valid_dp 0.060700 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:20:43
run time  0:01:40.729442
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_24/forward_24_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451811
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:20:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f84caaed050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1620, '_step_count': 1621, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046275 valid_loss:0.047925 each epoch time:20.33236
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.045871  valid_dp 0.047511 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:22:24
run time  0:01:40.359367
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_24/forward_24_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451828
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:22:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6294153610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1625, '_step_count': 1626, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.078898 valid_loss:0.077989 each epoch time:20.61895
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000067  valid_dq/boxsize 0.000066  train_dp 0.078301  valid_dp 0.077396 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:24:09
run time  0:01:43.306307
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_24/forward_24_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451845
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:24:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd258aa5d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1630, '_step_count': 1631, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046155 valid_loss:0.047810 each epoch time:19.90861
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.045750  valid_dp 0.047394 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:25:51
run time  0:01:41.029493
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_24/forward_24_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451862
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:25:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1f084e3ad0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1635, '_step_count': 1636, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.062188 valid_loss:0.060843 each epoch time:20.68502
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.061687  valid_dp 0.060353 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:27:34
run time  0:01:42.431867
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_24/forward_24_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451878
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:27:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa50c7ce490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1640, '_step_count': 1641, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.095186 valid_loss:0.094269 each epoch time:20.04615
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000089  valid_dq/boxsize 0.000089  train_dp 0.094503  valid_dp 0.093587 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:29:20
run time  0:01:42.382439
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_24/forward_24_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451895
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:29:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2bb5dac390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1645, '_step_count': 1646, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.121580 valid_loss:0.118197 each epoch time:21.21748
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000127  valid_dq/boxsize 0.000125  train_dp 0.120760  valid_dp 0.117386 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:31:07
run time  0:01:45.718249
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_24/forward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_24/forward_24_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451914
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:31:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2d49c496d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1650, '_step_count': 1651, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.094768 valid_loss:0.093983 each epoch time:21.07345
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000088  valid_dq/boxsize 0.000088  train_dp 0.094087  valid_dp 0.093303 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:32:51
run time  0:01:42.997600
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_24/backward_24_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451932
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:32:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd910e7cf90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1655, '_step_count': 1656, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.061910 valid_loss:0.060619 each epoch time:20.66533
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.061412  valid_dp 0.060130 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:34:34
run time  0:01:41.314108
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_24/backward_24_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451951
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:34:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0cae4cc390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1660, '_step_count': 1661, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045837 valid_loss:0.047443 each epoch time:20.34023
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000032  train_dp 0.045437  valid_dp 0.047032 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:36:16
run time  0:01:41.185114
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_24/backward_24_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451968
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:36:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff1cc26a150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1665, '_step_count': 1666, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.077874 valid_loss:0.077022 each epoch time:20.26830
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000066  valid_dq/boxsize 0.000065  train_dp 0.077283  valid_dp 0.076437 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:37:59
run time  0:01:41.681783
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_24/backward_24_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  451984
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:38:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f349f5125d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1670, '_step_count': 1671, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045667 valid_loss:0.047290 each epoch time:20.28139
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000032  train_dp 0.045266  valid_dp 0.046879 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:39:40
run time  0:01:40.481429
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_24/backward_24_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452002
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:39:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1cf391d9d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1675, '_step_count': 1676, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.061595 valid_loss:0.060348 each epoch time:19.57676
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.061092  valid_dp 0.059856 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:41:23
run time  0:01:41.587381
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_24/backward_24_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452018
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:41:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feb38002390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1680, '_step_count': 1681, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045559 valid_loss:0.047213 each epoch time:19.88132
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000033  train_dp 0.045157  valid_dp 0.046800 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:43:06
run time  0:01:41.561750
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_24/backward_24_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_24/backward_24_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452035
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:43:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f038a765bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1685, '_step_count': 1686, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.061373 valid_loss:0.060150 each epoch time:20.01666
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.060875  valid_dp 0.059662 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:44:48
run time  0:01:41.177477
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_25/forward_25_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452052
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:44:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff822868e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1690, '_step_count': 1691, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045363 valid_loss:0.047033 each epoch time:20.38960
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000032  train_dp 0.044963  valid_dp 0.046623 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:46:34
run time  0:01:43.480759
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_25/forward_25_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452069
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:46:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4e109dc850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1695, '_step_count': 1696, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.077453 valid_loss:0.076564 each epoch time:20.01647
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000066  valid_dq/boxsize 0.000065  train_dp 0.076862  valid_dp 0.075979 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:48:18
run time  0:01:40.091546
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_25/forward_25_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452087
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:48:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f348e577b10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1700, '_step_count': 1701, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045268 valid_loss:0.046949 each epoch time:20.27477
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000032  train_dp 0.044869  valid_dp 0.046539 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:50:04
run time  0:01:42.300963
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_25/forward_25_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452104
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:50:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0a7a1952d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1705, '_step_count': 1706, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.061044 valid_loss:0.059815 each epoch time:20.57035
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000046  valid_dq/boxsize 0.000045  train_dp 0.060549  valid_dp 0.059330 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:51:49
run time  0:01:40.571928
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_25/forward_25_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452121
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:51:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f465ac1b9d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1710, '_step_count': 1711, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.093959 valid_loss:0.093109 each epoch time:19.70559
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000090  valid_dq/boxsize 0.000090  train_dp 0.093266  valid_dp 0.092418 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 09:53:30
run time  0:01:40.504858
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_25/forward_25_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452138
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:53:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f59912429d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1715, '_step_count': 1716, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.119416 valid_loss:0.116067 each epoch time:20.27256
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000126  valid_dq/boxsize 0.000124  train_dp 0.118600  valid_dp 0.115262 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:55:15
run time  0:01:43.742722
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_25/forward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_25/forward_25_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452155
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:55:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5c63cb9ed0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1720, '_step_count': 1721, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.093269 valid_loss:0.092413 each epoch time:19.77523
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000089  valid_dq/boxsize 0.000089  train_dp 0.092587  valid_dp 0.091732 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 09:56:59
run time  0:01:39.534558
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_25/backward_25_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452172
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:57:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb916c47590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1725, '_step_count': 1726, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.060780 valid_loss:0.059569 each epoch time:20.34251
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.060283  valid_dp 0.059082 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 09:58:43
run time  0:01:41.988184
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_25/backward_25_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452188
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 09:58:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f01d44af4d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1730, '_step_count': 1731, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044966 valid_loss:0.046568 each epoch time:20.90162
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000032  valid_dq/boxsize 0.000032  train_dp 0.044567  valid_dp 0.046158 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:00:25
run time  0:01:41.109611
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_25/backward_25_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452205
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:00:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f31882e1e50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1735, '_step_count': 1736, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.076581 valid_loss:0.075734 each epoch time:20.56402
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000066  valid_dq/boxsize 0.000065  train_dp 0.075993  valid_dp 0.075152 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:02:09
run time  0:01:42.657340
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_25/backward_25_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452224
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:02:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f31cd147bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1740, '_step_count': 1741, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044817 valid_loss:0.046438 each epoch time:20.04150
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.044420  valid_dp 0.046030 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:03:53
run time  0:01:42.241759
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_25/backward_25_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452241
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:03:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f305195c410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1745, '_step_count': 1746, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.060375 valid_loss:0.059192 each epoch time:20.84741
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000046  valid_dq/boxsize 0.000045  train_dp 0.059882  valid_dp 0.058709 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:05:37
run time  0:01:42.143217
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_25/backward_25_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452257
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:05:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe59656c690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1750, '_step_count': 1751, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044644 valid_loss:0.046279 each epoch time:20.24509
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.044249  valid_dp 0.045873 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:07:19
run time  0:01:41.486612
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_25/backward_25_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_25/backward_25_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452274
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:07:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f87e71a47d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1755, '_step_count': 1756, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.060183 valid_loss:0.059020 each epoch time:20.31200
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000046  valid_dq/boxsize 0.000045  train_dp 0.059692  valid_dp 0.058538 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:09:02
run time  0:01:41.575560
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_26/forward_26_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452291
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:09:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f670b8d3250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1760, '_step_count': 1761, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044494 valid_loss:0.046143 each epoch time:20.33834
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.044100  valid_dp 0.045738 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:10:46
run time  0:01:42.210939
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_26/forward_26_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452308
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:10:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f080e51ce10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1765, '_step_count': 1766, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.076023 valid_loss:0.075196 each epoch time:20.30770
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000066  valid_dq/boxsize 0.000065  train_dp 0.075436  valid_dp 0.074614 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:12:29
run time  0:01:42.496559
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_26/forward_26_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452326
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:12:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f57e2416f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1770, '_step_count': 1771, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044388 valid_loss:0.046053 each epoch time:19.88411
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.043992  valid_dp 0.045646 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:14:13
run time  0:01:40.936741
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_26/forward_26_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452342
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:14:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7facf42bf310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1775, '_step_count': 1776, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.059888 valid_loss:0.058735 each epoch time:19.89348
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000046  valid_dq/boxsize 0.000045  train_dp 0.059397  valid_dp 0.058254 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:15:56
run time  0:01:40.671096
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_26/forward_26_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452358
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:15:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbb85f1f1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1780, '_step_count': 1781, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.091868 valid_loss:0.091041 each epoch time:20.65515
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000087  valid_dq/boxsize 0.000087  train_dp 0.091195  valid_dp 0.090369 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:17:39
run time  0:01:42.688225
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_26/forward_26_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452377
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:17:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6756ac4710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1785, '_step_count': 1786, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.117109 valid_loss:0.113834 each epoch time:20.85292
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000123  valid_dq/boxsize 0.000122  train_dp 0.116310  valid_dp 0.113045 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:19:25
run time  0:01:44.180554
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_26/forward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_26/forward_26_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452394
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:19:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd8075120d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1790, '_step_count': 1791, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.091484 valid_loss:0.090671 each epoch time:19.77011
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000087  valid_dq/boxsize 0.000087  train_dp 0.090815  valid_dp 0.090003 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:21:06
run time  0:01:39.984281
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_26/backward_26_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452411
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:21:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f35f9a0ff50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1795, '_step_count': 1796, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.059776 valid_loss:0.058624 each epoch time:20.30893
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000047  valid_dq/boxsize 0.000046  train_dp 0.059278  valid_dp 0.058136 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:22:48
run time  0:01:41.108980
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_26/backward_26_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452428
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:22:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5d2e8dae90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1800, '_step_count': 1801, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044144 valid_loss:0.045796 each epoch time:19.86978
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.043748  valid_dp 0.045389 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:24:33
run time  0:01:40.918020
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_26/backward_26_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452445
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:24:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f202fc04150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1805, '_step_count': 1806, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.075272 valid_loss:0.074535 each epoch time:20.00842
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000065  valid_dq/boxsize 0.000065  train_dp 0.074687  valid_dp 0.073954 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:26:13
run time  0:01:39.298420
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_26/backward_26_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452462
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:26:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feb636a0050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1810, '_step_count': 1811, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.043978 valid_loss:0.045648 each epoch time:20.95138
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.043584  valid_dp 0.045242 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:27:56
run time  0:01:42.249103
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_26/backward_26_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452504
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:27:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2215b00ad0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1815, '_step_count': 1816, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.059274 valid_loss:0.058156 each epoch time:20.33245
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000046  valid_dq/boxsize 0.000045  train_dp 0.058784  valid_dp 0.057675 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:29:38
run time  0:01:40.712685
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_26/backward_26_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452521
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:29:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9860382d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1820, '_step_count': 1821, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.043816 valid_loss:0.045490 each epoch time:20.09925
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.043423  valid_dp 0.045086 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:31:20
run time  0:01:40.075504
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_26/backward_26_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_26/backward_26_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452541
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:31:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe44f3720d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1825, '_step_count': 1826, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.059090 valid_loss:0.057992 each epoch time:20.45079
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000046  valid_dq/boxsize 0.000045  train_dp 0.058602  valid_dp 0.057514 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:33:03
run time  0:01:41.812367
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_27/forward_27_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452558
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:33:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa94df86950>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1830, '_step_count': 1831, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.043674 valid_loss:0.045355 each epoch time:20.70940
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.043283  valid_dp 0.044954 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:34:46
run time  0:01:41.701748
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_27/forward_27_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452575
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:34:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff6c95294d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1835, '_step_count': 1836, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.074697 valid_loss:0.073982 each epoch time:20.19907
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000065  valid_dq/boxsize 0.000064  train_dp 0.074118  valid_dp 0.073407 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:36:29
run time  0:01:40.592307
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_27/forward_27_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452591
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:36:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdcefabf650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1840, '_step_count': 1841, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.043572 valid_loss:0.045258 each epoch time:20.17642
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000032  train_dp 0.043182  valid_dp 0.044857 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:38:13
run time  0:01:40.141340
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_27/forward_27_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452608
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:38:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f606d55b650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1845, '_step_count': 1846, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.058974 valid_loss:0.057875 each epoch time:20.19184
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000046  valid_dq/boxsize 0.000045  train_dp 0.058482  valid_dp 0.057393 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:39:54
run time  0:01:39.633328
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_27/forward_27_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452626
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:39:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc855238c10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1850, '_step_count': 1851, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.090381 valid_loss:0.089596 each epoch time:20.01156
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000087  valid_dq/boxsize 0.000087  train_dp 0.089714  valid_dp 0.088930 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:41:37
run time  0:01:41.544371
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_27/forward_27_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452643
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:41:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f400c31e650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1855, '_step_count': 1856, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.115533 valid_loss:0.112450 each epoch time:20.79368
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000123  valid_dq/boxsize 0.000123  train_dp 0.114319  valid_dp 0.111653 reg_loss 0.004183
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:43:25
run time  0:01:44.126411
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_27/forward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_27/forward_27_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452661
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:43:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4eae7c3610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1860, '_step_count': 1861, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.089938 valid_loss:0.089165 each epoch time:19.63880
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000087  valid_dq/boxsize 0.000087  train_dp 0.089271  valid_dp 0.088499 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 10:45:10
run time  0:01:41.617362
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_27/backward_27_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452677
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:45:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8238986a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1865, '_step_count': 1866, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.058491 valid_loss:0.057396 each epoch time:20.45001
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000045  valid_dq/boxsize 0.000044  train_dp 0.058007  valid_dp 0.056922 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:46:51
run time  0:01:39.818052
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_27/backward_27_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452693
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:46:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7eff0c314610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1870, '_step_count': 1871, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.043280 valid_loss:0.044926 each epoch time:20.19614
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000031  valid_dq/boxsize 0.000031  train_dp 0.042892  valid_dp 0.044527 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:48:35
run time  0:01:41.968105
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_27/backward_27_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452710
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:48:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2327499310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1875, '_step_count': 1876, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.073796 valid_loss:0.073107 each epoch time:20.47714
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000064  valid_dq/boxsize 0.000064  train_dp 0.073224  valid_dp 0.072539 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:50:18
run time  0:01:42.337401
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_27/backward_27_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452729
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:50:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f89a0185250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1880, '_step_count': 1881, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.043122 valid_loss:0.044781 each epoch time:20.33522
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.042737  valid_dp 0.044385 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:52:02
run time  0:01:41.405115
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_27/backward_27_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452746
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:52:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7eff21fe38d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1885, '_step_count': 1886, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.058129 valid_loss:0.057060 each epoch time:19.66713
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000045  valid_dq/boxsize 0.000044  train_dp 0.057648  valid_dp 0.056589 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:53:43
run time  0:01:40.228285
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_27/backward_27_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452763
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:53:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f154697e090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1890, '_step_count': 1891, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.042980 valid_loss:0.044655 each epoch time:19.98506
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.042595  valid_dp 0.044259 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:55:28
run time  0:01:41.127424
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_27/backward_27_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_27/backward_27_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452780
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:55:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6b3d459350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1895, '_step_count': 1896, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.057970 valid_loss:0.056926 each epoch time:20.03862
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000045  valid_dq/boxsize 0.000044  train_dp 0.057490  valid_dp 0.056455 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 10:57:09
run time  0:01:40.446755
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_28/forward_28_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452797
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:57:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe7a48d17d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1900, '_step_count': 1901, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.042853 valid_loss:0.044541 each epoch time:19.87453
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.042469  valid_dp 0.044146 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 10:58:54
run time  0:01:41.399554
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_28/forward_28_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452814
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 10:58:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f66e0c1a450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1905, '_step_count': 1906, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.073455 valid_loss:0.072767 each epoch time:20.03022
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000064  valid_dq/boxsize 0.000064  train_dp 0.072881  valid_dp 0.072198 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:00:36
run time  0:01:41.280542
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_28/forward_28_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452830
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:00:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbcba648550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1910, '_step_count': 1911, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.042806 valid_loss:0.044495 each epoch time:20.09522
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.042421  valid_dp 0.044099 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:02:18
run time  0:01:40.712187
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_28/forward_28_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452848
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:02:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb009c7ed10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1915, '_step_count': 1916, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.057744 valid_loss:0.056703 each epoch time:20.43176
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000045  valid_dq/boxsize 0.000044  train_dp 0.057265  valid_dp 0.056234 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:04:01
run time  0:01:41.621488
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_28/forward_28_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452864
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:04:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f53c3e664d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1920, '_step_count': 1921, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.088803 valid_loss:0.088028 each epoch time:20.01321
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000086  valid_dq/boxsize 0.000086  train_dp 0.088142  valid_dp 0.087367 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:05:45
run time  0:01:42.225435
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_28/forward_28_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452880
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:05:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3931a4d390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1925, '_step_count': 1926, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.114651 valid_loss:0.110802 each epoch time:20.67085
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000123  valid_dq/boxsize 0.000122  train_dp 0.113113  valid_dp 0.110011 reg_loss 0.007420
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:07:30
run time  0:01:43.998793
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_28/forward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_28/forward_28_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452896
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:07:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc25462f210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1930, '_step_count': 1931, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.088803 valid_loss:0.088063 each epoch time:20.43947
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000086  valid_dq/boxsize 0.000086  train_dp 0.088137  valid_dp 0.087399 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:09:15
run time  0:01:42.363015
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_28/backward_28_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452913
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:09:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb0c41e4090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1935, '_step_count': 1936, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.057653 valid_loss:0.056549 each epoch time:19.82689
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000045  valid_dq/boxsize 0.000044  train_dp 0.057173  valid_dp 0.056079 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:10:57
run time  0:01:40.448495
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_28/backward_28_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452931
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:10:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb221298510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1940, '_step_count': 1941, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.042613 valid_loss:0.044330 each epoch time:20.13340
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.042231  valid_dp 0.043937 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:12:40
run time  0:01:41.839754
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_28/backward_28_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452948
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:12:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f118a71d690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1945, '_step_count': 1946, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.072757 valid_loss:0.072050 each epoch time:20.60533
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000063  valid_dq/boxsize 0.000063  train_dp 0.072190  valid_dp 0.071487 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:14:25
run time  0:01:43.083160
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_28/backward_28_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452964
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:14:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7116b985d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1950, '_step_count': 1951, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.042507 valid_loss:0.044234 each epoch time:20.14858
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.042122  valid_dp 0.043838 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:16:08
run time  0:01:40.872161
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_28/backward_28_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  452982
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:16:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f00ac1f8650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1955, '_step_count': 1956, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.057277 valid_loss:0.056204 each epoch time:19.63159
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000045  valid_dq/boxsize 0.000044  train_dp 0.056798  valid_dp 0.055735 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:17:50
run time  0:01:39.966068
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_28/backward_28_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453002
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:17:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2dde243290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1960, '_step_count': 1961, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.042326 valid_loss:0.044056 each epoch time:20.21019
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.041944  valid_dp 0.043663 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:19:34
run time  0:01:41.545331
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_28/backward_28_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_28/backward_28_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453020
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:19:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f628947f810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1965, '_step_count': 1966, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.057091 valid_loss:0.056047 each epoch time:20.57695
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000045  valid_dq/boxsize 0.000044  train_dp 0.056615  valid_dp 0.055580 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:21:18
run time  0:01:41.105070
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_29/forward_29_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453036
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:21:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0cb02748d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1970, '_step_count': 1971, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.042188 valid_loss:0.043924 each epoch time:20.06263
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.041808  valid_dp 0.043532 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:23:00
run time  0:01:40.714355
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_29/forward_29_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453052
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:23:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc1f2981d50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1975, '_step_count': 1976, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.072188 valid_loss:0.071491 each epoch time:21.00402
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000063  valid_dq/boxsize 0.000063  train_dp 0.071625  valid_dp 0.070931 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:24:43
run time  0:01:41.788091
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_29/forward_29_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453068
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:24:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdd44c0abd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1980, '_step_count': 1981, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.042062 valid_loss:0.043792 each epoch time:20.10792
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.041684  valid_dp 0.043404 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:26:26
run time  0:01:41.836251
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_29/forward_29_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453085
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:26:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdb0d8dbd90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1985, '_step_count': 1986, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056921 valid_loss:0.055898 each epoch time:20.23062
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000045  valid_dq/boxsize 0.000044  train_dp 0.056440  valid_dp 0.055427 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:28:09
run time  0:01:40.841508
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_29/forward_29_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453103
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:28:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4d42a88a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1990, '_step_count': 1991, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.087543 valid_loss:0.086812 each epoch time:20.36747
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000086  valid_dq/boxsize 0.000086  train_dp 0.086884  valid_dp 0.086152 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:29:51
run time  0:01:41.289304
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_29/forward_29_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453120
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:29:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f080c92bf90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.41192e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 1995, '_step_count': 1996, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.41192e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.111904 valid_loss:0.108771 each epoch time:20.67340
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000122  valid_dq/boxsize 0.000121  train_dp 0.111112  valid_dp 0.107989 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:31:37
run time  0:01:44.267721
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_29/forward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_29/forward_29_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453139
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:31:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff1a22230d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2000, '_step_count': 2001, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.087156 valid_loss:0.086535 each epoch time:20.66915
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000085  valid_dq/boxsize 0.000085  train_dp 0.086501  valid_dp 0.085879 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:33:20
run time  0:01:42.183370
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_29/backward_29_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453156
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:33:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faf5a522fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2005, '_step_count': 2006, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056611 valid_loss:0.055640 each epoch time:20.43038
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000044  valid_dq/boxsize 0.000043  train_dp 0.056137  valid_dp 0.055176 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:35:03
run time  0:01:41.573916
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_29/backward_29_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453176
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:35:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbf384dbb90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2010, '_step_count': 2011, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.041859 valid_loss:0.043545 each epoch time:20.34974
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.041481  valid_dp 0.043156 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:36:46
run time  0:01:41.605221
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_29/backward_29_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453193
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:36:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f84e131e4d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2015, '_step_count': 2016, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.071548 valid_loss:0.070861 each epoch time:20.34440
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000063  valid_dq/boxsize 0.000062  train_dp 0.070987  valid_dp 0.070304 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:38:29
run time  0:01:41.512811
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_29/backward_29_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453210
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:38:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb456325650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2020, '_step_count': 2021, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.041711 valid_loss:0.043400 each epoch time:20.23700
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.041335  valid_dp 0.043013 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:40:13
run time  0:01:42.375000
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_29/backward_29_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453226
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:40:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd76cde9750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2025, '_step_count': 2026, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056433 valid_loss:0.055474 each epoch time:19.80507
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000045  valid_dq/boxsize 0.000044  train_dp 0.055956  valid_dp 0.055008 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:41:54
run time  0:01:40.381338
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_29/backward_29_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453242
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:41:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb631dba510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2030, '_step_count': 2031, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.041668 valid_loss:0.043383 each epoch time:19.88989
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.041289  valid_dp 0.042994 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:43:36
run time  0:01:40.979716
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_29/backward_29_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_29/backward_29_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453261
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:43:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd94602f210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2035, '_step_count': 2036, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056237 valid_loss:0.055306 each epoch time:20.29111
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000044  valid_dq/boxsize 0.000043  train_dp 0.055765  valid_dp 0.054844 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:45:20
run time  0:01:40.534332
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_30/forward_30_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453278
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:45:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f76acb5c750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2040, '_step_count': 2041, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.041551 valid_loss:0.043272 each epoch time:19.26421
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.041175  valid_dp 0.042885 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:46:59
run time  0:01:38.488939
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_30/forward_30_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453295
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:47:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb69e1d1550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2045, '_step_count': 2046, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.071232 valid_loss:0.070558 each epoch time:19.94486
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000063  valid_dq/boxsize 0.000062  train_dp 0.070670  valid_dp 0.070001 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:48:42
run time  0:01:40.764249
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_30/forward_30_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453313
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:48:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4e918e3710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2050, '_step_count': 2051, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.041450 valid_loss:0.043165 each epoch time:19.82225
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.041075  valid_dp 0.042779 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:50:26
run time  0:01:41.157339
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_30/forward_30_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453330
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:50:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1ad3d72290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2055, '_step_count': 2056, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.055955 valid_loss:0.055043 each epoch time:19.46767
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000044  valid_dq/boxsize 0.000043  train_dp 0.055485  valid_dp 0.054583 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:52:07
run time  0:01:39.488314
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_30/forward_30_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453347
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:52:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5a67794f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2060, '_step_count': 2061, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.086162 valid_loss:0.085452 each epoch time:20.18920
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000084  valid_dq/boxsize 0.000084  train_dp 0.085513  valid_dp 0.084802 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 11:53:53
run time  0:01:42.909299
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_30/forward_30_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453364
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:53:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd607b718d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2065, '_step_count': 2066, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.109983 valid_loss:0.106927 each epoch time:21.31143
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000120  valid_dq/boxsize 0.000118  train_dp 0.109206  valid_dp 0.106159 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:55:39
run time  0:01:45.688585
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_30/forward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_30/forward_30_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453381
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:55:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f905b0bd4d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2070, '_step_count': 2071, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.085973 valid_loss:0.085339 each epoch time:20.17067
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000084  valid_dq/boxsize 0.000084  train_dp 0.085325  valid_dp 0.084691 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 11:57:23
run time  0:01:41.007786
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_30/backward_30_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453398
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:57:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff0441c40d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2075, '_step_count': 2076, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.055775 valid_loss:0.054928 each epoch time:19.87375
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000044  valid_dq/boxsize 0.000043  train_dp 0.055307  valid_dp 0.054470 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 11:59:04
run time  0:01:39.557717
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_30/backward_30_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453415
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 11:59:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2918506250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2080, '_step_count': 2081, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.041233 valid_loss:0.042908 each epoch time:20.62373
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.040861  valid_dp 0.042524 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:00:48
run time  0:01:41.740512
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_30/backward_30_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453432
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:00:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fddf61eac50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2085, '_step_count': 2086, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.070733 valid_loss:0.070087 each epoch time:20.05620
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000063  valid_dq/boxsize 0.000063  train_dp 0.070169  valid_dp 0.069527 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:02:27
run time  0:01:38.289354
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_30/backward_30_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453448
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:02:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f49d913d110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2090, '_step_count': 2091, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.041245 valid_loss:0.042939 each epoch time:21.02999
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000031  train_dp 0.040866  valid_dp 0.042550 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:04:10
run time  0:01:41.783679
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_30/backward_30_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453466
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:04:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f09923ef3d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2095, '_step_count': 2096, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.055569 valid_loss:0.054721 each epoch time:20.71118
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000044  valid_dq/boxsize 0.000043  train_dp 0.055099  valid_dp 0.054261 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:05:53
run time  0:01:41.766560
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_30/backward_30_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453483
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:05:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f11be9d7250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2100, '_step_count': 2101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.041041 valid_loss:0.042750 each epoch time:20.32928
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000030  train_dp 0.040668  valid_dp 0.042365 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:07:35
run time  0:01:40.307039
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_30/backward_30_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_30/backward_30_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453499
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:07:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb6f4122ed0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2105, '_step_count': 2106, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.055384 valid_loss:0.054551 each epoch time:20.80015
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000044  valid_dq/boxsize 0.000043  train_dp 0.054916  valid_dp 0.054094 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:09:19
run time  0:01:42.877283
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_31/forward_31_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453516
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:09:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f494cfd4690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2110, '_step_count': 2111, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.040912 valid_loss:0.042627 each epoch time:19.83150
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.040540  valid_dp 0.042245 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:11:01
run time  0:01:40.804450
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_31/forward_31_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453534
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:11:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc29c5ea0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2115, '_step_count': 2116, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.070327 valid_loss:0.069697 each epoch time:20.53358
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000063  valid_dq/boxsize 0.000062  train_dp 0.069766  valid_dp 0.069140 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:12:45
run time  0:01:41.414828
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_31/forward_31_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453551
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:12:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f316ffd6810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2120, '_step_count': 2121, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.040867 valid_loss:0.042597 each epoch time:20.04576
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000030  train_dp 0.040493  valid_dp 0.042212 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:14:27
run time  0:01:40.772033
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_31/forward_31_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453568
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:14:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6de104ec50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2125, '_step_count': 2126, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.055190 valid_loss:0.054332 each epoch time:20.34611
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000044  valid_dq/boxsize 0.000043  train_dp 0.054723  valid_dp 0.053875 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:16:08
run time  0:01:39.517370
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_31/forward_31_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453585
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:16:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6787296690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2130, '_step_count': 2131, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.085107 valid_loss:0.084339 each epoch time:20.23042
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000084  valid_dq/boxsize 0.000084  train_dp 0.084462  valid_dp 0.083695 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:17:50
run time  0:01:40.296073
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_31/forward_31_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453605
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:17:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f125ed0b450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2135, '_step_count': 2136, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.108440 valid_loss:0.105498 each epoch time:20.76054
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000119  valid_dq/boxsize 0.000117  train_dp 0.107670  valid_dp 0.104737 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:19:35
run time  0:01:44.008082
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_31/forward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_31/forward_31_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453623
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:19:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdfac0903d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2140, '_step_count': 2141, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.084832 valid_loss:0.084131 each epoch time:20.07705
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000084  valid_dq/boxsize 0.000084  train_dp 0.084186  valid_dp 0.083485 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:21:18
run time  0:01:41.538701
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_31/backward_31_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453640
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:21:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3ca9078050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2145, '_step_count': 2146, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.054975 valid_loss:0.054092 each epoch time:19.87923
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000043  train_dp 0.054510  valid_dp 0.053637 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:22:59
run time  0:01:40.377999
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_31/backward_31_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453658
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:23:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd5f89e0110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2150, '_step_count': 2151, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.040712 valid_loss:0.042447 each epoch time:19.68570
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.040340  valid_dp 0.042063 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:24:40
run time  0:01:39.582128
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_31/backward_31_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453674
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:24:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fba6c77ce10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2155, '_step_count': 2156, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.070298 valid_loss:0.069334 each epoch time:20.28806
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000063  valid_dq/boxsize 0.000063  train_dp 0.069479  valid_dp 0.068773 reg_loss 0.002527
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:26:22
run time  0:01:40.198036
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_31/backward_31_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453690
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:26:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5312063450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2160, '_step_count': 2161, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.040638 valid_loss:0.042363 each epoch time:20.17146
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000030  valid_dq/boxsize 0.000030  train_dp 0.040263  valid_dp 0.041978 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:28:05
run time  0:01:41.490455
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_31/backward_31_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453707
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:28:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f14c32c3290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2165, '_step_count': 2166, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.054782 valid_loss:0.053897 each epoch time:20.19878
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000044  valid_dq/boxsize 0.000043  train_dp 0.054315  valid_dp 0.053441 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:29:49
run time  0:01:41.670930
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_31/backward_31_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453724
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:29:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa83ab404d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2170, '_step_count': 2171, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.040440 valid_loss:0.042172 each epoch time:19.73292
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.040070  valid_dp 0.041791 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:31:30
run time  0:01:39.128646
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_31/backward_31_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_31/backward_31_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453743
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:31:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7134af50d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2175, '_step_count': 2176, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.054644 valid_loss:0.053793 each epoch time:20.25896
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000043  train_dp 0.054179  valid_dp 0.053338 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:33:13
run time  0:01:42.342763
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_32/forward_32_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453761
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:33:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6d29eaa690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2180, '_step_count': 2181, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.040338 valid_loss:0.042108 each epoch time:20.16074
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.039969  valid_dp 0.041727 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:34:58
run time  0:01:42.290015
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_32/forward_32_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453780
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:35:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6c373a55d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2185, '_step_count': 2186, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.069192 valid_loss:0.068580 each epoch time:20.36618
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000062  valid_dq/boxsize 0.000061  train_dp 0.068641  valid_dp 0.068034 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:36:41
run time  0:01:41.683359
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_32/forward_32_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453797
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:36:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2e0d4dbf50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2190, '_step_count': 2191, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.040213 valid_loss:0.041982 each epoch time:20.22080
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.039847  valid_dp 0.041604 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:38:24
run time  0:01:41.964547
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_32/forward_32_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453814
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:38:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f03adc37410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2195, '_step_count': 2196, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.054512 valid_loss:0.053663 each epoch time:20.22695
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000044  valid_dq/boxsize 0.000043  train_dp 0.054046  valid_dp 0.053208 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:40:07
run time  0:01:41.090645
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_32/forward_32_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453831
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:40:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe98ca19990>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2200, '_step_count': 2201, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.084127 valid_loss:0.083352 each epoch time:20.47644
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000084  valid_dq/boxsize 0.000084  train_dp 0.083479  valid_dp 0.082704 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:41:53
run time  0:01:42.012681
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_32/forward_32_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453847
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:41:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3225963d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2205, '_step_count': 2206, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.107601 valid_loss:0.104871 each epoch time:20.49674
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000119  valid_dq/boxsize 0.000119  train_dp 0.106476  valid_dp 0.104099 reg_loss 0.003539
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:43:37
run time  0:01:42.516242
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_32/forward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_32/forward_32_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453863
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:43:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f52f289de50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2210, '_step_count': 2211, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.083904 valid_loss:0.083179 each epoch time:20.52703
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000084  valid_dq/boxsize 0.000084  train_dp 0.083258  valid_dp 0.082534 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:45:23
run time  0:01:42.082617
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_32/backward_32_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453881
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:45:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8c489e5710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2215, '_step_count': 2216, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.054266 valid_loss:0.053463 each epoch time:19.92984
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000042  train_dp 0.053802  valid_dp 0.053010 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:47:04
run time  0:01:40.217666
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_32/backward_32_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453897
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:47:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f396c906fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2220, '_step_count': 2221, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.040075 valid_loss:0.041763 each epoch time:20.05618
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.039708  valid_dp 0.041385 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:48:46
run time  0:01:40.411157
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_32/backward_32_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453914
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:48:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdf186af7d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2225, '_step_count': 2226, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.068636 valid_loss:0.068106 each epoch time:20.11205
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000061  train_dp 0.068087  valid_dp 0.067561 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:50:28
run time  0:01:41.275642
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_32/backward_32_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453931
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:50:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7adb181890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2230, '_step_count': 2231, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.039924 valid_loss:0.041641 each epoch time:20.48788
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.039559  valid_dp 0.041265 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:52:11
run time  0:01:40.867178
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_32/backward_32_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453947
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:52:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe533db3790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2235, '_step_count': 2236, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.053910 valid_loss:0.053099 each epoch time:20.01578
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000042  train_dp 0.053451  valid_dp 0.052650 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 12:53:54
run time  0:01:39.892069
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_32/backward_32_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453964
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:53:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3b767ceb90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2240, '_step_count': 2241, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.039802 valid_loss:0.041539 each epoch time:20.02404
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.039438  valid_dp 0.041163 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 12:55:35
run time  0:01:39.946420
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_32/backward_32_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_32/backward_32_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453981
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:55:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feb067e2d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2245, '_step_count': 2246, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.053846 valid_loss:0.053081 each epoch time:20.38045
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000042  train_dp 0.053382  valid_dp 0.052627 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:57:19
run time  0:01:39.941540
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_33/forward_33_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  453998
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:57:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc410a390d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2250, '_step_count': 2251, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.039727 valid_loss:0.041479 each epoch time:20.08245
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.039360  valid_dp 0.041101 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 12:59:00
run time  0:01:39.893383
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_33/forward_33_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454015
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 12:59:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcb12becd50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2255, '_step_count': 2256, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.068233 valid_loss:0.067722 each epoch time:20.25500
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000061  train_dp 0.067685  valid_dp 0.067177 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:00:43
run time  0:01:41.286129
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_33/forward_33_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454031
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:00:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd57029b410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2260, '_step_count': 2261, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.039611 valid_loss:0.041366 each epoch time:20.02860
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.039246  valid_dp 0.040991 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:02:26
run time  0:01:41.347118
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_33/forward_33_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454047
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:02:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f05b542e4d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2265, '_step_count': 2266, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.053558 valid_loss:0.052785 each epoch time:19.87411
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000042  train_dp 0.053100  valid_dp 0.052337 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:04:06
run time  0:01:39.182824
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_33/forward_33_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454064
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:04:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f474e4bf410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2270, '_step_count': 2271, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.082582 valid_loss:0.081887 each epoch time:20.41231
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000082  valid_dq/boxsize 0.000082  train_dp 0.081950  valid_dp 0.081254 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:05:49
run time  0:01:41.508946
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_33/forward_33_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454081
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:05:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe5342d9510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2275, '_step_count': 2276, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.105754 valid_loss:0.103038 each epoch time:20.54243
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000118  valid_dq/boxsize 0.000117  train_dp 0.104988  valid_dp 0.102282 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:07:33
run time  0:01:42.534512
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_33/forward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_33/forward_33_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454099
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:07:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1bf07aa050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2280, '_step_count': 2281, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.082446 valid_loss:0.081784 each epoch time:20.38892
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000083  valid_dq/boxsize 0.000083  train_dp 0.081810  valid_dp 0.081147 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:09:15
run time  0:01:41.578985
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_33/backward_33_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454115
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:09:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f06ec4a5c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2285, '_step_count': 2286, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.053382 valid_loss:0.052620 each epoch time:20.23589
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000042  train_dp 0.052925  valid_dp 0.052173 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:10:59
run time  0:01:42.063142
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_33/backward_33_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454133
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:11:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5fe4227310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2290, '_step_count': 2291, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.039435 valid_loss:0.041161 each epoch time:20.68670
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.039073  valid_dp 0.040787 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:12:45
run time  0:01:42.098467
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_33/backward_33_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454150
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:12:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f655e9e8c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2295, '_step_count': 2296, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.067861 valid_loss:0.067307 each epoch time:19.46445
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000061  train_dp 0.067312  valid_dp 0.066763 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:14:27
run time  0:01:41.515518
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_33/backward_33_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454167
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:14:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2a5f749450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2300, '_step_count': 2301, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.039392 valid_loss:0.041142 each epoch time:19.97036
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000030  train_dp 0.039029  valid_dp 0.040768 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:16:10
run time  0:01:41.428222
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_33/backward_33_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454184
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:16:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc31486e3d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2305, '_step_count': 2306, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.053179 valid_loss:0.052411 each epoch time:19.79993
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000042  train_dp 0.052723  valid_dp 0.051964 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:17:53
run time  0:01:39.532313
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_33/backward_33_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454203
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:17:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f34081f6dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2310, '_step_count': 2311, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.039254 valid_loss:0.041018 each epoch time:20.45675
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000029  train_dp 0.038892  valid_dp 0.040645 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:19:36
run time  0:01:41.530015
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_33/backward_33_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_33/backward_33_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454220
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:19:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f456b146cd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2315, '_step_count': 2316, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.053036 valid_loss:0.052293 each epoch time:19.99726
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000042  train_dp 0.052581  valid_dp 0.051847 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:21:19
run time  0:01:41.960256
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_34/forward_34_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454239
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:21:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f03ba494250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2320, '_step_count': 2321, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.039145 valid_loss:0.040922 each epoch time:21.07448
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000029  train_dp 0.038784  valid_dp 0.040550 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:23:01
run time  0:01:41.024598
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_34/forward_34_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454256
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:23:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1b7dd5d8d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2325, '_step_count': 2326, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.067311 valid_loss:0.066766 each epoch time:19.93971
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000060  train_dp 0.066768  valid_dp 0.066228 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:24:45
run time  0:01:41.430427
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_34/forward_34_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454272
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:24:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f08510c91d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2330, '_step_count': 2331, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.039041 valid_loss:0.040825 each epoch time:20.55625
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.038682  valid_dp 0.040455 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:26:29
run time  0:01:42.254184
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_34/forward_34_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454289
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:26:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe5a724f110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2335, '_step_count': 2336, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.052805 valid_loss:0.052064 each epoch time:20.26857
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.052353  valid_dp 0.051621 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:28:11
run time  0:01:40.545102
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_34/forward_34_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454307
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:28:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1ac1060f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2340, '_step_count': 2341, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.081665 valid_loss:0.081013 each epoch time:20.00953
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000082  valid_dq/boxsize 0.000083  train_dp 0.081030  valid_dp 0.080378 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:29:53
run time  0:01:41.089398
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_34/forward_34_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454325
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:29:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8b654fc710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2345, '_step_count': 2346, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.104485 valid_loss:0.101774 each epoch time:21.48024
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000118  valid_dq/boxsize 0.000116  train_dp 0.103722  valid_dp 0.101020 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:31:39
run time  0:01:45.066878
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_34/forward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_34/forward_34_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454346
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:31:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc97f0eea50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2350, '_step_count': 2351, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.081337 valid_loss:0.080718 each epoch time:19.55574
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000082  valid_dq/boxsize 0.000082  train_dp 0.080707  valid_dp 0.080087 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:33:24
run time  0:01:40.525338
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_34/backward_34_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454364
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:33:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f12563c0890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2355, '_step_count': 2356, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.052671 valid_loss:0.051950 each epoch time:20.29395
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.052219  valid_dp 0.051507 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:35:09
run time  0:01:42.510203
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_34/backward_34_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454381
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:35:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff967d3a7d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2360, '_step_count': 2361, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.038903 valid_loss:0.040636 each epoch time:20.47379
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.038545  valid_dp 0.040266 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:36:52
run time  0:01:41.822069
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_34/backward_34_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454398
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:36:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efc613997d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2365, '_step_count': 2366, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.066877 valid_loss:0.066302 each epoch time:20.42948
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000060  train_dp 0.066335  valid_dp 0.065764 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:38:37
run time  0:01:41.764526
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_34/backward_34_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454416
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:38:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd5e8621050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2370, '_step_count': 2371, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.038818 valid_loss:0.040563 each epoch time:20.62562
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.038459  valid_dp 0.040193 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:40:20
run time  0:01:41.830887
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_34/backward_34_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454433
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:40:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe2b3951510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2375, '_step_count': 2376, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.052618 valid_loss:0.051941 each epoch time:19.60529
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000042  train_dp 0.052161  valid_dp 0.051494 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:42:00
run time  0:01:39.192286
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_34/backward_34_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454450
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:42:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f89c2db2390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2380, '_step_count': 2381, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.038798 valid_loss:0.040577 each epoch time:20.11062
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000029  train_dp 0.038438  valid_dp 0.040206 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:43:42
run time  0:01:40.080853
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_34/backward_34_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_34/backward_34_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454467
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:43:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f07956e0350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2385, '_step_count': 2386, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.052396 valid_loss:0.051747 each epoch time:19.81045
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.051943  valid_dp 0.051304 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:45:23
run time  0:01:39.888246
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_35/forward_35_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454484
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:45:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7d2a776510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2390, '_step_count': 2391, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.038668 valid_loss:0.040459 each epoch time:19.93256
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.038309  valid_dp 0.040090 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:47:05
run time  0:01:40.662814
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_35/forward_35_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454501
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:47:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbc468f78d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2395, '_step_count': 2396, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.066719 valid_loss:0.066185 each epoch time:20.01250
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000061  train_dp 0.066172  valid_dp 0.065642 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:48:48
run time  0:01:42.040865
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_35/forward_35_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454518
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:48:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7efbfc616210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2400, '_step_count': 2401, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.038640 valid_loss:0.040439 each epoch time:20.34696
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000029  train_dp 0.038278  valid_dp 0.040066 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:50:31
run time  0:01:41.454844
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_35/forward_35_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454535
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:50:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb4d5291390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2405, '_step_count': 2406, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.052236 valid_loss:0.051580 each epoch time:19.71515
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000042  train_dp 0.051782  valid_dp 0.051135 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:52:11
run time  0:01:39.127789
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_35/forward_35_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454552
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:52:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb116d47510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2410, '_step_count': 2411, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.080776 valid_loss:0.080104 each epoch time:20.54942
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000082  valid_dq/boxsize 0.000082  train_dp 0.080142  valid_dp 0.079470 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:53:53
run time  0:01:40.680342
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_35/forward_35_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454570
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:53:54
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa78aad9990>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2415, '_step_count': 2416, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.103455 valid_loss:0.100808 each epoch time:21.21640
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000118  valid_dq/boxsize 0.000116  train_dp 0.102691  valid_dp 0.100053 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 13:55:39
run time  0:01:44.856398
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_35/forward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_35/forward_35_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454588
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:55:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8ec4527390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2420, '_step_count': 2421, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.080583 valid_loss:0.079975 each epoch time:21.00102
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000082  valid_dq/boxsize 0.000082  train_dp 0.079950  valid_dp 0.079341 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 13:57:22
run time  0:01:41.472921
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_35/backward_35_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454605
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:57:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbc80e9e610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2425, '_step_count': 2426, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.052116 valid_loss:0.051380 each epoch time:19.92944
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000042  train_dp 0.051662  valid_dp 0.050936 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 13:59:03
run time  0:01:40.380293
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_35/backward_35_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454622
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 13:59:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa7169ee510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2430, '_step_count': 2431, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.038494 valid_loss:0.040227 each epoch time:20.50924
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000029  valid_dq/boxsize 0.000029  train_dp 0.038133  valid_dp 0.039855 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:00:45
run time  0:01:40.642095
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_35/backward_35_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454639
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:00:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd0d5508090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2435, '_step_count': 2436, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.066084 valid_loss:0.065466 each epoch time:20.72283
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000060  train_dp 0.065543  valid_dp 0.064929 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 14:02:30
run time  0:01:41.747057
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_35/backward_35_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454656
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:02:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcd10c9f7d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2440, '_step_count': 2441, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.038351 valid_loss:0.040092 each epoch time:20.06903
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.037992  valid_dp 0.039722 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:04:13
run time  0:01:41.870856
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_35/backward_35_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454673
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:04:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fce866f9250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2445, '_step_count': 2446, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.051843 valid_loss:0.051126 each epoch time:20.84356
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.051391  valid_dp 0.050684 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:05:58
run time  0:01:43.275619
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_35/backward_35_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454690
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:06:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f47c3bc94d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2450, '_step_count': 2451, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.038240 valid_loss:0.039998 each epoch time:20.20980
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.037883  valid_dp 0.039629 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:07:40
run time  0:01:40.650852
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_35/backward_35_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_35/backward_35_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454707
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:07:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff7f12ef410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2455, '_step_count': 2456, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.051716 valid_loss:0.051022 each epoch time:20.18859
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.051265  valid_dp 0.050581 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:09:23
run time  0:01:41.433231
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_36/forward_36_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454724
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:09:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f06ba895790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2460, '_step_count': 2461, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.038143 valid_loss:0.039915 each epoch time:20.61415
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.037786  valid_dp 0.039548 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:11:06
run time  0:01:42.035409
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_36/forward_36_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454742
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:11:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2194ff86d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2465, '_step_count': 2466, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.065863 valid_loss:0.065305 each epoch time:20.18061
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000061  valid_dq/boxsize 0.000060  train_dp 0.065322  valid_dp 0.064768 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:12:49
run time  0:01:41.318950
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_36/forward_36_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454758
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:12:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2b3ce9c490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2470, '_step_count': 2471, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.038201 valid_loss:0.039992 each epoch time:20.17660
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.037841  valid_dp 0.039621 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:14:36
run time  0:01:42.719421
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_36/forward_36_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454775
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:14:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff3bd6d1dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2475, '_step_count': 2476, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.051629 valid_loss:0.050949 each epoch time:20.38796
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.051178  valid_dp 0.050508 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:16:18
run time  0:01:41.122154
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_36/forward_36_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454792
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:16:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f62b6e56850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2480, '_step_count': 2481, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.079677 valid_loss:0.079033 each epoch time:21.12768
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000081  valid_dq/boxsize 0.000081  train_dp 0.079054  valid_dp 0.078409 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:18:02
run time  0:01:42.847048
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_36/forward_36_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454811
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:18:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7afc145310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2485, '_step_count': 2486, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.102264 valid_loss:0.099647 each epoch time:20.57972
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000117  valid_dq/boxsize 0.000115  train_dp 0.101506  valid_dp 0.098899 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:19:50
run time  0:01:46.132734
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_36/forward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_36/forward_36_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454828
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:19:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa6e9ba3490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2490, '_step_count': 2491, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.079551 valid_loss:0.078867 each epoch time:20.18139
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000081  valid_dq/boxsize 0.000081  train_dp 0.078925  valid_dp 0.078241 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:21:34
run time  0:01:41.931211
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_36/backward_36_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454844
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:21:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f02bd481710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.2236816e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2495, '_step_count': 2496, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.2236816e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.051411 valid_loss:0.050725 each epoch time:20.27419
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.050962  valid_dp 0.050286 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 14:23:19
run time  0:01:41.406215
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_36/backward_36_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454861
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:23:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f76b8cdb6d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2500, '_step_count': 2501, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.037945 valid_loss:0.039691 each epoch time:20.02162
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.037590  valid_dp 0.039325 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:25:04
run time  0:01:40.848136
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_36/backward_36_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454878
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:25:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9e219742d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2505, '_step_count': 2506, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.065213 valid_loss:0.064681 each epoch time:19.85099
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000060  valid_dq/boxsize 0.000059  train_dp 0.064678  valid_dp 0.064150 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:26:49
run time  0:01:41.299001
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_36/backward_36_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454895
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:26:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9a53917550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2510, '_step_count': 2511, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.037824 valid_loss:0.039580 each epoch time:20.70103
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.037471  valid_dp 0.039215 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:28:36
run time  0:01:42.776966
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_36/backward_36_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454911
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:28:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcb6899d390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2515, '_step_count': 2516, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.051151 valid_loss:0.050473 each epoch time:20.12564
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.050705  valid_dp 0.050036 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:30:19
run time  0:01:40.439900
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_36/backward_36_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454932
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:30:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f34bcd30410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2520, '_step_count': 2521, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.037724 valid_loss:0.039495 each epoch time:20.22808
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.037371  valid_dp 0.039131 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:32:01
run time  0:01:40.057041
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_36/backward_36_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_36/backward_36_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454950
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:32:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb47311fd10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2525, '_step_count': 2526, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.051037 valid_loss:0.050380 each epoch time:19.86407
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.050591  valid_dp 0.049944 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:33:43
run time  0:01:41.235688
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_37/forward_37_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454967
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:33:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f374a54f890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2530, '_step_count': 2531, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.037634 valid_loss:0.039421 each epoch time:20.47909
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.037281  valid_dp 0.039057 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:35:26
run time  0:01:41.418460
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_37/forward_37_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  454983
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:35:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0583fe01d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2535, '_step_count': 2536, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.064846 valid_loss:0.064303 each epoch time:20.24273
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000060  valid_dq/boxsize 0.000059  train_dp 0.064313  valid_dp 0.063774 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:37:10
run time  0:01:42.497392
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_37/forward_37_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455000
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:37:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe64736a190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2540, '_step_count': 2541, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.037546 valid_loss:0.039341 each epoch time:20.58721
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.037195  valid_dp 0.038979 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 14:38:54
run time  0:01:42.651257
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_37/forward_37_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455017
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:38:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4aa30ea4d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2545, '_step_count': 2546, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.051081 valid_loss:0.050486 each epoch time:20.00658
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.050627  valid_dp 0.050043 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:40:36
run time  0:01:41.591529
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_37/forward_37_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455035
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:40:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f16061e8410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2550, '_step_count': 2551, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.078957 valid_loss:0.078318 each epoch time:21.07179
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000081  valid_dq/boxsize 0.000081  train_dp 0.078331  valid_dp 0.077692 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:42:25
run time  0:01:45.535396
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_37/forward_37_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455051
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:42:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4c3fa3e190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2555, '_step_count': 2556, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.100986 valid_loss:0.098400 each epoch time:20.28149
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000116  valid_dq/boxsize 0.000115  train_dp 0.100233  valid_dp 0.097657 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:44:10
run time  0:01:43.132923
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_37/forward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_37/forward_37_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455067
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:44:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3f9e34a410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2560, '_step_count': 2561, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.078590 valid_loss:0.078019 each epoch time:20.96807
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000081  valid_dq/boxsize 0.000081  train_dp 0.077969  valid_dp 0.077397 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:45:55
run time  0:01:42.897849
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_37/backward_37_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455084
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:45:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f53dbfc8090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2565, '_step_count': 2566, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.050869 valid_loss:0.050240 each epoch time:19.94954
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.050423  valid_dp 0.049804 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:47:36
run time  0:01:40.638696
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_37/backward_37_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455101
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:47:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4b7ba70210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2570, '_step_count': 2571, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.037479 valid_loss:0.039278 each epoch time:20.02053
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.037127  valid_dp 0.038916 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:49:17
run time  0:01:39.836969
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_37/backward_37_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455117
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:49:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe60e392910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2575, '_step_count': 2576, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.064486 valid_loss:0.063918 each epoch time:20.25900
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000059  train_dp 0.063955  valid_dp 0.063391 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 14:51:01
run time  0:01:41.800460
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_37/backward_37_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455135
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:51:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f86ffe0d390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2580, '_step_count': 2581, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.037339 valid_loss:0.039145 each epoch time:19.96226
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.036989  valid_dp 0.038784 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:52:43
run time  0:01:41.246793
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_37/backward_37_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455153
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:52:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa67eaf7250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2585, '_step_count': 2586, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.050524 valid_loss:0.049908 each epoch time:20.15055
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.050081  valid_dp 0.049475 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:54:26
run time  0:01:41.498610
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_37/backward_37_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455169
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:54:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5df5974110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2590, '_step_count': 2591, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.037241 valid_loss:0.039062 each epoch time:20.25543
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000028  train_dp 0.036892  valid_dp 0.038702 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:56:09
run time  0:01:42.175692
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_37/backward_37_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_37/backward_37_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455186
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:56:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff9a43dd0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2595, '_step_count': 2596, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.050415 valid_loss:0.049818 each epoch time:20.00006
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.049973  valid_dp 0.049385 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 14:57:54
run time  0:01:41.365656
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_38/forward_38_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455202
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:57:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0be9081690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2600, '_step_count': 2601, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.037156 valid_loss:0.038993 each epoch time:20.28474
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000028  train_dp 0.036807  valid_dp 0.038633 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 14:59:36
run time  0:01:41.366403
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_38/forward_38_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455219
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 14:59:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f98df015590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2605, '_step_count': 2606, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.064121 valid_loss:0.063564 each epoch time:20.60088
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000059  train_dp 0.063592  valid_dp 0.063039 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:01:19
run time  0:01:41.822453
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_38/forward_38_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455235
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:01:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdc37400310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2610, '_step_count': 2611, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.037073 valid_loss:0.038914 each epoch time:19.75404
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.036725  valid_dp 0.038555 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:03:02
run time  0:01:40.382677
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_38/forward_38_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455251
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:03:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7facd8f952d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2615, '_step_count': 2616, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.050234 valid_loss:0.049632 each epoch time:20.09630
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.049793  valid_dp 0.049201 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:04:43
run time  0:01:40.171910
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_38/forward_38_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455268
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:04:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f77ed0fc590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2620, '_step_count': 2621, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.077874 valid_loss:0.077310 each epoch time:20.63986
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000080  valid_dq/boxsize 0.000081  train_dp 0.077255  valid_dp 0.076690 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:06:26
run time  0:01:41.534995
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_38/forward_38_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455284
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:06:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5bc48684d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2625, '_step_count': 2626, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.099971 valid_loss:0.097539 each epoch time:21.51339
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000116  valid_dq/boxsize 0.000115  train_dp 0.099217  valid_dp 0.096795 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:08:16
run time  0:01:46.342052
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_38/forward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_38/forward_38_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455300
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:08:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6f6dc9c050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2630, '_step_count': 2631, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.077868 valid_loss:0.077289 each epoch time:20.59916
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000081  valid_dq/boxsize 0.000081  train_dp 0.077245  valid_dp 0.076666 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:10:00
run time  0:01:42.417897
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_38/backward_38_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455318
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:10:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9d8e621550>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2635, '_step_count': 2636, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.050190 valid_loss:0.049640 each epoch time:20.06060
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.049746  valid_dp 0.049205 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:11:42
run time  0:01:40.514958
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_38/backward_38_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455335
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:11:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7effabac7090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2640, '_step_count': 2641, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.037063 valid_loss:0.038809 each epoch time:20.28348
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.036708  valid_dp 0.038444 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:13:24
run time  0:01:41.266541
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_38/backward_38_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455351
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:13:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc7f7217490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2645, '_step_count': 2646, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.063985 valid_loss:0.063495 each epoch time:20.64774
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000060  valid_dq/boxsize 0.000059  train_dp 0.063449  valid_dp 0.062964 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:15:07
run time  0:01:41.129669
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_38/backward_38_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455367
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:15:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f89252fdc50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2650, '_step_count': 2651, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.036987 valid_loss:0.038764 each epoch time:19.89821
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.036635  valid_dp 0.038401 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:16:49
run time  0:01:40.617129
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_38/backward_38_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455384
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:16:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff7592b1ad0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2655, '_step_count': 2656, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.050016 valid_loss:0.049460 each epoch time:20.82311
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.049573  valid_dp 0.049026 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:18:33
run time  0:01:41.489860
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_38/backward_38_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455405
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:18:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8c9aee3190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2660, '_step_count': 2661, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.036865 valid_loss:0.038658 each epoch time:19.84772
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.036515  valid_dp 0.038297 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:20:16
run time  0:01:41.219008
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_38/backward_38_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_38/backward_38_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455422
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:20:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7715fb6110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2665, '_step_count': 2666, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.049892 valid_loss:0.049347 each epoch time:19.98350
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.049450  valid_dp 0.048915 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:21:58
run time  0:01:40.971362
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_39/forward_39_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455439
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:21:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd510cd9e90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2670, '_step_count': 2671, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.036772 valid_loss:0.038579 each epoch time:19.42152
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000028  train_dp 0.036423  valid_dp 0.038219 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:23:39
run time  0:01:40.097085
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_39/forward_39_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455456
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:23:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f113ad71dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2675, '_step_count': 2676, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.063692 valid_loss:0.063235 each epoch time:20.12725
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000060  valid_dq/boxsize 0.000059  train_dp 0.063158  valid_dp 0.062705 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:25:20
run time  0:01:39.878454
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_39/forward_39_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455473
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:25:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdd7e1973d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2680, '_step_count': 2681, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.036833 valid_loss:0.038671 each epoch time:20.15501
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.036481  valid_dp 0.038308 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:27:03
run time  0:01:40.015145
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_39/forward_39_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455489
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:27:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3358985d90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2685, '_step_count': 2686, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.050448 valid_loss:0.049807 each epoch time:19.83089
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000043  valid_dq/boxsize 0.000041  train_dp 0.049993  valid_dp 0.049365 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:28:46
run time  0:01:42.008131
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_39/forward_39_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455506
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:28:48
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5b2bf6d250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2690, '_step_count': 2691, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.077358 valid_loss:0.076792 each epoch time:20.38579
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000080  valid_dq/boxsize 0.000080  train_dp 0.076741  valid_dp 0.076174 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:30:28
run time  0:01:40.118226
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_39/forward_39_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455525
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:30:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fae2bcb65d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2695, '_step_count': 2696, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.099502 valid_loss:0.097126 each epoch time:20.61241
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000116  valid_dq/boxsize 0.000115  train_dp 0.098747  valid_dp 0.096381 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:32:14
run time  0:01:44.745398
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_39/forward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_39/forward_39_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455545
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:32:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f39ea87fed0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2700, '_step_count': 2701, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.077509 valid_loss:0.076826 each epoch time:20.47032
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000082  valid_dq/boxsize 0.000082  train_dp 0.076880  valid_dp 0.076197 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:33:57
run time  0:01:40.560796
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_39/backward_39_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455562
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:33:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc48c869210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2705, '_step_count': 2706, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.049803 valid_loss:0.049263 each epoch time:19.81114
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000041  train_dp 0.049357  valid_dp 0.048826 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:35:36
run time  0:01:38.594981
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_39/backward_39_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455578
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:35:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffb70f3c8d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2710, '_step_count': 2711, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.036718 valid_loss:0.038483 each epoch time:20.66206
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.036367  valid_dp 0.038121 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:37:20
run time  0:01:42.637192
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_39/backward_39_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455595
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:37:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc7de611dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2715, '_step_count': 2716, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.063315 valid_loss:0.062796 each epoch time:19.75580
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000060  valid_dq/boxsize 0.000059  train_dp 0.062781  valid_dp 0.062266 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:39:02
run time  0:01:40.562471
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_39/backward_39_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455611
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:39:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f22062b9f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2720, '_step_count': 2721, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.036618 valid_loss:0.038414 each epoch time:20.26972
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000029  train_dp 0.036267  valid_dp 0.038052 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:40:46
run time  0:01:42.029742
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_39/backward_39_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455640
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:40:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f69d0166390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2725, '_step_count': 2726, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.049529 valid_loss:0.048985 each epoch time:20.48582
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000041  train_dp 0.049086  valid_dp 0.048551 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:42:30
run time  0:01:39.194763
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_39/backward_39_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455656
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:42:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe31d10a290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2730, '_step_count': 2731, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.036500 valid_loss:0.038321 each epoch time:20.43171
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000028  valid_dq/boxsize 0.000028  train_dp 0.036151  valid_dp 0.037961 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:44:11
run time  0:01:40.227442
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_39/backward_39_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_39/backward_39_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455672
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:44:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff0a20a9090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2735, '_step_count': 2736, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.049404 valid_loss:0.048882 each epoch time:20.05490
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.048963  valid_dp 0.048450 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:45:54
run time  0:01:41.395129
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_40/forward_40_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455689
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:45:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdaf4841f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2740, '_step_count': 2741, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.036406 valid_loss:0.038244 each epoch time:20.29650
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.036058  valid_dp 0.037885 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:47:38
run time  0:01:43.073821
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_40/forward_40_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455707
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:47:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f85ab230090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2745, '_step_count': 2746, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.062942 valid_loss:0.062438 each epoch time:20.10541
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000059  train_dp 0.062413  valid_dp 0.061913 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:49:19
run time  0:01:39.181445
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_40/forward_40_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455724
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:49:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3bba5d2090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2750, '_step_count': 2751, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.036360 valid_loss:0.038182 each epoch time:20.27084
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.036013  valid_dp 0.037824 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:51:00
run time  0:01:40.131999
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_40/forward_40_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455741
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:51:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3714f3e210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2755, '_step_count': 2756, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.049245 valid_loss:0.048751 each epoch time:20.25827
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.048806  valid_dp 0.048321 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:52:42
run time  0:01:41.220937
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_40/forward_40_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455758
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:52:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fee8526c750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2760, '_step_count': 2761, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.076513 valid_loss:0.075901 each epoch time:19.98494
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000080  valid_dq/boxsize 0.000081  train_dp 0.075894  valid_dp 0.075281 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 15:54:24
run time  0:01:39.850752
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_40/forward_40_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455776
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:54:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f204bfe98d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2765, '_step_count': 2766, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.098994 valid_loss:0.096355 each epoch time:21.39069
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000116  valid_dq/boxsize 0.000115  train_dp 0.097768  valid_dp 0.095611 reg_loss 0.004742
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:56:09
run time  0:01:43.876353
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_40/forward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_40/forward_40_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455793
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:56:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0812429fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2770, '_step_count': 2771, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.076274 valid_loss:0.075793 each epoch time:20.26095
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000080  valid_dq/boxsize 0.000080  train_dp 0.075659  valid_dp 0.075178 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 15:57:53
run time  0:01:42.517747
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_40/backward_40_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455809
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:57:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f18d8173bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2775, '_step_count': 2776, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.049157 valid_loss:0.048641 each epoch time:20.20161
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.048719  valid_dp 0.048213 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 15:59:36
run time  0:01:40.717193
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_40/backward_40_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455826
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 15:59:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3c96435a90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2780, '_step_count': 2781, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.036242 valid_loss:0.038041 each epoch time:19.68237
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.035897  valid_dp 0.037685 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:01:17
run time  0:01:39.330154
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_40/backward_40_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455844
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:01:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7399c50ed0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2785, '_step_count': 2786, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.062505 valid_loss:0.061952 each epoch time:20.60100
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000058  train_dp 0.061981  valid_dp 0.061432 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:03:03
run time  0:01:42.447181
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_40/backward_40_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455861
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:03:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f982ec43590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2790, '_step_count': 2791, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.036127 valid_loss:0.037940 each epoch time:19.75940
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.035784  valid_dp 0.037585 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:04:44
run time  0:01:39.883576
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_40/backward_40_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455879
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:04:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5ce650a290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2795, '_step_count': 2796, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048914 valid_loss:0.048397 each epoch time:20.06464
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.048478  valid_dp 0.047970 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:06:26
run time  0:01:40.278959
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_40/backward_40_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455896
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:06:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f368fa9c2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2800, '_step_count': 2801, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.036038 valid_loss:0.037868 each epoch time:19.80585
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.035695  valid_dp 0.037514 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:08:07
run time  0:01:39.563031
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_40/backward_40_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_40/backward_40_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455912
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:08:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2adf107190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2805, '_step_count': 2806, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048813 valid_loss:0.048313 each epoch time:19.94952
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.048378  valid_dp 0.047887 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:09:47
run time  0:01:39.021473
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_41/forward_41_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455929
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:09:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f06b99b7650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2810, '_step_count': 2811, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035959 valid_loss:0.037803 each epoch time:20.53748
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.035616  valid_dp 0.037449 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:11:32
run time  0:01:41.496446
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_41/forward_41_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455946
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:11:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9c8aa95310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2815, '_step_count': 2816, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.062328 valid_loss:0.061797 each epoch time:19.57261
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000059  train_dp 0.061801  valid_dp 0.061274 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:13:13
run time  0:01:39.693616
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_41/forward_41_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455963
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:13:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3d652e7450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2820, '_step_count': 2821, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035926 valid_loss:0.037765 each epoch time:20.04981
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.035581  valid_dp 0.037408 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:14:55
run time  0:01:40.473470
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_41/forward_41_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455980
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:14:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4cc855bf90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2825, '_step_count': 2826, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048852 valid_loss:0.048377 each epoch time:19.61540
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.048412  valid_dp 0.047947 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:16:35
run time  0:01:39.382066
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_41/forward_41_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  455997
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:16:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f97bffba690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2830, '_step_count': 2831, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.075745 valid_loss:0.075202 each epoch time:20.39053
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000080  valid_dq/boxsize 0.000080  train_dp 0.075130  valid_dp 0.074587 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:18:22
run time  0:01:42.938315
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_41/forward_41_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456018
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:18:23
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb6e3f399d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2835, '_step_count': 2836, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.096924 valid_loss:0.094746 each epoch time:21.05779
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000114  valid_dq/boxsize 0.000113  train_dp 0.096182  valid_dp 0.094012 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:20:07
run time  0:01:44.168028
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_41/forward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_41/forward_41_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456035
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:20:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9b85457150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2840, '_step_count': 2841, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.075299 valid_loss:0.074780 each epoch time:20.06117
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000079  valid_dq/boxsize 0.000079  train_dp 0.074690  valid_dp 0.074171 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:21:48
run time  0:01:39.831079
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_41/backward_41_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456051
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:21:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ffb39151110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2845, '_step_count': 2846, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048550 valid_loss:0.048049 each epoch time:20.60063
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.048117  valid_dp 0.047625 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:23:30
run time  0:01:41.330171
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_41/backward_41_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456069
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:23:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f95ce091bd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2850, '_step_count': 2851, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035786 valid_loss:0.037594 each epoch time:19.73766
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.035445  valid_dp 0.037242 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:25:11
run time  0:01:39.711698
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_41/backward_41_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456086
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:25:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f86f7e151d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2855, '_step_count': 2856, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.061788 valid_loss:0.061282 each epoch time:19.93160
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000058  train_dp 0.061268  valid_dp 0.060766 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:26:56
run time  0:01:40.514215
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_41/backward_41_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456103
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:26:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f26f3ddac50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2860, '_step_count': 2861, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035690 valid_loss:0.037517 each epoch time:19.85347
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.035349  valid_dp 0.037165 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:28:38
run time  0:01:41.406534
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_41/backward_41_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456119
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:28:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fea6fa44b90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2865, '_step_count': 2866, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048427 valid_loss:0.047960 each epoch time:20.76355
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.047990  valid_dp 0.047532 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:30:25
run time  0:01:41.859828
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_41/backward_41_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456138
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:30:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f10aaed1610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2870, '_step_count': 2871, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035646 valid_loss:0.037486 each epoch time:19.36691
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.035303  valid_dp 0.037132 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:32:05
run time  0:01:39.652087
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_41/backward_41_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_41/backward_41_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456155
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:32:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f74463d9e10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2875, '_step_count': 2876, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048298 valid_loss:0.047838 each epoch time:20.22705
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.047864  valid_dp 0.047412 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:33:48
run time  0:01:41.381036
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_42/forward_42_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456175
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:33:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f288652f790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2880, '_step_count': 2881, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035560 valid_loss:0.037421 each epoch time:20.34141
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.035218  valid_dp 0.037068 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:35:30
run time  0:01:40.677837
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_42/forward_42_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456194
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:35:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f137714e810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2885, '_step_count': 2886, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.061722 valid_loss:0.061267 each epoch time:19.89757
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000059  valid_dq/boxsize 0.000058  train_dp 0.061197  valid_dp 0.060747 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:37:11
run time  0:01:40.075209
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_42/forward_42_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456211
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:37:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f907bd3cc10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2890, '_step_count': 2891, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035571 valid_loss:0.037440 each epoch time:20.16819
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.035229  valid_dp 0.037087 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:38:53
run time  0:01:40.528083
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_42/forward_42_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456228
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:38:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe5cd0939d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2895, '_step_count': 2896, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048203 valid_loss:0.047729 each epoch time:20.32405
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000041  valid_dq/boxsize 0.000040  train_dp 0.047770  valid_dp 0.047305 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:40:38
run time  0:01:41.016785
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_42/forward_42_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456244
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:40:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0ac3d9e8d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2900, '_step_count': 2901, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.074867 valid_loss:0.074368 each epoch time:20.09535
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000079  valid_dq/boxsize 0.000079  train_dp 0.074244  valid_dp 0.073759 reg_loss 0.000148
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:42:20
run time  0:01:41.271307
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_42/forward_42_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456261
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:42:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbfe99f7250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2905, '_step_count': 2906, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.096232 valid_loss:0.094044 each epoch time:21.32510
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000114  valid_dq/boxsize 0.000112  train_dp 0.095494  valid_dp 0.093315 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:44:07
run time  0:01:45.646952
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_42/forward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_42/forward_42_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456278
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:44:08
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0739016f50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2910, '_step_count': 2911, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.074780 valid_loss:0.074349 each epoch time:20.82589
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000079  valid_dq/boxsize 0.000079  train_dp 0.074171  valid_dp 0.073741 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:45:52
run time  0:01:43.366499
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_42/backward_42_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456295
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:45:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feec51b5050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2915, '_step_count': 2916, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048158 valid_loss:0.047651 each epoch time:20.26960
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.047726  valid_dp 0.047230 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:47:33
run time  0:01:40.101358
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_42/backward_42_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456312
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:47:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f03f060a310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2920, '_step_count': 2921, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035457 valid_loss:0.037297 each epoch time:20.16879
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.035119  valid_dp 0.036947 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 16:49:15
run time  0:01:40.260582
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_42/backward_42_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456330
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:49:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faaa660d750>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2925, '_step_count': 2926, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.061310 valid_loss:0.060813 each epoch time:19.70498
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000058  train_dp 0.060791  valid_dp 0.060298 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:50:58
run time  0:01:40.918236
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_42/backward_42_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456347
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:50:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f42c12bf450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2930, '_step_count': 2931, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035369 valid_loss:0.037237 each epoch time:20.41423
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.035030  valid_dp 0.036887 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:52:39
run time  0:01:39.919266
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_42/backward_42_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456364
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:52:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0b3726a790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2935, '_step_count': 2936, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047943 valid_loss:0.047409 each epoch time:20.11388
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.047512  valid_dp 0.046988 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:54:22
run time  0:01:42.012316
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_42/backward_42_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456380
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:54:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f683f84a090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2940, '_step_count': 2941, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035275 valid_loss:0.037161 each epoch time:19.90859
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.034937  valid_dp 0.036812 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 16:56:05
run time  0:01:40.971065
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_42/backward_42_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_42/backward_42_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456397
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:56:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8d285e2450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2945, '_step_count': 2946, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047842 valid_loss:0.047326 each epoch time:20.34845
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.047412  valid_dp 0.046906 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:57:49
run time  0:01:43.109689
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_43/forward_43_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456414
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:57:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f62eec82290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2950, '_step_count': 2951, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035197 valid_loss:0.037098 each epoch time:20.98117
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.034860  valid_dp 0.036749 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 16:59:33
run time  0:01:41.423726
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_43/forward_43_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456431
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 16:59:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8f4bd60790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2955, '_step_count': 2956, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.061109 valid_loss:0.060645 each epoch time:20.51857
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000058  train_dp 0.060589  valid_dp 0.060129 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:01:16
run time  0:01:41.663789
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_43/forward_43_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456447
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:01:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd024b45dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2960, '_step_count': 2961, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035200 valid_loss:0.037090 each epoch time:20.19031
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.034860  valid_dp 0.036739 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:02:58
run time  0:01:40.712692
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_43/forward_43_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456465
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:02:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff384f88890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2965, '_step_count': 2966, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047754 valid_loss:0.047254 each epoch time:20.56685
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.047323  valid_dp 0.046833 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:04:41
run time  0:01:41.475734
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_43/forward_43_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456482
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:04:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f512a546b90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2970, '_step_count': 2971, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.074163 valid_loss:0.073687 each epoch time:20.37330
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000079  valid_dq/boxsize 0.000079  train_dp 0.073558  valid_dp 0.073081 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:06:25
run time  0:01:41.043797
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_43/forward_43_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456500
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:06:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fecfb64dd90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2975, '_step_count': 2976, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.095555 valid_loss:0.093358 each epoch time:20.66886
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000114  valid_dq/boxsize 0.000113  train_dp 0.094815  valid_dp 0.092627 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:08:08
run time  0:01:42.192492
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_43/forward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_43/forward_43_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456516
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:08:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f620cee9590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2980, '_step_count': 2981, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.073992 valid_loss:0.073573 each epoch time:19.48886
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000079  valid_dq/boxsize 0.000079  train_dp 0.073388  valid_dp 0.072968 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:09:48
run time  0:01:38.489907
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_43/backward_43_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456533
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:09:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fadf132e850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2985, '_step_count': 2986, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.048570 valid_loss:0.047979 each epoch time:20.09413
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000042  valid_dq/boxsize 0.000040  train_dp 0.048126  valid_dp 0.047547 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:11:31
run time  0:01:40.179776
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_43/backward_43_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456550
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:11:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff6dd572390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2990, '_step_count': 2991, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035268 valid_loss:0.037164 each epoch time:20.83527
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.034926  valid_dp 0.036811 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:13:17
run time  0:01:42.616619
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_43/backward_43_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456567
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:13:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9689fbf090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 9.039207968e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 2995, '_step_count': 2996, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [9.039207968e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.060931 valid_loss:0.060385 each epoch time:19.87435
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000058  train_dp 0.060412  valid_dp 0.059870 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:15:00
run time  0:01:41.582668
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_43/backward_43_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456586
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:15:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faabc48e350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3000, '_step_count': 3001, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035100 valid_loss:0.036996 each epoch time:20.34143
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.034762  valid_dp 0.036647 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:16:42
run time  0:01:40.505476
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_43/backward_43_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456603
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:16:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f041293b6d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3005, '_step_count': 3006, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047669 valid_loss:0.047184 each epoch time:20.41538
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.047239  valid_dp 0.046764 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:18:24
run time  0:01:41.234165
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_43/backward_43_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456623
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:18:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2c6861ebd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3010, '_step_count': 3011, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.035026 valid_loss:0.036927 each epoch time:20.12308
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000027  train_dp 0.034689  valid_dp 0.036579 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:20:06
run time  0:01:40.621916
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_43/backward_43_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_43/backward_43_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456640
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:20:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1ec868d0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3015, '_step_count': 3016, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047503 valid_loss:0.047030 each epoch time:19.80071
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.047075  valid_dp 0.046611 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:21:49
run time  0:01:39.345041
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_44/forward_44_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456657
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:21:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe862252250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3020, '_step_count': 3021, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034920 valid_loss:0.036836 each epoch time:19.41566
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000027  train_dp 0.034584  valid_dp 0.036489 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:23:29
run time  0:01:38.976715
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_44/forward_44_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456674
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:23:32
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb64a788c50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3025, '_step_count': 3026, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.060653 valid_loss:0.060101 each epoch time:20.25806
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000057  train_dp 0.060138  valid_dp 0.059590 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:25:12
run time  0:01:39.992543
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_44/forward_44_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456691
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:25:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fadc9ee43d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3030, '_step_count': 3031, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034906 valid_loss:0.036815 each epoch time:19.93392
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.034571  valid_dp 0.036469 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:26:55
run time  0:01:40.720181
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_44/forward_44_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456707
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:26:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc4fb6ce590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3035, '_step_count': 3036, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047368 valid_loss:0.046903 each epoch time:20.42139
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.046941  valid_dp 0.046486 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:28:38
run time  0:01:41.266826
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_44/forward_44_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456724
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:28:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6bd80d8c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3040, '_step_count': 3041, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.073505 valid_loss:0.073079 each epoch time:20.34012
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000078  valid_dq/boxsize 0.000078  train_dp 0.072904  valid_dp 0.072477 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:30:24
run time  0:01:43.216425
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_44/forward_44_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456744
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:30:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fee99158a50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3045, '_step_count': 3046, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.094955 valid_loss:0.092780 each epoch time:20.50593
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000114  valid_dq/boxsize 0.000113  train_dp 0.094215  valid_dp 0.092049 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:32:09
run time  0:01:42.985962
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_44/forward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_44/forward_44_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456760
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:32:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7faacc774050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3050, '_step_count': 3051, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.073443 valid_loss:0.073060 each epoch time:20.47057
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000079  valid_dq/boxsize 0.000079  train_dp 0.072837  valid_dp 0.072454 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:33:53
run time  0:01:42.151533
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_44/backward_44_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456777
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:33:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc2e812dbd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3055, '_step_count': 3056, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047280 valid_loss:0.046863 each epoch time:20.39481
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.046850  valid_dp 0.046443 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:35:35
run time  0:01:40.606105
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_44/backward_44_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456796
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:35:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f465dedd790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3060, '_step_count': 3061, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034785 valid_loss:0.036629 each epoch time:19.92188
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.034448  valid_dp 0.036281 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:37:19
run time  0:01:40.576383
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_44/backward_44_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456812
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:37:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9c7965ee10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3065, '_step_count': 3066, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.060386 valid_loss:0.059872 each epoch time:19.99318
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000057  train_dp 0.059868  valid_dp 0.059359 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:39:02
run time  0:01:40.708925
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_44/backward_44_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456830
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:39:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f667d82cf90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3070, '_step_count': 3071, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034777 valid_loss:0.036648 each epoch time:19.63585
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000028  train_dp 0.034440  valid_dp 0.036300 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:40:43
run time  0:01:39.692336
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_44/backward_44_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456848
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:40:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdf5fabc4d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3075, '_step_count': 3076, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047136 valid_loss:0.046709 each epoch time:20.12236
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.046708  valid_dp 0.046290 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:42:27
run time  0:01:40.918496
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_44/backward_44_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456865
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:42:28
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9826ffce50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3080, '_step_count': 3081, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034669 valid_loss:0.036550 each epoch time:19.55950
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000027  valid_dq/boxsize 0.000027  train_dp 0.034333  valid_dp 0.036203 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:44:07
run time  0:01:39.366904
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_44/backward_44_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_44/backward_44_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456883
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:44:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fec4a9e23d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3085, '_step_count': 3086, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.047022 valid_loss:0.046611 each epoch time:20.64764
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.046596  valid_dp 0.046194 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:45:51
run time  0:01:41.053271
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_45/forward_45_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456899
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:45:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa810e6f290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3090, '_step_count': 3091, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034586 valid_loss:0.036482 each epoch time:20.26796
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.034252  valid_dp 0.036136 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:47:34
run time  0:01:41.391865
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_45/forward_45_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456916
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:47:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4ad46426d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3095, '_step_count': 3096, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.060009 valid_loss:0.059523 each epoch time:20.42013
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000057  train_dp 0.059495  valid_dp 0.059013 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:49:16
run time  0:01:41.750882
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_45/forward_45_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456933
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:49:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fca63313410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3100, '_step_count': 3101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034547 valid_loss:0.036459 each epoch time:20.08540
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.034213  valid_dp 0.036113 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 17:50:59
run time  0:01:40.913161
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_45/forward_45_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456950
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:51:00
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe8d289f290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3105, '_step_count': 3106, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046891 valid_loss:0.046498 each epoch time:20.36343
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.046465  valid_dp 0.046082 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:52:41
run time  0:01:41.151328
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_45/forward_45_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456967
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:52:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe10df05c50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3110, '_step_count': 3111, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.072874 valid_loss:0.072463 each epoch time:20.53229
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000078  valid_dq/boxsize 0.000078  train_dp 0.072271  valid_dp 0.071859 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:54:26
run time  0:01:42.615332
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_45/forward_45_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  456983
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:54:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4458970c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3115, '_step_count': 3116, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.094186 valid_loss:0.091891 each epoch time:20.62410
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000114  valid_dq/boxsize 0.000112  train_dp 0.093447  valid_dp 0.091161 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:56:12
run time  0:01:43.035591
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_45/forward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_45/forward_45_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457000
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:56:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4269b0b1d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3120, '_step_count': 3121, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.072747 valid_loss:0.072384 each epoch time:20.31502
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000078  valid_dq/boxsize 0.000078  train_dp 0.072144  valid_dp 0.071781 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 17:57:56
run time  0:01:41.283851
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_45/backward_45_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457017
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:57:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6778fee2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3125, '_step_count': 3126, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046790 valid_loss:0.046382 each epoch time:20.01414
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.046364  valid_dp 0.045966 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 17:59:39
run time  0:01:42.266402
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_45/backward_45_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457035
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 17:59:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f75ad498e90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3130, '_step_count': 3131, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034445 valid_loss:0.036312 each epoch time:20.28698
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.034111  valid_dp 0.035966 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:01:23
run time  0:01:40.429115
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_45/backward_45_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457052
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:01:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc9ce5e73d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3135, '_step_count': 3136, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.059594 valid_loss:0.059128 each epoch time:19.99766
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000057  train_dp 0.059082  valid_dp 0.058620 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:03:05
run time  0:01:40.485533
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_45/backward_45_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457068
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:03:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9ab09dd810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3140, '_step_count': 3141, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034359 valid_loss:0.036251 each epoch time:20.18410
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.034026  valid_dp 0.035906 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:04:47
run time  0:01:41.242881
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_45/backward_45_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457085
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:04:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f667f948510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3145, '_step_count': 3146, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046791 valid_loss:0.046410 each epoch time:20.67433
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.046362  valid_dp 0.045992 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:06:30
run time  0:01:40.374165
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_45/backward_45_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457101
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:06:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4b7807a390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3150, '_step_count': 3151, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034391 valid_loss:0.036292 each epoch time:20.00497
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.034056  valid_dp 0.035946 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:08:10
run time  0:01:38.565640
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_45/backward_45_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_45/backward_45_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457118
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:08:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd7876b0190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3155, '_step_count': 3156, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046601 valid_loss:0.046227 each epoch time:19.46920
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.046175  valid_dp 0.045811 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:09:53
run time  0:01:39.936322
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_46/forward_46_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457135
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:09:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f896c8fcbd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3160, '_step_count': 3161, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034287 valid_loss:0.036194 each epoch time:19.90648
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033953  valid_dp 0.035850 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:11:36
run time  0:01:40.009391
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_46/forward_46_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457152
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:11:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f85ab637fd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3165, '_step_count': 3166, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.059409 valid_loss:0.058969 each epoch time:20.08602
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000057  train_dp 0.058897  valid_dp 0.058462 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:13:18
run time  0:01:40.492829
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_46/forward_46_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457169
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:13:22
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f81c7a66050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3170, '_step_count': 3171, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034203 valid_loss:0.036118 each epoch time:20.57332
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033871  valid_dp 0.035774 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:15:04
run time  0:01:41.685284
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_46/forward_46_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457186
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:15:05
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3f6bbb46d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3175, '_step_count': 3176, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046485 valid_loss:0.046146 each epoch time:20.49289
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.046058  valid_dp 0.045728 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:16:47
run time  0:01:42.052978
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_46/forward_46_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457203
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:16:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5ab178da10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3180, '_step_count': 3181, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.072171 valid_loss:0.071795 each epoch time:19.97645
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000078  valid_dq/boxsize 0.000078  train_dp 0.071571  valid_dp 0.071194 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:18:33
run time  0:01:41.220159
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_46/forward_46_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457224
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:18:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcbed2864d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3185, '_step_count': 3186, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.092750 valid_loss:0.090793 each epoch time:20.53143
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000113  valid_dq/boxsize 0.000112  train_dp 0.092017  valid_dp 0.090069 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:20:17
run time  0:01:43.174246
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_46/forward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_46/forward_46_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457242
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:20:18
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1e06737d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3190, '_step_count': 3191, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.072052 valid_loss:0.071687 each epoch time:19.85477
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000078  valid_dq/boxsize 0.000078  train_dp 0.071454  valid_dp 0.071087 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:22:01
run time  0:01:43.107066
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_46/backward_46_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457260
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:22:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f249cce04d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3195, '_step_count': 3196, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046322 valid_loss:0.045922 each epoch time:20.46067
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.045899  valid_dp 0.045508 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:23:45
run time  0:01:41.420471
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_46/backward_46_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457276
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:23:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcfece49690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3200, '_step_count': 3201, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034159 valid_loss:0.036069 each epoch time:20.17291
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033828  valid_dp 0.035726 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:25:27
run time  0:01:40.791436
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_46/backward_46_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457293
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:25:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f75cc130f10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3205, '_step_count': 3206, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.059511 valid_loss:0.058973 each epoch time:20.68080
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000058  valid_dq/boxsize 0.000057  train_dp 0.058995  valid_dp 0.058463 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:27:11
run time  0:01:41.925958
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_46/backward_46_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457309
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:27:12
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3a558592d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3210, '_step_count': 3211, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034141 valid_loss:0.036058 each epoch time:20.60478
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033809  valid_dp 0.035715 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:28:54
run time  0:01:41.957397
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_46/backward_46_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457326
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:28:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3655715dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3215, '_step_count': 3216, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046263 valid_loss:0.045891 each epoch time:20.59607
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.045840  valid_dp 0.045478 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:30:36
run time  0:01:40.885508
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_46/backward_46_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457344
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:30:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8c52336850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3220, '_step_count': 3221, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.034020 valid_loss:0.035941 each epoch time:20.44769
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033690  valid_dp 0.035599 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:32:19
run time  0:01:41.135047
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_46/backward_46_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_46/backward_46_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457361
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:32:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe17a0b08d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3225, '_step_count': 3226, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046150 valid_loss:0.045799 each epoch time:19.58828
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000039  train_dp 0.045728  valid_dp 0.045386 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:33:59
run time  0:01:39.535890
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_47/forward_47_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457380
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:34:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1a22882710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3230, '_step_count': 3231, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033942 valid_loss:0.035873 each epoch time:20.36135
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033612  valid_dp 0.035532 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:35:44
run time  0:01:41.911893
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_47/forward_47_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457396
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:35:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f31ea874650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3235, '_step_count': 3236, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.058966 valid_loss:0.058593 each epoch time:19.87680
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000057  train_dp 0.058456  valid_dp 0.058086 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:37:26
run time  0:01:41.203903
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_47/forward_47_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457414
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:37:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd7b68c0ad0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3240, '_step_count': 3241, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033910 valid_loss:0.035838 each epoch time:20.38679
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033579  valid_dp 0.035496 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:39:09
run time  0:01:41.728531
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_47/forward_47_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457430
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:39:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f6a46c0c0d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3245, '_step_count': 3246, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046072 valid_loss:0.045694 each epoch time:19.75108
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000039  train_dp 0.045650  valid_dp 0.045282 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:40:50
run time  0:01:40.266457
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_47/forward_47_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457447
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:40:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd7ceb3dd10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3250, '_step_count': 3251, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.071686 valid_loss:0.071308 each epoch time:20.27180
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000077  valid_dq/boxsize 0.000078  train_dp 0.071089  valid_dp 0.070711 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:42:34
run time  0:01:42.074325
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_47/forward_47_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457465
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:42:36
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2eb6ab4690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3255, '_step_count': 3256, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.092131 valid_loss:0.090211 each epoch time:21.08970
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000112  valid_dq/boxsize 0.000111  train_dp 0.091402  valid_dp 0.089491 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:44:21
run time  0:01:44.924301
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_47/forward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_47/forward_47_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457485
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:44:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd1c3494090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3260, '_step_count': 3261, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.071599 valid_loss:0.071239 each epoch time:20.29554
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000078  valid_dq/boxsize 0.000078  train_dp 0.071001  valid_dp 0.070639 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:46:07
run time  0:01:41.873589
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_47/backward_47_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457502
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:46:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb2b1262690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3265, '_step_count': 3266, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.046141 valid_loss:0.045769 each epoch time:20.42506
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.045715  valid_dp 0.045353 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:47:50
run time  0:01:39.567907
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_47/backward_47_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457518
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:47:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f996a792110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3270, '_step_count': 3271, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033924 valid_loss:0.035844 each epoch time:20.33132
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033592  valid_dp 0.035500 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:49:31
run time  0:01:40.198214
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_47/backward_47_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457535
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:49:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9287899890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3275, '_step_count': 3276, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.058833 valid_loss:0.058448 each epoch time:20.24027
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000057  train_dp 0.058320  valid_dp 0.057939 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:51:16
run time  0:01:40.931286
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_47/backward_47_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457553
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:51:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb3a1d13150>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3280, '_step_count': 3281, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033832 valid_loss:0.035739 each epoch time:20.06702
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033500  valid_dp 0.035395 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 18:52:57
run time  0:01:39.787847
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_47/backward_47_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457571
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:53:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2f98275190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3285, '_step_count': 3286, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045869 valid_loss:0.045502 each epoch time:21.10663
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.045446  valid_dp 0.045088 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:54:45
run time  0:01:43.542217
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_47/backward_47_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457588
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:54:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdbb47133d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3290, '_step_count': 3291, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033730 valid_loss:0.035658 each epoch time:19.97250
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033399  valid_dp 0.035315 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:56:26
run time  0:01:40.185582
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_47/backward_47_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_47/backward_47_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457605
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:56:27
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc9a1a5bc90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3295, '_step_count': 3296, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045766 valid_loss:0.045413 each epoch time:19.94374
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000039  train_dp 0.045344  valid_dp 0.045001 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 18:58:09
run time  0:01:41.358035
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_48/forward_48_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457621
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:58:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4588dd9290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3300, '_step_count': 3301, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033656 valid_loss:0.035599 each epoch time:19.99106
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033326  valid_dp 0.035257 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 18:59:51
run time  0:01:41.393720
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_48/forward_48_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457638
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 18:59:53
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe1a610dcd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3305, '_step_count': 3306, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.058435 valid_loss:0.058065 each epoch time:20.32528
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000056  train_dp 0.057927  valid_dp 0.057561 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:01:33
run time  0:01:39.891449
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_48/forward_48_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457655
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:01:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff636083890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3310, '_step_count': 3311, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033587 valid_loss:0.035540 each epoch time:19.92518
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033258  valid_dp 0.035199 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:03:14
run time  0:01:40.174655
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_48/forward_48_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457671
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:03:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f679390e490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3315, '_step_count': 3316, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045621 valid_loss:0.045264 each epoch time:20.02246
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.045201  valid_dp 0.044853 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:04:56
run time  0:01:40.259521
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_48/forward_48_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457688
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:04:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f442cff3dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3320, '_step_count': 3321, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.071241 valid_loss:0.070809 each epoch time:20.35024
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000078  valid_dq/boxsize 0.000078  train_dp 0.070641  valid_dp 0.070208 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:06:38
run time  0:01:41.501522
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_48/forward_48_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457705
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:06:40
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f63ce855850>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3325, '_step_count': 3326, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.091766 valid_loss:0.089993 each epoch time:20.88163
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000112  valid_dq/boxsize 0.000112  train_dp 0.090778  valid_dp 0.089269 reg_loss 0.002586
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:08:23
run time  0:01:43.880596
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_48/forward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_48/forward_48_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457722
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:08:25
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff1dbdf2710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3330, '_step_count': 3331, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.071172 valid_loss:0.070788 each epoch time:19.72123
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000078  valid_dq/boxsize 0.000078  train_dp 0.070544  valid_dp 0.070187 reg_loss 0.000284
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:10:05
run time  0:01:40.043137
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_48/backward_48_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457740
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:10:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8fb0a01f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3335, '_step_count': 3336, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045620 valid_loss:0.045300 each epoch time:20.02041
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000040  valid_dq/boxsize 0.000039  train_dp 0.045197  valid_dp 0.044886 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:11:47
run time  0:01:41.043044
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_48/backward_48_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457757
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:11:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2c627fb510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3340, '_step_count': 3341, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033568 valid_loss:0.035447 each epoch time:20.00251
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033237  valid_dp 0.035105 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:13:29
run time  0:01:40.543481
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_48/backward_48_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457774
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:13:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f25afed7190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3345, '_step_count': 3346, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.058391 valid_loss:0.058023 each epoch time:20.98297
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000057  train_dp 0.057880  valid_dp 0.057517 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:15:13
run time  0:01:42.085428
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_48/backward_48_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457791
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:15:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd0ca00dc90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3350, '_step_count': 3351, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033555 valid_loss:0.035471 each epoch time:20.17808
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033224  valid_dp 0.035129 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:16:55
run time  0:01:41.373222
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_48/backward_48_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457808
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:16:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc07c790690>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3355, '_step_count': 3356, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045482 valid_loss:0.045159 each epoch time:19.66591
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000039  train_dp 0.045060  valid_dp 0.044747 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:18:37
run time  0:01:40.264320
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_48/backward_48_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457828
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:18:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7027614c90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3360, '_step_count': 3361, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033454 valid_loss:0.035383 each epoch time:20.10279
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033124  valid_dp 0.035043 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:20:22
run time  0:01:42.720632
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_48/backward_48_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_48/backward_48_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457844
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:20:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5c6c053dd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3365, '_step_count': 3366, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045381 valid_loss:0.045069 each epoch time:19.90586
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.044961  valid_dp 0.044658 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:22:05
run time  0:01:41.461771
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_49/forward_49_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457863
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:22:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0ce0e413d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3370, '_step_count': 3371, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033378 valid_loss:0.035323 each epoch time:20.64341
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033049  valid_dp 0.034984 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:23:49
run time  0:01:41.856477
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_49/forward_49_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457880
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:23:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd04e494650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3375, '_step_count': 3376, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.058058 valid_loss:0.057707 each epoch time:20.19593
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000057  train_dp 0.057549  valid_dp 0.057201 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:25:33
run time  0:01:41.298676
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_49/forward_49_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457897
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:25:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f30bde35f90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3380, '_step_count': 3381, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033347 valid_loss:0.035301 each epoch time:19.45438
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.033017  valid_dp 0.034960 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:27:13
run time  0:01:38.948469
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_49/forward_49_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457914
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:27:15
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff7aed4c110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3385, '_step_count': 3386, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045284 valid_loss:0.044968 each epoch time:19.66444
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.044863  valid_dp 0.044557 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:28:54
run time  0:01:39.503089
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_49/forward_49_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457931
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:28:58
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe936b372d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3390, '_step_count': 3391, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.070532 valid_loss:0.070151 each epoch time:20.52628
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000077  valid_dq/boxsize 0.000078  train_dp 0.069936  valid_dp 0.069555 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:30:40
run time  0:01:42.340864
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_49/forward_49_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457950
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:30:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff57521b2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3395, '_step_count': 3396, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.090743 valid_loss:0.088865 each epoch time:21.23557
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000112  valid_dq/boxsize 0.000111  train_dp 0.090015  valid_dp 0.088146 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:32:29
run time  0:01:44.780645
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_49/forward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_49/forward_49_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457969
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:32:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff831f64090>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3400, '_step_count': 3401, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.070296 valid_loss:0.069981 each epoch time:20.30639
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000077  valid_dq/boxsize 0.000077  train_dp 0.069703  valid_dp 0.069387 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:34:12
run time  0:01:41.429448
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_49/backward_49_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  457986
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:34:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3ba407b490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3405, '_step_count': 3406, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045336 valid_loss:0.045003 each epoch time:20.25186
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.044915  valid_dp 0.044592 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:35:54
run time  0:01:40.935425
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_49/backward_49_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458005
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:35:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff6c535f290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3410, '_step_count': 3411, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033308 valid_loss:0.035235 each epoch time:20.02954
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032979  valid_dp 0.034896 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:37:37
run time  0:01:41.404681
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_49/backward_49_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458022
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:37:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f90eb2a7310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3415, '_step_count': 3416, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.057753 valid_loss:0.057387 each epoch time:20.16854
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000057  valid_dq/boxsize 0.000056  train_dp 0.057247  valid_dp 0.056885 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:39:19
run time  0:01:41.400028
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_49/backward_49_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458039
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:39:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f820ddc0350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3420, '_step_count': 3421, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033197 valid_loss:0.035132 each epoch time:19.76981
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032870  valid_dp 0.034794 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:41:01
run time  0:01:40.788094
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_49/backward_49_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458057
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:41:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff433a66450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3425, '_step_count': 3426, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.045066 valid_loss:0.044722 each epoch time:19.62099
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.044648  valid_dp 0.044314 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:42:42
run time  0:01:39.630298
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_49/backward_49_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458073
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:42:43
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fe53b7a1810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3430, '_step_count': 3431, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033123 valid_loss:0.035070 each epoch time:20.59522
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032797  valid_dp 0.034732 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:44:24
run time  0:01:41.343952
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_49/backward_49_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_49/backward_49_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458090
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:44:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc4d1e2afd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3435, '_step_count': 3436, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044982 valid_loss:0.044661 each epoch time:20.19353
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.044565  valid_dp 0.044254 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 19:46:05
run time  0:01:39.594390
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_50/forward_50_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458107
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:46:06
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9519902d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3440, '_step_count': 3441, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033060 valid_loss:0.035019 each epoch time:19.92955
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032735  valid_dp 0.034681 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:47:48
run time  0:01:41.694092
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_50/forward_50_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458124
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:47:52
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb3056eb050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3445, '_step_count': 3446, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.057487 valid_loss:0.057132 each epoch time:20.00821
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000056  train_dp 0.056983  valid_dp 0.056632 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:49:33
run time  0:01:41.483626
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_50/forward_50_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458141
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:49:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9d003ec350>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3450, '_step_count': 3451, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033000 valid_loss:0.034964 each epoch time:20.16319
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032674  valid_dp 0.034627 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:51:18
run time  0:01:41.009421
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_50/forward_50_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458157
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:51:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0beec60410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3455, '_step_count': 3456, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044856 valid_loss:0.044536 each epoch time:19.92159
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.044439  valid_dp 0.044129 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:53:01
run time  0:01:41.016307
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_50/forward_50_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458175
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:53:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7e509e43d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3460, '_step_count': 3461, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.069827 valid_loss:0.069504 each epoch time:19.65651
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000077  valid_dq/boxsize 0.000077  train_dp 0.069237  valid_dp 0.068912 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:54:43
run time  0:01:40.742721
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_50/forward_50_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458192
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:54:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbec2c58d10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3465, '_step_count': 3466, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.089894 valid_loss:0.088054 each epoch time:20.63108
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000112  valid_dq/boxsize 0.000110  train_dp 0.089170  valid_dp 0.087338 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:56:29
run time  0:01:44.298727
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_50/forward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_50/forward_50_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458209
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:56:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f3e770118d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3470, '_step_count': 3471, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.069735 valid_loss:0.069413 each epoch time:20.46243
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000077  valid_dq/boxsize 0.000077  train_dp 0.069143  valid_dp 0.068820 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 19:58:13
run time  0:01:42.674980
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_50/backward_50_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458225
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:58:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f40bb5c0c10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3475, '_step_count': 3476, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044758 valid_loss:0.044406 each epoch time:19.79666
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.044342  valid_dp 0.043999 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 19:59:55
run time  0:01:40.731039
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_50/backward_50_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458241
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 19:59:56
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5977388a10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3480, '_step_count': 3481, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.033019 valid_loss:0.034870 each epoch time:19.83478
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032693  valid_dp 0.034533 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:01:36
run time  0:01:40.698629
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_50/backward_50_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458258
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:01:38
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fc1223f7650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3485, '_step_count': 3486, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.057449 valid_loss:0.057097 each epoch time:20.81137
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000056  train_dp 0.056944  valid_dp 0.056597 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:03:19
run time  0:01:41.662451
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_50/backward_50_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458275
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:03:21
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f7f2f55b790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3490, '_step_count': 3491, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032948 valid_loss:0.034870 each epoch time:20.59545
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032622  valid_dp 0.034533 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:05:03
run time  0:01:42.449918
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_50/backward_50_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458292
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:05:04
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9c28e64450>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.858423808639999e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3495, '_step_count': 3496, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.858423808639999e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044716 valid_loss:0.044379 each epoch time:20.15230
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.044300  valid_dp 0.043974 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:06:46
run time  0:01:41.515938
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_50/backward_50_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458309
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:06:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f78a23ac410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3500, '_step_count': 3501, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032852 valid_loss:0.034785 each epoch time:20.15995
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032528  valid_dp 0.034450 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:08:27
run time  0:01:40.077585
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_50/backward_50_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_50/backward_50_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458326
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:08:30
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5445e857d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3505, '_step_count': 3506, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044621 valid_loss:0.044298 each epoch time:19.47230
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.044207  valid_dp 0.043893 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:10:09
run time  0:01:39.301401
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_51/forward_51_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458345
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:10:11
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f651d82c9d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3510, '_step_count': 3511, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032785 valid_loss:0.034732 each epoch time:19.82900
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000026  train_dp 0.032462  valid_dp 0.034397 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:11:50
run time  0:01:39.587050
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_51/forward_51_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458361
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:11:51
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8a93324490>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3515, '_step_count': 3516, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.057022 valid_loss:0.056728 each epoch time:20.16671
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000056  train_dp 0.056521  valid_dp 0.056230 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:13:32
run time  0:01:41.090101
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_51/forward_51_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458378
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:13:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdd2d61ad90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3520, '_step_count': 3521, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032724 valid_loss:0.034681 each epoch time:20.36278
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000026  train_dp 0.032402  valid_dp 0.034347 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:15:16
run time  0:01:42.132900
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_51/forward_51_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458397
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:15:17
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcc059978d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3525, '_step_count': 3526, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044493 valid_loss:0.044165 each epoch time:20.63796
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.044080  valid_dp 0.043761 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:16:58
run time  0:01:41.088630
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_51/forward_51_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458413
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:16:59
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f1e6e416810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3530, '_step_count': 3531, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.069364 valid_loss:0.069096 each epoch time:20.20000
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000076  valid_dq/boxsize 0.000077  train_dp 0.068776  valid_dp 0.068507 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:18:41
run time  0:01:41.562345
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_51/forward_51_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458433
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:18:44
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fabca42da90>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3535, '_step_count': 3536, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.089523 valid_loss:0.087689 each epoch time:20.96557
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000111  valid_dq/boxsize 0.000110  train_dp 0.088801  valid_dp 0.086974 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:20:28
run time  0:01:43.815075
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_51/forward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_51/forward_51_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458449
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:20:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fcdaca764d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3540, '_step_count': 3541, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.069278 valid_loss:0.068969 each epoch time:20.56499
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000076  valid_dq/boxsize 0.000077  train_dp 0.068690  valid_dp 0.068379 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:22:11
run time  0:01:42.448362
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_51/backward_51_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458466
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:22:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff1dd215250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3545, '_step_count': 3546, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044481 valid_loss:0.044176 each epoch time:19.82579
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.044068  valid_dp 0.043772 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:23:51
run time  0:01:38.906972
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_51/backward_51_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458483
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:23:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdc5c3af050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3550, '_step_count': 3551, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032726 valid_loss:0.034629 each epoch time:20.14117
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032401  valid_dp 0.034292 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:25:35
run time  0:01:39.698581
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_51/backward_51_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458501
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:25:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff43ee24ed0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3555, '_step_count': 3556, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056901 valid_loss:0.056565 each epoch time:20.07566
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000056  train_dp 0.056398  valid_dp 0.056066 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:27:18
run time  0:01:41.361403
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_51/backward_51_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458517
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:27:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f157adb3110>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3560, '_step_count': 3561, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032663 valid_loss:0.034564 each epoch time:19.83184
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032338  valid_dp 0.034228 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:28:58
run time  0:01:39.137491
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_51/backward_51_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458534
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:29:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f5eae42ba10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3565, '_step_count': 3566, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044528 valid_loss:0.044295 each epoch time:20.84826
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.044110  valid_dp 0.043887 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:30:45
run time  0:01:44.260375
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_51/backward_51_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458556
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:30:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f075ac17050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3570, '_step_count': 3571, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032685 valid_loss:0.034619 each epoch time:19.58602
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032360  valid_dp 0.034283 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:32:27
run time  0:01:40.194730
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_51/backward_51_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_51/backward_51_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458573
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:32:29
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f14ac78ac50>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3575, '_step_count': 3576, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044355 valid_loss:0.044128 each epoch time:19.93584
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.043939  valid_dp 0.043723 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:34:09
run time  0:01:39.534537
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_52/forward_52_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458590
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:34:10
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f720e7351d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3580, '_step_count': 3581, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032589 valid_loss:0.034531 each epoch time:19.80499
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000026  train_dp 0.032266  valid_dp 0.034197 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:35:49
run time  0:01:38.978934
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_52/forward_52_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458607
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:35:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f80611fbfd0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3585, '_step_count': 3586, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056690 valid_loss:0.056395 each epoch time:20.35002
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000056  train_dp 0.056189  valid_dp 0.055898 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:37:31
run time  0:01:40.742465
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_52/forward_52_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458623
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:37:35
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f52aad73890>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3590, '_step_count': 3591, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032517 valid_loss:0.034462 each epoch time:19.38999
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000026  train_dp 0.032194  valid_dp 0.034128 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:39:13
run time  0:01:38.663480
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_52/forward_52_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458641
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:39:16
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd850eb8710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3595, '_step_count': 3596, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044200 valid_loss:0.043957 each epoch time:19.92668
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.043787  valid_dp 0.043553 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:40:56
run time  0:01:39.751751
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_52/forward_52_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458658
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:40:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f26550ca050>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3600, '_step_count': 3601, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.068936 valid_loss:0.068627 each epoch time:20.08855
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000076  valid_dq/boxsize 0.000076  train_dp 0.068349  valid_dp 0.068039 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:42:38
run time  0:01:41.445719
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_52/forward_52_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458675
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:42:41
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f89b029b310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3605, '_step_count': 3606, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.089020 valid_loss:0.087134 each epoch time:20.77172
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000112  valid_dq/boxsize 0.000111  train_dp 0.088293  valid_dp 0.086417 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:44:23
run time  0:01:42.066042
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_52/forward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_52/forward_52_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458692
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:44:24
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2c7d4d17d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3610, '_step_count': 3611, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.068825 valid_loss:0.068502 each epoch time:20.33138
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000077  valid_dq/boxsize 0.000077  train_dp 0.068234  valid_dp 0.067909 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:46:06
run time  0:01:41.316320
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_52/backward_52_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458710
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:46:07
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feadedc55d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3615, '_step_count': 3616, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044135 valid_loss:0.043825 each epoch time:20.29172
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.043719  valid_dp 0.043420 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:47:47
run time  0:01:40.578791
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_52/backward_52_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458727
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:47:49
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f90bf579290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3620, '_step_count': 3621, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032506 valid_loss:0.034456 each epoch time:20.34220
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032182  valid_dp 0.034121 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:49:29
run time  0:01:40.689987
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_52/backward_52_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458744
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:49:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7feed495b910>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3625, '_step_count': 3626, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056441 valid_loss:0.056185 each epoch time:19.98883
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000056  train_dp 0.055941  valid_dp 0.055688 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:51:12
run time  0:01:41.557043
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_52/backward_52_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458760
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:51:14
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fbfa27f7ed0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3630, '_step_count': 3631, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032400 valid_loss:0.034353 each epoch time:20.19789
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000026  train_dp 0.032077  valid_dp 0.034019 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 20:52:55
run time  0:01:41.792214
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_52/backward_52_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458777
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:52:57
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f12b5acb2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3635, '_step_count': 3636, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044086 valid_loss:0.043833 each epoch time:20.24812
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.043669  valid_dp 0.043426 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:54:38
run time  0:01:41.567994
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_52/backward_52_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458794
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:54:39
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f2f7932f310>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3640, '_step_count': 3641, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032366 valid_loss:0.034321 each epoch time:19.55152
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.032041  valid_dp 0.033985 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:56:19
run time  0:01:39.518325
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_52/backward_52_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_52/backward_52_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458811
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:56:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f31edf3d610>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3645, '_step_count': 3646, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.043970 valid_loss:0.043732 each epoch time:20.06346
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.043556  valid_dp 0.043326 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 20:58:00
run time  0:01:40.137781
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_53/forward_53_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458829
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:58:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff6c6349810>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3650, '_step_count': 3651, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032298 valid_loss:0.034269 each epoch time:20.78179
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000026  train_dp 0.031975  valid_dp 0.033934 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 20:59:44
run time  0:01:42.494891
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_53/forward_53_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458847
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 20:59:47
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fd19d12d6d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3655, '_step_count': 3656, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056337 valid_loss:0.056114 each epoch time:20.44812
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000056  train_dp 0.055835  valid_dp 0.055616 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:01:29
run time  0:01:42.000766
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_53/forward_53_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458864
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:01:33
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0f5446ea10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3660, '_step_count': 3661, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032280 valid_loss:0.034261 each epoch time:20.18623
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000026  train_dp 0.031957  valid_dp 0.033927 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:03:15
run time  0:01:42.282722
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_53/forward_53_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458880
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:03:19
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f243af276d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3665, '_step_count': 3666, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.043886 valid_loss:0.043656 each epoch time:20.22535
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.043472  valid_dp 0.043251 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 21:05:00
run time  0:01:40.194908
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_53/forward_53_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458896
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:05:01
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f107d79a2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3670, '_step_count': 3671, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.068537 valid_loss:0.068295 each epoch time:20.63402
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000077  valid_dq/boxsize 0.000077  train_dp 0.067948  valid_dp 0.067704 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 21:06:42
run time  0:01:41.097464
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_53/forward_53_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458913
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:06:46
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f825d839210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3675, '_step_count': 3676, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.088227 valid_loss:0.086347 each epoch time:20.90501
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000111  valid_dq/boxsize 0.000110  train_dp 0.087508  valid_dp 0.085636 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:08:31
run time  0:01:44.803130
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_53/forward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_53/forward_53_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458929
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:08:34
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f8626b8f2d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3680, '_step_count': 3681, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.068613 valid_loss:0.068389 each epoch time:20.10851
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000077  valid_dq/boxsize 0.000077  train_dp 0.068023  valid_dp 0.067798 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:10:15
run time  0:01:41.616124
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_53/backward_53_loss.txt
backward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458949
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:10:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f02bad74250>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3685, '_step_count': 3686, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.044030 valid_loss:0.043826 each epoch time:20.34637
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.043613  valid_dp 0.043418 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:11:59
run time  0:01:39.914704
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/backward_53/backward_53_loss.txt
backward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458965
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:12:03
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f0fb0212190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3690, '_step_count': 3691, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032289 valid_loss:0.034246 each epoch time:20.36422
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000027  train_dp 0.031964  valid_dp 0.033911 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 21:13:43
run time  0:01:40.204143
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/backward_53/backward_53_loss.txt
backward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458982
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:13:45
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fad44f52210>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3695, '_step_count': 3696, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.056107 valid_loss:0.055907 each epoch time:19.95241
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000056  train_dp 0.055605  valid_dp 0.055410 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:15:25
run time  0:01:40.263550
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/backward_53/backward_53_loss.txt
backward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  458998
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:15:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f16d546c590>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3700, '_step_count': 3701, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032178 valid_loss:0.034141 each epoch time:20.26789
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000026  valid_dq/boxsize 0.000026  train_dp 0.031855  valid_dp 0.033807 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 21:17:08
run time  0:01:41.670503
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/backward_53/backward_53_loss.txt
backward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  459018
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:17:09
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff8969da710>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3705, '_step_count': 3706, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.043725 valid_loss:0.043499 each epoch time:19.94449
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.043312  valid_dp 0.043095 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:18:49
run time  0:01:40.005831
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/backward_53/backward_53_loss.txt
backward 1rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  459035
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:18:50
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f4aca5ba5d0>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3710, '_step_count': 3711, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032110 valid_loss:0.034085 each epoch time:20.39086
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000025  valid_dq/boxsize 0.000026  train_dp 0.031787  valid_dp 0.033752 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:20:30
run time  0:01:39.858893
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_53/backward_53_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/backward_53/backward_53_loss.txt
forward 2rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  459052
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:20:31
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb1080e0290>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/1rho0.10/1rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3715, '_step_count': 3716, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.043646 valid_loss:0.043435 each epoch time:19.96325
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.043233  valid_dp 0.043032 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:22:12
run time  0:01:40.871465
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_54/forward_54_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/forward_54/forward_54_loss.txt
forward 3rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  459068
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:22:13
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f108d2d0790>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/2rho0.14/2rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3720, '_step_count': 3721, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.032052 valid_loss:0.034039 each epoch time:20.14470
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000025  valid_dq/boxsize 0.000026  train_dp 0.031730  valid_dp 0.033706 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:23:54
run time  0:01:40.154465
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_54/forward_54_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/forward_54/forward_54_loss.txt
forward 4rho0.20
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  459085
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:23:55
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.2lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.2lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fa9d098f650>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/3rho0.10/3rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3725, '_step_count': 3726, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  8.94427190999916 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.055842 valid_loss:0.055655 each epoch time:20.61645
optimizer lr 0.00009  boxsize 8.94427  train_dq/boxsize 0.000056  valid_dq/boxsize 0.000055  train_dp 0.055343  valid_dp 0.055159 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 21:25:36
run time  0:01:41.242257
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_54/forward_54_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/forward_54/forward_54_loss.txt
forward 5rho0.10
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  459102
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:25:37
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.1lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.1lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f97dadb6410>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/4rho0.20/4rho0.20_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3730, '_step_count': 3731, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  12.649110640673518 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.031996 valid_loss:0.033990 each epoch time:20.28385
optimizer lr 0.00009  boxsize 12.64911  train_dq/boxsize 0.000025  valid_dq/boxsize 0.000026  train_dp 0.031675  valid_dp 0.033658 reg_loss 0.000000
memory usage : 3.4  at e= 5
end date/time : 20211025, 21:27:19
run time  0:01:42.255317
mean mem :  3.4 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_54/forward_54_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/forward_54/forward_54_loss.txt
forward 6rho0.14
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  459118
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:27:20
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.14lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.14lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fdcd6e6c190>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/5rho0.10/5rho0.10_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3735, '_step_count': 3736, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  10.690449676496975 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.043530 valid_loss:0.043312 each epoch time:19.79405
optimizer lr 0.00009  boxsize 10.69045  train_dq/boxsize 0.000039  valid_dq/boxsize 0.000038  train_dp 0.043118  valid_dp 0.042910 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:29:01
run time  0:01:40.124821
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_54/forward_54_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/forward_54/forward_54_loss.txt
forward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  459135
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:29:02
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7ff5a0799c10>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/6rho0.14/6rho0.14_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3740, '_step_count': 3741, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.067945 valid_loss:0.067718 each epoch time:19.55330
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000076  valid_dq/boxsize 0.000076  train_dp 0.067361  valid_dp 0.067132 reg_loss 0.000000
memory usage : 3.3  at e= 5
end date/time : 20211025, 21:30:40
run time  0:01:38.544835
mean mem :  3.3 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_54/forward_54_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/forward_54/forward_54_loss.txt
forward 8rho0.38
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  459156
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:30:42
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.38lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.38lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7f9db0d55390>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3745, '_step_count': 3746, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  6.488856845230502 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.087714 valid_loss:0.085848 each epoch time:20.82332
optimizer lr 0.00009  boxsize 6.48886  train_dq/boxsize 0.000111  valid_dq/boxsize 0.000110  train_dp 0.086994  valid_dp 0.085136 reg_loss 0.000000
memory usage : 3.5  at e= 5
end date/time : 20211025, 21:32:24
run time  0:01:42.760974
mean mem :  3.5 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_54/forward_54_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/forward_54/forward_54_loss.txt
backward 7rho0.27
optimizer initialized : op  <class 'torch.optim.sgd.SGD'>  lr  0.0001
pid :  459173
uname :  posix.uname_result(sysname='Linux', nodename='jae2', release='5.8.0-55-generic', version='#62~20.04.1-Ubuntu SMP Wed Jun 2 08:55:04 UTC 2021', machine='x86_64')
code run start time  20211025, 21:32:26
my device here
pb initialized
phase_space initialized
check4particle_crash_dummy initialized
linear_integrator initialized 
MLP_net initialized :  25 -> ... -> 1024 -> 2
MLP_net initialized :  25 -> ... -> 1024 -> 2
hamiltonian initialized
LJ_term initialized : sigma  1  epsilon  1
lennard_jones.py call potential
pb initialized
phase_space initialized
lennard_jones initialized: sigma  1  epsilon  1
kinetic_energy initialized : mass  1
HNN_base initialized
grids initialized : gridL  0.2 ngrid  6
phi_fields initialized : ngrids 6 dgrid 0.2  dphi maxcut  108.35
fields_HNN initialized 
my_data initialized : train_filename  ../data/gen_by_MD/train/n16rho0.27lt0.1nsamples24000_shuffle.pt  val_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  test_filename  ../data/gen_by_MD/valid/n16rho0.27lt0.1nsamples4800_shuffle.pt  train_pts  24000  val_pts  4800  test_pts  4800
kwargs  {}
created  SGD  with lr  0.0001
checkpoint initialized : net list  [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)]  opt  SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.0001
    lr: 0.0001
    momentum: 0
    nesterov: False
    weight_decay: 0
) sch <torch.optim.lr_scheduler.StepLR object at 0x7fb990c73510>
=> loading checkpoint '../data/gen_by_ML/f-auto-lambda0.1l2reg/8rho0.38/8rho0.38_5.pth'
{'net_list': [mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
), mlp_net(
  (layers): ModuleList(
    (0): Linear(in_features=25, out_features=1024, bias=True)
    (1): Tanh()
    (2): Linear(in_features=1024, out_features=64, bias=True)
    (3): Tanh()
    (4): Dropout(p=0, inplace=False)
    (5): Linear(in_features=64, out_features=1024, bias=True)
    (6): Tanh()
    (7): Dropout(p=0, inplace=False)
    (8): Linear(in_features=1024, out_features=2, bias=True)
  )
)], 'optimizer': {'state': {}, 'param_groups': [{'lr': 8.681255332467199e-05, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}, 'scheduler': {'step_size': 500, 'gamma': 0.98, 'base_lrs': [0.0001], 'last_epoch': 3750, '_step_count': 3751, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [8.681255332467199e-05]}}
Previously net_list state_dict loaded...
Previously net_list state_dict loaded...
Previously trained optimizer state_dict loaded...
Previously trained scheduler state_dict loaded...
loss type : mse_loss
MD_learner initialized : tau_cur  0.1  boxsize  7.69800358919501 pothrsh 159.5294604629323 Lambda 0.1 clip value 10.0
5 epoch: train_loss:0.067805 valid_loss:0.067629 each epoch time:20.92255
optimizer lr 0.00009  boxsize 7.69800  train_dq/boxsize 0.000076  valid_dq/boxsize 0.000076  train_dp 0.067219  valid_dp 0.067042 reg_loss 0.000000
memory usage : 3.6  at e= 5
end date/time : 20211025, 21:34:08
run time  0:01:41.974185
mean mem :  3.6 , std mem :  0.0
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_5.pth ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_54/backward_54_5.pth
cp ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/7rho0.27_loss.txt ../data/gen_by_ML/f-auto-lambda0.1l2reg/7rho0.27/backward_54/backward_54_loss.txt
backward 6rho0.14
